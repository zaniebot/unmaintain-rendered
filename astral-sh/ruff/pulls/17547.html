<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[red-knot] mypy_primer: larger depot runner - astral-sh/ruff #17547</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>[red-knot] mypy_primer: larger depot runner</h1>

    <div class="meta">
        <span class="state-icon state-merged"></span>
        <a href="https://github.com/astral-sh/ruff/pull/17547">#17547</a>
        opened by <a href="https://github.com/sharkdp">@sharkdp</a>
        on 2025-04-22 12:16
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/sharkdp">@sharkdp</a></div>
            <div class="timeline-body"><h2>Summary</h2>
<p>A switch from 16 to 32 cores reduces the <code>mypy_primer</code> CI time from 3.5-4 min to 2.5-3 min. There's also a 64-core runner, but the 4 min -&gt; 3 min change when doubling the cores once does suggest that it doesn't parallelize <em>this</em> well.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">ci</span> added by @sharkdp on 2025-04-22 12:16</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">red-knot</span> added by @sharkdp on 2025-04-22 12:16</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/github-actions[bot]">@github-actions[bot]</a> on 2025-04-22 12:20</div>
            <div class="timeline-body"><!-- generated-comment mypy_primer -->

<h2><code>mypy_primer</code> results</h2>
<p>No ecosystem changes detected âœ…</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Marked ready for review by @sharkdp on 2025-04-22 12:24</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/AlexWaygood">@AlexWaygood</a> on 2025-04-22 12:30</div>
            <div class="timeline-body"><p>I wonder if we should experiment with passing <code>--concurrency=1</code> to mypy_primer. red-knot uses multithreading internally, so the concurrency that mypy_primer uses might just be leading to thread contention without any extra speedup? By default, mypy_primer spawns as many processes as there are cores available: https://github.com/hauntsaninja/mypy_primer/blob/ebaa9fd27b51a278873b63676fd25490cec6823b/mypy_primer/globals.py#L208-L214</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/sharkdp">@sharkdp</a> on 2025-04-22 12:34</div>
            <div class="timeline-body"><blockquote>
<p>I wonder if we should experiment with passing <code>--concurrency=1</code> to mypy_primer. red-knot uses multithreading internally, so the concurrency that mypy_primer uses might just be leading to thread contention without any extra speedup?</p>
</blockquote>
<p>Certainly worth doing an experiment, but note that we profit massively from large concurrency during the IO-heavy setup stage (cloning + dependency installation). That would suggest that we should rather limit the number of cores for our red knot runs. Or just hope that the OS scheduler does a good job.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/AlexWaygood">@AlexWaygood</a> on 2025-04-22 12:35</div>
            <div class="timeline-body"><p>Right, we could experiment with setting <code>RAYON_NUM_THREADS</code> in the environment for the github workflow, which would disable red-knot's concurrency while keeping mypy_primer's?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/AlexWaygood">@AlexWaygood</a> approved on 2025-04-22 12:38</div>
            <div class="timeline-body"><p>Seems fine to me, but I don't know how much upgrading to the larger runner might cost us financially (@zanieb?)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/sharkdp">@sharkdp</a> on 2025-04-22 14:38</div>
            <div class="timeline-body"><blockquote>
<p>but I don't know how much upgrading to the larger runner might cost us financially</p>
</blockquote>
<p>I looked at <a href="https://depot.dev/docs/github-actions/runner-types#ubuntu-2204-runners">this table</a> which shows that the -32 runners have a 16x minutes-multiplier, compared to the 8x multiplier for the -16 runners. So it looks to me like they're twice as expensive, but we only use them for ~75% of the time. So probably 50% more expensive overall.</p>
<p>Edit: I'm merging this with the assumption that this is not a significant raise in CI costs, but let me know if this is a concern, and we can simply roll it back.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/carljm">@carljm</a> on 2025-04-22 15:30</div>
            <div class="timeline-body"><p>I wouldn't want to drop <code>RAYON_NUM_THREADS</code> all the way to 1, because if we have multi-threading bugs (especially ones that don't repro reliably), flaky failures of mypy-primer is one of our best ways to see that they are happening.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Merged by @sharkdp on 2025-04-22 15:36</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @sharkdp on 2025-04-22 15:36</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Branch deleted on 2025-04-22 15:36</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2025-04-22 18:01</div>
            <div class="timeline-body"><p>In general, I'm supportive of biasing towards spending money to speed up CI :) I'll keep an eye on the total spend.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/AlexWaygood">@AlexWaygood</a> on 2025-04-23 22:38</div>
            <div class="timeline-body"><blockquote>
<p>I wonder if we should experiment with passing <code>--concurrency=1</code> to mypy_primer. red-knot uses multithreading internally, so the concurrency that mypy_primer uses might just be leading to thread contention without any extra speedup? By default, mypy_primer spawns as many processes as there are cores available: <a href="https://github.com/hauntsaninja/mypy_primer/blob/ebaa9fd27b51a278873b63676fd25490cec6823b/mypy_primer/globals.py#L208-L214">hauntsaninja/mypy_primer@<code>ebaa9fd</code>/mypy_primer/globals.py#L208-L214</a></p>
</blockquote>
<p>I experimented with this change to mypy_primer locally to see if it sped up running mypy_primer with red-knot at all (the idea is to keep mypy_primer's concurrency for the setup stage but limit it to one subprocess actually running red-knot at any one time, since red-knot internally uses concurrency anyway):</p>
<pre><code class="language-diff">--- a/mypy_primer/model.py
+++ b/mypy_primer/model.py
@@ -319,6 +319,7 @@ class Project:
             check=False,
             cwd=ctx.get().projects_dir / self.name,
             env=env,
+            use_checker_lock=True,
         )
         if ctx.get().debug:
             debug_print(f&quot;{Style.BLUE}{knot} on {self.name} took {runtime:.2f}s{Style.RESET}&quot;)
diff --git a/mypy_primer/utils.py b/mypy_primer/utils.py
index 8d2aacd..cb60595 100644
--- a/mypy_primer/utils.py
+++ b/mypy_primer/utils.py
@@ -67,6 +67,7 @@ def debug_print(obj: Any) -&gt; None:
 
 
 _semaphore: asyncio.Semaphore | None = None
+_checker_lock = asyncio.Lock()
 
 
 async def run(
@@ -75,6 +76,7 @@ async def run(
     shell: bool = False,
     output: bool = False,
     check: bool = True,
+    use_checker_lock: bool = False,
     **kwargs: Any,
 ) -&gt; tuple[subprocess.CompletedProcess[str], float]:
     if output:
@@ -87,7 +89,7 @@ async def run(
     global _semaphore
     if _semaphore is None:
         _semaphore = asyncio.BoundedSemaphore(ctx.get().concurrency)
-    async with _semaphore:
+    async with _checker_lock if use_checker_lock else _semaphore:
         if ctx.get().debug:
             log = cmd if shell else shlex.join(cmd)
             log = f&quot;{Style.BLUE}{log}&quot;
</code></pre>
<p>Unfortunately it seems like it just slows mypy_primer down rather than speeding it up at all!</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-12 17:11:47 UTC
    </footer>
</body>
</html>
