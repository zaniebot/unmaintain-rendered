<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[ty] Pluck some low hanging performance fruit for completions - astral-sh/ruff #22630</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>[ty] Pluck some low hanging performance fruit for completions</h1>

    <div class="meta">
        <span class="state-icon state-open"></span>
        <a href="https://github.com/astral-sh/ruff/pull/22630">#22630</a>
        opened by <a href="https://github.com/BurntSushi">@BurntSushi</a>
        on 2026-01-16 20:09
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/BurntSushi">@BurntSushi</a></div>
            <div class="timeline-body"><p>This PR adds a new ad hoc benchmarking CLI for completions and
implements a few low hanging optimizations. All told, for my particular
benchmark (asking for completions on <code>r</code> in a blank file within a
checkout of Home Assistant), we get about a 40% improvement (~250ms
down to ~140ms) in the cached case and a more modest ~12.5% improvement
in the uncached case (~600ms down to ~526ms).</p>
<p>Before:</p>
<pre><code>$ ./target/profiling/ty_completion_bench ~/astral/relatedclones/scratch-home-assistant/homeassistant/scratch.py 1 -q --iters 30
total elapsed for initial completions request: 603.491595ms
total elapsed: 7.36554807s, time per completion request: 245.518269ms
</code></pre>
<p>After:</p>
<pre><code>$ ./target/profiling/ty_completion_bench ~/astral/relatedclones/scratch-home-assistant/homeassistant/scratch.py 1 -q --iters 30
total elapsed for initial completions request: 526.743638ms
total elapsed: 4.268009725s, time per completion request: 142.26699ms
</code></pre>
<p>Closes astral-sh/ty#2298</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @carljm by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @AlexWaygood by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @sharkdp by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @dcreager by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @MichaReiser by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @Gankra by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review request for @dcreager removed by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review request for @carljm removed by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review request for @Gankra removed by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review request for @sharkdp removed by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review request for @AlexWaygood removed by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @Gankra by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">performance</span> added by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">server</span> added by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">ty</span> added by @BurntSushi on 2026-01-16 20:09</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/astral-sh-bot[bot]">@astral-sh-bot[bot]</a> on 2026-01-16 20:10</div>
            <div class="timeline-body"><!-- generated-comment typing_conformance_diagnostics_diff -->

<h2><a href="https://github.com/python/typing/blob/dece44f2922ca390fe314145d09939514a21e76e/conformance/">Typing conformance results</a></h2>
<p>No changes detected ✅</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/astral-sh-bot[bot]">@astral-sh-bot[bot]</a> on 2026-01-16 20:12</div>
            <div class="timeline-body"><!-- generated-comment mypy_primer -->

<h2><code>mypy_primer</code> results</h2>
<details>
<summary>Changes were detected when running on open source projects</summary>

<pre><code class="language-diff">tornado (https://github.com/tornadoweb/tornado)
- tornado/gen.py:255:62: error[invalid-argument-type] Argument to bound method `__init__` is incorrect: Expected `None | Awaitable[Unknown] | list[Awaitable[Unknown]] | dict[Any, Awaitable[Unknown]] | Future[Unknown]`, found `_T@next | _T@next | _VT@next`
+ tornado/gen.py:255:62: error[invalid-argument-type] Argument to bound method `__init__` is incorrect: Expected `None | Awaitable[Unknown] | list[Awaitable[Unknown]] | dict[Any, Awaitable[Unknown]] | Future[Unknown]`, found `_T@next | _VT@next | _T@next`

prefect (https://github.com/PrefectHQ/prefect)
- src/integrations/prefect-dbt/prefect_dbt/core/settings.py:94:28: error[invalid-assignment] Object of type `T@resolve_block_document_references | dict[str, Any]` is not assignable to `dict[str, Any]`
+ src/integrations/prefect-dbt/prefect_dbt/core/settings.py:94:28: error[invalid-assignment] Object of type `T@resolve_block_document_references | dict[str, Any] | str | ... omitted 4 union elements` is not assignable to `dict[str, Any]`
- src/integrations/prefect-dbt/prefect_dbt/core/settings.py:99:28: error[invalid-assignment] Object of type `T@resolve_variables | dict[str, Any]` is not assignable to `dict[str, Any]`
+ src/integrations/prefect-dbt/prefect_dbt/core/settings.py:99:28: error[invalid-assignment] Object of type `T@resolve_variables | str | int | ... omitted 4 union elements` is not assignable to `dict[str, Any]`
- src/prefect/cli/deploy/_core.py:86:21: error[invalid-assignment] Object of type `T@resolve_block_document_references | dict[str, Any]` is not assignable to `dict[str, Any]`
+ src/prefect/cli/deploy/_core.py:86:21: error[invalid-assignment] Object of type `T@resolve_block_document_references | dict[str, Any] | str | ... omitted 4 union elements` is not assignable to `dict[str, Any]`
- src/prefect/cli/deploy/_core.py:87:21: error[invalid-assignment] Object of type `T@resolve_variables` is not assignable to `dict[str, Any]`
+ src/prefect/cli/deploy/_core.py:87:21: error[invalid-assignment] Object of type `T@resolve_variables | str | int | ... omitted 4 union elements` is not assignable to `dict[str, Any]`
- src/prefect/deployments/steps/core.py:137:38: error[invalid-argument-type] Argument is incorrect: Expected `T@resolve_variables`, found `T@resolve_block_document_references | dict[str, Any]`
+ src/prefect/deployments/steps/core.py:137:38: error[invalid-argument-type] Argument is incorrect: Expected `T@resolve_variables`, found `T@resolve_block_document_references | dict[str, Any] | str | ... omitted 4 union elements`
- src/prefect/utilities/templating.py:320:13: error[invalid-assignment] Invalid subscript assignment with key of type `object` and value of type `T@resolve_block_document_references | dict[str, Any]` on object of type `dict[str, Any]`
+ src/prefect/utilities/templating.py:320:13: error[invalid-assignment] Invalid subscript assignment with key of type `object` and value of type `T@resolve_block_document_references | dict[str, Any] | str | ... omitted 4 union elements` on object of type `dict[str, Any]`
- src/prefect/utilities/templating.py:323:16: error[invalid-return-type] Return type does not match returned value: expected `T@resolve_block_document_references | dict[str, Any]`, found `list[T@resolve_block_document_references | dict[str, Any] | Unknown]`
+ src/prefect/utilities/templating.py:323:16: error[invalid-return-type] Return type does not match returned value: expected `T@resolve_block_document_references | dict[str, Any]`, found `list[T@resolve_block_document_references | dict[str, Any] | str | ... omitted 5 union elements]`
- src/prefect/utilities/templating.py:437:16: error[invalid-return-type] Return type does not match returned value: expected `T@resolve_variables`, found `dict[object, T@resolve_variables | Unknown]`
+ src/prefect/utilities/templating.py:437:16: error[invalid-return-type] Return type does not match returned value: expected `T@resolve_variables`, found `dict[object, T@resolve_variables | str | int | ... omitted 5 union elements]`
- src/prefect/utilities/templating.py:442:16: error[invalid-return-type] Return type does not match returned value: expected `T@resolve_variables`, found `list[T@resolve_variables | Unknown]`
+ src/prefect/utilities/templating.py:442:16: error[invalid-return-type] Return type does not match returned value: expected `T@resolve_variables`, found `list[T@resolve_variables | str | int | ... omitted 5 union elements]`
- src/prefect/workers/base.py:232:13: error[invalid-argument-type] Argument is incorrect: Expected `T@resolve_variables`, found `T@resolve_block_document_references | dict[str, Any]`
+ src/prefect/workers/base.py:232:13: error[invalid-argument-type] Argument is incorrect: Expected `T@resolve_variables`, found `T@resolve_block_document_references | dict[str, Any] | str | ... omitted 4 union elements`
- src/prefect/workers/base.py:234:20: error[invalid-argument-type] Argument expression after ** must be a mapping type: Found `T@resolve_variables`
+ src/prefect/workers/base.py:234:20: error[invalid-argument-type] Argument expression after ** must be a mapping type: Found `T@resolve_variables | str | int | ... omitted 4 union elements`

scikit-build-core (https://github.com/scikit-build/scikit-build-core)
+ src/scikit_build_core/build/wheel.py:99:20: error[no-matching-overload] No overload of bound method `__init__` matches arguments
- Found 46 diagnostics
+ Found 47 diagnostics

static-frame (https://github.com/static-frame/static-frame)
- static_frame/core/bus.py:671:16: error[invalid-return-type] Return type does not match returned value: expected `InterGetItemLocReduces[Bus[Any], object_]`, found `InterGetItemLocReduces[Bus[Any] | Bottom[Index[Any]] | TypeBlocks | ... omitted 6 union elements, object_]`
- static_frame/core/bus.py:675:16: error[invalid-return-type] Return type does not match returned value: expected `InterGetItemILocReduces[Bus[Any], object_]`, found `InterGetItemILocReduces[Bus[Any] | Bottom[Index[Any]] | TypeBlocks | ... omitted 6 union elements, object_ | Self@iloc]`
+ static_frame/core/bus.py:675:16: error[invalid-return-type] Return type does not match returned value: expected `InterGetItemILocReduces[Bus[Any], object_]`, found `InterGetItemILocReduces[Self@iloc | Bus[Any], object_ | Self@iloc]`
- static_frame/core/series.py:772:16: error[invalid-return-type] Return type does not match returned value: expected `InterGetItemILocReduces[Series[Any, Any], TVDtype@Series]`, found `InterGetItemILocReduces[Series[Any, Any] | ndarray[Never, Never] | TypeBlocks | ... omitted 6 union elements, TVDtype@Series]`
- static_frame/core/series.py:4072:16: error[invalid-return-type] Return type does not match returned value: expected `InterGetItemILocReduces[SeriesHE[Any, Any], TVDtype@SeriesHE]`, found `InterGetItemILocReduces[Bottom[Series[Any, Any]] | ndarray[Never, Never] | TypeBlocks | ... omitted 7 union elements, TVDtype@SeriesHE]`
- static_frame/core/yarn.py:418:16: error[invalid-return-type] Return type does not match returned value: expected `InterGetItemILocReduces[Yarn[Any], object_]`, found `InterGetItemILocReduces[Yarn[Any] | ndarray[Never, Never] | TypeBlocks | ... omitted 6 union elements, object_]`
- Found 1825 diagnostics
+ Found 1821 diagnostics


</code></pre>
</details>

<p>No memory usage changes detected ✅</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/astral-sh-bot[bot]">@astral-sh-bot[bot]</a> on 2026-01-16 20:15</div>
            <div class="timeline-body"><!-- generated-comment ecosystem -->

<h2><code>ruff-ecosystem</code> results</h2>
<h3>Linter (stable)</h3>
<p>✅ ecosystem check detected no linter changes.</p>
<h3>Linter (preview)</h3>
<p>✅ ecosystem check detected no linter changes.</p>
<h3>Formatter (stable)</h3>
<p>✅ ecosystem check detected no format changes.</p>
<h3>Formatter (preview)</h3>
<p>✅ ecosystem check detected no format changes.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ty_completion_bench/Cargo.toml</code>:1 on 2026-01-17 13:57</div>
            <div class="timeline-body"><p>Can you say more about why you chose to create an entirely separate crate over integrating the benchmarks into <code>ty_walltime</code> or the Python benchmarks in <code>scripts/ty_benchmark</code> (which even includes code to benchmark an LSP server). Integrating into <code>ty_walltime</code> has the advantage that we could decide to run the benchmarks as part of our CI pipeline. Integrating it into <code>ty_benchmark</code> has the advantage that they're easier to discover. Both benchmark also already provide the necessary infrastructure to install dependency and definitions for common ecosystem projects.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ty_ide/src/completion.rs</code>:91 on 2026-01-17 13:57</div>
            <div class="timeline-body"><p>Nice! That's a much better approach than my brute force <code>truncate</code> call</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2026-01-17 13:59</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/BurntSushi">@BurntSushi</a> reviewed on 2026-01-20 13:37</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on <code>crates/ty_completion_bench/Cargo.toml</code>:1 on 2026-01-20 13:37</div>
            <div class="timeline-body"><p>Honestly, the reason is partially just that I wasn't aware of those.  :-) And this particular program is just a copy of <code>ty_completion_eval</code> but stripped down for ad hoc benchmarking of completions specifically. So it was extremely quick and easy to add.</p>
<p>Looking at <code>scripts/ty_benchmark</code>, it looks like that requires doing a full build of <code>ty</code> which means longer iteration times:</p>
<pre><code>$ touch ./crates/ty_ide/src/completion.rs &amp;&amp; time cargo build --bin ty_completion_bench --profile profiling
   Compiling ty_ide v0.0.0 (/home/andrew/astral/ruff/pr1/crates/ty_ide)
   Compiling ty_completion_bench v0.0.0 (/home/andrew/astral/ruff/pr1/crates/ty_completion_bench)
    Finished `profiling` profile [optimized + debuginfo] target(s) in 3.24s

real    3.313
user    16.869
sys     1.102
maxmem  1227 MB
faults  1767

$ touch ./crates/ty_ide/src/completion.rs &amp;&amp; time cargo build --bin ty --profile profiling
   Compiling ty_ide v0.0.0 (/home/andrew/astral/ruff/pr1/crates/ty_ide)
   Compiling ty_server v0.0.0 (/home/andrew/astral/ruff/pr1/crates/ty_server)
   Compiling ty v0.0.0 (/home/andrew/astral/ruff/pr1/crates/ty)
    Finished `profiling` profile [optimized + debuginfo] target(s) in 8.93s

real    9.005
user    1:15.21
sys     1.702
maxmem  1539 MB
faults  2140
</code></pre>
<p>The program was also made with profiling and ad hoc testing in mind. I'd have to actually go through the process of adding completions to <code>ty_benchmark</code> to figure out whether it would work for that. But my program does the minimal amount of work necessary to do a completion request and lets you also repeat that completion request to test the cached case. <em>And</em> you can see the actual completion output, which can be important for understanding what is actually happening. Similarly for <code>ty_walltime</code>, which uses divan and doesn't <a href="https://github.com/nvzqz/divan/issues/72">seem to have a good profiling story</a>.</p>
<p>Now to be clear, I <em>do</em> think we should add completion benchmarks to both <code>ty_benchmark</code> and <code>ty_walltime</code>. Because, yes, running the benchmarks in CI and running them as part of a more complete LSP flow seems like a wise thing to do. But I'd still want this little CLI for ad hoc testing and profiling.</p>
<p>I can add a README noting all of this. Maybe we can get to a point where the CLI isn't needed any more.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on <code>crates/ty_completion_bench/Cargo.toml</code>:1 on 2026-01-20 13:59</div>
            <div class="timeline-body"><p>I added a README.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/BurntSushi">@BurntSushi</a> reviewed on 2026-01-20 13:59</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2026-01-20 13:59</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ty_completion_bench/Cargo.toml</code>:1 on 2026-01-20 13:59</div>
            <div class="timeline-body"><p>Thanks for the context.</p>
<p>I think my concern mainly is this</p>
<blockquote>
<p>Honestly, the reason is partially just that I wasn't aware of those. :-)</p>
</blockquote>
<p>But that's addressed if the plan is to ultimately add those benchmarks to <code>ty_walltime</code>, and this is more of an ad-hoc script.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> approved on 2026-01-20 13:59</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2026-01-20 14:20</div>
            <div class="timeline-body"><p>I created https://github.com/astral-sh/ty/issues/2570 for tracking adding benchmarks to <code>ty_walltime</code> at minimum.</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 14:44:01 UTC
    </footer>
</body>
</html>
