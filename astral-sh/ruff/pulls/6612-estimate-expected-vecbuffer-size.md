```yaml
number: 6612
title: "Estimate expected `VecBuffer` size"
type: pull_request
state: merged
author: MichaReiser
labels:
  - performance
  - formatter
assignees: []
merged: true
base: main
head: pre-allocate-elements-buffer
created_at: 2023-08-16T11:02:23Z
updated_at: 2023-08-16T13:31:32Z
url: https://github.com/astral-sh/ruff/pull/6612
synced_at: 2026-01-12T02:52:04Z
```

# Estimate expected `VecBuffer` size

---

_Pull request opened by @MichaReiser on 2023-08-16 11:02_

<!--
Thank you for contributing to Ruff! To help us out with reviewing, please consider the following:

- Does this pull request include a summary of the change? (See below.)
- Does this pull request include a descriptive title?
- Does this pull request include references to any relevant issues?
-->

## Summary

This PR changes the `format` function to reserve `source.len() / 2` elements in the `VecBuffer` instead of relying on Rust's generic "double the vec when you run out of space" heuristic. Rust's heuristic still applies if the estimate is too low. 

I tried to play scientist, but you all probably have more experience in gathering statistics than I. Please point out any mistakes that I made ;)

I added a simple print statement to log the buffer length after formatting and the source code length and ran our ecosystem check ([raw CSV](https://gist.github.com/MichaReiser/988ab62d0db109cf3e8be67e9a7a2b7c)). I then used my very limited Python skills to [generate a histogram](https://gist.github.com/MichaReiser/988ab62d0db109cf3e8be67e9a7a2b7c#file-generate-py) (luckily, there are many blog posts explaining on how to do that).

![Histogram showing the number of files with a certain buffer/source ratio](https://raw.githubusercontent.com/gist/MichaReiser/988ab62d0db109cf3e8be67e9a7a2b7c/raw/504d907052bd38af64b1e9441aab041a6d3fd155/distribution.svg)

The histogram shows the ratio of $\frac{buffer-length}{sourcecode-length}$. 

What I understand from the histogram is that a ratio of 0.5 is the most common and a good guess. There are still many files where this is underestimated, but this is fine because Rust will grow the Vec to double its size when it runs out of space. 


I have no idea why there's a peak around 0.1... 

## Test Plan

```
formatter/numpy/globals.py
                        time:   [37.415 Âµs 37.468 Âµs 37.523 Âµs]
                        thrpt:  [78.637 MiB/s 78.751 MiB/s 78.862 MiB/s]
                 change:
                        time:   [-5.6859% -5.2827% -4.8477%] (p = 0.00 < 0.05)
                        thrpt:  [+5.0946% +5.5773% +6.0287%]
                        Performance has improved.
Found 9 outliers among 100 measurements (9.00%)
  1 (1.00%) high mild
  8 (8.00%) high severe
formatter/pydantic/types.py
                        time:   [772.68 Âµs 775.05 Âµs 777.91 Âµs]
                        thrpt:  [32.784 MiB/s 32.905 MiB/s 33.006 MiB/s]
                 change:
                        time:   [-3.6234% -3.0237% -2.3473%] (p = 0.00 < 0.05)
                        thrpt:  [+2.4037% +3.1179% +3.7597%]
                        Performance has improved.
Found 4 outliers among 100 measurements (4.00%)
  3 (3.00%) high mild
  1 (1.00%) high severe
formatter/numpy/ctypeslib.py
                        time:   [387.98 Âµs 388.20 Âµs 388.44 Âµs]
                        thrpt:  [42.867 MiB/s 42.893 MiB/s 42.917 MiB/s]
                 change:
                        time:   [-3.6028% -3.3383% -3.0706%] (p = 0.00 < 0.05)
                        thrpt:  [+3.1678% +3.4535% +3.7374%]
                        Performance has improved.
Found 4 outliers among 100 measurements (4.00%)
  2 (2.00%) high mild
  2 (2.00%) high severe
Benchmarking formatter/large/dataset.py: Warming up for 3.0000 s
Warning: Unable to complete 100 samples in 5.0s. You may wish to increase target time to 10.0s, enable flat sampling, or reduce sample count to 40.
formatter/large/dataset.py
                        time:   [1.9642 ms 1.9661 ms 1.9682 ms]
                        thrpt:  [20.670 MiB/s 20.692 MiB/s 20.712 MiB/s]
                 change:
                        time:   [-3.1729% -3.0335% -2.8740%] (p = 0.00 < 0.05)
                        thrpt:  [+2.9591% +3.1284% +3.2769%]
                        Performance has improved.
Found 13 outliers among 100 measurements (13.00%)
  7 (7.00%) high mild
  6 (6.00%) high severe

```


---

_Comment by @MichaReiser on 2023-08-16 11:02_

Current dependencies on/for this PR:
* main
  * **PR #6612** <a href="https://app.graphite.dev/github/pr/astral-sh/ruff/6612" target="_blank"><img src="https://static.graphite.dev/graphite-32x32.png" alt="Graphite" width="10px" height="10px"/></a>  ðŸ‘ˆ

This comment was auto-generated by [Graphite](https://app.graphite.dev/github/pr/astral-sh/ruff/6612?utm_source=stack-comment).

---

_Review requested from @charliermarsh by @MichaReiser on 2023-08-16 11:12_

---

_Review requested from @zanieb by @MichaReiser on 2023-08-16 11:12_

---

_Review requested from @konstin by @MichaReiser on 2023-08-16 11:12_

---

_Label `formatter` added by @MichaReiser on 2023-08-16 11:12_

---

_Label `performance` added by @MichaReiser on 2023-08-16 11:12_

---

_Marked ready for review by @MichaReiser on 2023-08-16 11:12_

---

_Comment by @github-actions[bot] on 2023-08-16 11:36_

## PR Check Results
### Benchmark
#### Linux
```
group                                      main                                   pr
-----                                      ----                                   --
formatter/large/dataset.py                 1.02      4.3Â±0.07ms     9.4 MB/sec    1.00      4.2Â±0.06ms     9.6 MB/sec
formatter/numpy/ctypeslib.py               1.02   892.8Â±11.85Âµs    18.7 MB/sec    1.00   878.9Â±13.99Âµs    18.9 MB/sec
formatter/numpy/globals.py                 1.01     92.4Â±1.39Âµs    31.9 MB/sec    1.00     91.5Â±1.31Âµs    32.3 MB/sec
formatter/pydantic/types.py                1.00  1747.1Â±21.82Âµs    14.6 MB/sec    1.01  1760.8Â±14.57Âµs    14.5 MB/sec
linter/all-rules/large/dataset.py          1.02     12.6Â±0.14ms     3.2 MB/sec    1.00     12.4Â±0.15ms     3.3 MB/sec
linter/all-rules/numpy/ctypeslib.py        1.00      3.3Â±0.03ms     5.1 MB/sec    1.00      3.3Â±0.04ms     5.1 MB/sec
linter/all-rules/numpy/globals.py          1.01    466.5Â±5.15Âµs     6.3 MB/sec    1.00    463.6Â±5.60Âµs     6.4 MB/sec
linter/all-rules/pydantic/types.py         1.00      6.3Â±0.08ms     4.0 MB/sec    1.00      6.3Â±0.08ms     4.0 MB/sec
linter/default-rules/large/dataset.py      1.01      6.5Â±0.06ms     6.2 MB/sec    1.00      6.4Â±0.06ms     6.3 MB/sec
linter/default-rules/numpy/ctypeslib.py    1.00  1440.0Â±11.50Âµs    11.6 MB/sec    1.00   1433.5Â±7.82Âµs    11.6 MB/sec
linter/default-rules/numpy/globals.py      1.01    166.5Â±2.44Âµs    17.7 MB/sec    1.00    165.7Â±2.23Âµs    17.8 MB/sec
linter/default-rules/pydantic/types.py     1.01      2.9Â±0.02ms     8.7 MB/sec    1.00      2.9Â±0.04ms     8.8 MB/sec
```

#### Windows
```
group                                      main                                   pr
-----                                      ----                                   --
formatter/large/dataset.py                 1.00      5.1Â±0.19ms     8.0 MB/sec    1.02      5.2Â±0.28ms     7.8 MB/sec
formatter/numpy/ctypeslib.py               1.01  1034.0Â±58.98Âµs    16.1 MB/sec    1.00  1019.1Â±56.30Âµs    16.3 MB/sec
formatter/numpy/globals.py                 1.01    107.9Â±6.54Âµs    27.4 MB/sec    1.00    107.0Â±6.97Âµs    27.6 MB/sec
formatter/pydantic/types.py                1.00      2.1Â±0.10ms    12.3 MB/sec    1.00      2.1Â±0.09ms    12.3 MB/sec
linter/all-rules/large/dataset.py          1.00     15.9Â±0.37ms     2.6 MB/sec    1.00     16.0Â±0.39ms     2.5 MB/sec
linter/all-rules/numpy/ctypeslib.py        1.02      4.4Â±0.28ms     3.8 MB/sec    1.00      4.3Â±0.13ms     3.9 MB/sec
linter/all-rules/numpy/globals.py          1.00   545.3Â±27.31Âµs     5.4 MB/sec    1.02   553.6Â±32.23Âµs     5.3 MB/sec
linter/all-rules/pydantic/types.py         1.00      8.2Â±0.28ms     3.1 MB/sec    1.00      8.2Â±0.27ms     3.1 MB/sec
linter/default-rules/large/dataset.py      1.00      8.7Â±0.27ms     4.7 MB/sec    1.01      8.8Â±0.25ms     4.6 MB/sec
linter/default-rules/numpy/ctypeslib.py    1.00  1815.9Â±56.35Âµs     9.2 MB/sec    1.01  1840.4Â±73.74Âµs     9.0 MB/sec
linter/default-rules/numpy/globals.py      1.00   216.6Â±10.61Âµs    13.6 MB/sec    1.03   223.5Â±18.25Âµs    13.2 MB/sec
linter/default-rules/pydantic/types.py     1.00      3.9Â±0.12ms     6.6 MB/sec    1.02      3.9Â±0.20ms     6.5 MB/sec
```
<!-- thollander/actions-comment-pull-request "PR Check Results" -->

---

_@charliermarsh approved on 2023-08-16 13:00_

Nice, good science :)

---

_@zanieb approved on 2023-08-16 13:00_

Cute graph

---

_@charliermarsh reviewed on 2023-08-16 13:03_

---

_Review comment by @charliermarsh on `crates/ruff_formatter/src/lib.rs`:784 on 2023-08-16 13:03_

Does this mean we were already using the source code length as the heuristic?

---

_@MichaReiser reviewed on 2023-08-16 13:14_

---

_Review comment by @MichaReiser on `crates/ruff_formatter/src/lib.rs`:784 on 2023-08-16 13:14_

Lol must be... I must have accidentally committed this when playing around with the `Printer.state.buffer` size :hand_over_mouth: 

---

_Merged by @MichaReiser on 2023-08-16 13:31_

---

_Closed by @MichaReiser on 2023-08-16 13:31_

---

_Branch deleted on 2023-08-16 13:31_

---
