<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>formatter: multi char tokens in SimpleTokenizer  - astral-sh/ruff #5610</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>formatter: multi char tokens in SimpleTokenizer</h1>

    <div class="meta">
        <span class="state-icon state-merged"></span>
        <a href="https://github.com/astral-sh/ruff/pull/5610">#5610</a>
        opened by <a href="https://github.com/davidszotten">@davidszotten</a>
        on 2023-07-08 09:45
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davidszotten">@davidszotten</a></div>
            <div class="timeline-body"><p><em>No description provided.</em></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/github-actions[bot]">@github-actions[bot]</a> on 2023-07-08 10:02</div>
            <div class="timeline-body"><h2>PR Check Results</h2>
<h3>Ecosystem</h3>
<p>✅ ecosystem check detected no changes.</p>
<h3>Benchmark</h3>
<h4>Linux</h4>
<pre><code>group                                      main                                   pr
-----                                      ----                                   --
formatter/large/dataset.py                 1.00      8.3±0.02ms     4.9 MB/sec    1.01      8.4±0.02ms     4.9 MB/sec
formatter/numpy/ctypeslib.py               1.00   1777.2±2.45µs     9.4 MB/sec    1.00   1781.6±3.53µs     9.3 MB/sec
formatter/numpy/globals.py                 1.00    195.4±0.28µs    15.1 MB/sec    1.01    197.1±1.11µs    15.0 MB/sec
formatter/pydantic/types.py                1.00      4.0±0.01ms     6.3 MB/sec    1.00      4.0±0.01ms     6.3 MB/sec
linter/all-rules/large/dataset.py          1.01     14.0±0.02ms     2.9 MB/sec    1.00     13.9±0.04ms     2.9 MB/sec
linter/all-rules/numpy/ctypeslib.py        1.01      3.5±0.01ms     4.7 MB/sec    1.00      3.5±0.02ms     4.8 MB/sec
linter/all-rules/numpy/globals.py          1.00    361.9±0.70µs     8.2 MB/sec    1.00    362.8±1.07µs     8.1 MB/sec
linter/all-rules/pydantic/types.py         1.00      6.2±0.01ms     4.1 MB/sec    1.00      6.1±0.01ms     4.1 MB/sec
linter/default-rules/large/dataset.py      1.01      7.1±0.02ms     5.7 MB/sec    1.00      7.1±0.01ms     5.8 MB/sec
linter/default-rules/numpy/ctypeslib.py    1.02   1465.9±2.00µs    11.4 MB/sec    1.00   1443.7±2.13µs    11.5 MB/sec
linter/default-rules/numpy/globals.py      1.01    156.3±0.47µs    18.9 MB/sec    1.00    155.1±0.27µs    19.0 MB/sec
linter/default-rules/pydantic/types.py     1.00      3.2±0.01ms     8.0 MB/sec    1.00      3.2±0.01ms     8.1 MB/sec
</code></pre>
<h4>Windows</h4>
<pre><code>group                                      main                                    pr
-----                                      ----                                    --
formatter/large/dataset.py                 1.00     10.6±0.61ms     3.8 MB/sec     1.03     10.9±0.67ms     3.7 MB/sec
formatter/numpy/ctypeslib.py               1.00      2.2±0.11ms     7.5 MB/sec     1.03      2.3±0.13ms     7.3 MB/sec
formatter/numpy/globals.py                 1.00   265.9±18.58µs    11.1 MB/sec     1.01   267.3±19.84µs    11.0 MB/sec
formatter/pydantic/types.py                1.02      5.2±0.49ms     4.9 MB/sec     1.00      5.1±0.31ms     5.0 MB/sec
linter/all-rules/large/dataset.py          1.00     17.6±0.80ms     2.3 MB/sec     1.01     17.9±0.81ms     2.3 MB/sec
linter/all-rules/numpy/ctypeslib.py        1.00      4.6±0.22ms     3.7 MB/sec     1.03      4.7±0.21ms     3.6 MB/sec
linter/all-rules/numpy/globals.py          1.00   554.9±29.80µs     5.3 MB/sec     1.03   573.9±38.12µs     5.1 MB/sec
linter/all-rules/pydantic/types.py         1.00      8.0±0.45ms     3.2 MB/sec     1.02      8.1±0.42ms     3.1 MB/sec
linter/default-rules/large/dataset.py      1.00      9.1±0.44ms     4.5 MB/sec     1.02      9.2±0.48ms     4.4 MB/sec
linter/default-rules/numpy/ctypeslib.py    1.00  1976.4±128.45µs     8.4 MB/sec    1.00  1985.3±130.29µs     8.4 MB/sec
linter/default-rules/numpy/globals.py      1.00   235.5±13.96µs    12.5 MB/sec     1.01   237.0±15.92µs    12.4 MB/sec
linter/default-rules/pydantic/types.py     1.01      4.1±0.23ms     6.2 MB/sec     1.00      4.1±0.17ms     6.3 MB/sec
</code></pre>
<!-- thollander/actions-comment-pull-request "PR Check Results" -->

</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Marked ready for review by @davidszotten on 2023-07-08 10:46</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2023-07-08 13:12</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:309 on 2023-07-08 13:12</div>
            <div class="timeline-body"><p>I believe this will incorrectly lex <code>ify</code> as an <code>if</code> keyword because it doesn't test what follows after. Lexing out keyword is a bit harder than I assumed it is.</p>
<p>I'm also unsure if LLVM is able to short-circuit if the expression, for example, starts with a number.</p>
<p>I think the way I would implement this is to implement lexing for identifiers, and then use a match on the lexed identifier to test if it is a keyword. You'll need to add a dependency to <code>unic-ucd-ident</code> (used by RustPython's lexer) to detect the start/end of an identifier.</p>
<pre><code class="language-rust">if is_identifier_start(c) {
	self.cursor.eat_while(is_identifier_continuation);

	// If we want to support all identifiers, then we need to handle the string prefixes `b'`, `rf` etc. but we can ignore those for keywords
	
	let range = TextRange::at(self.offset, token_len);
	let kind = match &amp;self.source[range] {	 // This requires storing the whole source on the tokenizer. I think that's fine
		&quot;if&quot; =&gt; TokenKind::If,
		&quot;else&quot; =&gt; TokenKind::Else,
		&quot;match&quot; =&gt; TokenKind::Match // Match is a soft keyword that depends on the context but we can always lex it as a keyword and leave it to the caller (parser) to decide if it should be handled as an identifier or keyword.
		...,
		_ =&gt; TokenKind::Other // Potentially an identifier, but only if it isn't a string prefix. We can ignore this for now https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals
	}
}

fn is_identifier_start(c: char) -&gt; bool {
	c.is_ascii_alphabetic() || c == '_' || is_non_ascii_identifier_start(c) 
}

// Checks if the character c is a valid continuation character as described
// in https://docs.python.org/3/reference/lexical_analysis.html#identifiers
fn is_identifier_continuation(c: char) -&gt; bool {
    if c.is_ascii() {
        matches!(c, 'a'..='z' | 'A'..='Z' | '_' | '0'..='9')
    } else {
        is_xid_continue(c)
    }
}

fn is_non_ascii_identifier_start(c: char) -&gt; bool {
    is_xid_start(c)
}
</code></pre>
<p>Something similar should work for the backward parsing, except that it must start with an <code>is_non_ascii_identifier_start</code> and the last (or first, depending on how you look at the problem) must be <code>is_identifier_start</code> . We should be able to move the match expression into some shared function.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2023-07-08 13:16</div>
            <div class="timeline-body"><p>Neat. Thank you for working on this. I think there's an edge case that I didn't consider initially, making this a little less simple than I assumed (we may also need to rename the <code>SimpleTokenizer</code> at some point, it's getting close to a full python lexer)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davidszotten">@davidszotten</a> on 2023-07-08 16:19</div>
            <div class="timeline-body"><p>Thanks, will have a go</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davidszotten">@davidszotten</a> on 2023-07-08 18:43</div>
            <div class="timeline-body"><p>in unicode fun, some multi-character grapheme clusters (including one from <code>black/simple_cases/tricky_unicode_symbols.py</code>, <code>ម</code>) now result in different tokens when parsed in reverse.</p>
<pre><code> left:  `[Token { kind: Bogus, range: 0..3 }, Token { kind: Other, range: 3..6 }]`,
 right: `[Token { kind: Other, range: 0..6 }]`
</code></pre>
<p>we can maybe fix by using something like https://crates.io/crates/unicode-segmentation but i'm not sure of the perf implications and i guess we don't need this while we only support keyword tokens</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:439 on 2023-07-08 20:59</div>
            <div class="timeline-body"><p>I believe we need to change this to test if it is an id continuation because we are testing the last character and not the first</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:445 on 2023-07-08 21:00</div>
            <div class="timeline-body"><p>We need to test if the last processed character was an identifier start (otherwise 555 is a valid identifier)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:702 on 2023-07-08 21:01</div>
            <div class="timeline-body"><p>Hmm interesting. This is somewhat unexpected. I would expect that we consume the same text range</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2023-07-08 21:01</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davidszotten">@davidszotten</a> reviewed on 2023-07-09 06:43</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/davidszotten">@davidszotten</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:439 on 2023-07-09 06:43</div>
            <div class="timeline-body"><p>ah yes. ~but i guess we also need to change the strategy a bit, since we must _finish with an identifier_start?~ ah you mentioned this below</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davidszotten">@davidszotten</a> reviewed on 2023-07-09 06:45</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/davidszotten">@davidszotten</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:445 on 2023-07-09 06:45</div>
            <div class="timeline-body"><p>unless i'm missing something, wouldn't this mean that say <code>555</code> would be parsed as a single <code>Other</code> backwards, but <code>[Other, Bogus, Bogus]</code> forwards?  to fix, don't we need to scan first (without bumping) to make sure we end on an <code>identifier_start</code>?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2023-07-09 07:18</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:445 on 2023-07-09 07:18</div>
            <div class="timeline-body"><p>Oh yeah. Good point. I think we can either scan first (similar to detecting if there are any comments), or we clone curser, lex it, and restore the cursor if first turns out not to be an identifier</p>
<p>Did these changes fix the graphemes issue?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davidszotten">@davidszotten</a> reviewed on 2023-07-09 07:19</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/davidszotten">@davidszotten</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:702 on 2023-07-09 07:19</div>
            <div class="timeline-body"><p>i think this is fixed by the above conversation</p>
<p>but strings of non-identifiers (or any chars that would be considered <code>Other</code> like <code>555</code>) would still be parsed as <code>Other</code> followed by <code>Bogus</code>, and depending on direction, the <code>Other</code> would be first or last. This is the case currently on <code>main</code>, eg with <code>555</code> or even <code>aaa</code>.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/comments/placement.rs</code>:1223 on 2023-07-09 18:20</div>
            <div class="timeline-body"><p>Nit: We can use <code>debug_assert_eq</code> now to compare the kinds.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/comments/placement.rs</code>:1226 on 2023-07-09 18:20</div>
            <div class="timeline-body"><p>Nit: We can use <code>debug_assert_eq(..., None)</code> here. It should give us a better error message when it throws (I believe)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:331 on 2023-07-09 18:23</div>
            <div class="timeline-body"><p>Nit: The method name indicates to me that this parses an identifier and not a keyword. I haven't been able to come up with a name that I like, but was thinking of <code>match_keyword</code> or <code>to_keyword_or_other</code></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:454 on 2023-07-09 18:25</div>
            <div class="timeline-body"><p>Not really. You could use <code>let mut identifier_start = c</code> and then update the variable in the <code>eat_back_while</code> callback if it is an <code>identifier_continuation</code> but I would prefer what you have right now.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> approved on 2023-07-09 18:26</div>
            <div class="timeline-body"><p>This is awesome. Well done! I'm sorry that it turned out much more complicated than I thought. Let me know when you're ready to merge.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davidszotten">@davidszotten</a> reviewed on 2023-07-09 18:47</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/davidszotten">@davidszotten</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:331 on 2023-07-09 18:47</div>
            <div class="timeline-body"><p>sure, i don't mind. i also considered making it a method on <code>TokenKind</code> (similar to <code>from_non_trivia_char</code>)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davidszotten">@davidszotten</a> reviewed on 2023-07-09 18:48</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/davidszotten">@davidszotten</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:200 on 2023-07-09 18:48</div>
            <div class="timeline-body"><p>oops i guess this is no longer true (length 1)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davidszotten">@davidszotten</a> on 2023-07-09 18:51</div>
            <div class="timeline-body"><p>ok i think that's ready from me now</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davidszotten">@davidszotten</a> on 2023-07-09 18:51</div>
            <div class="timeline-body"><p>thanks for the impl help and the review!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2023-07-10 07:59</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:331 on 2023-07-10 07:59</div>
            <div class="timeline-body"><p>That would work too!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2023-07-10 07:59</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_formatter/src/trivia.rs</code>:200 on 2023-07-10 07:59</div>
            <div class="timeline-body"><p>Good find</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2023-07-10 08:00</div>
            <div class="timeline-body"><p>Thank you for implementing. This is so cool :) Not long, and our <code>SimpleTokenizer</code> can replace RustPython's tokenizer :P</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Merged by @MichaReiser on 2023-07-10 08:00</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @MichaReiser on 2023-07-10 08:01</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-12 16:58:37 UTC
    </footer>
</body>
</html>
