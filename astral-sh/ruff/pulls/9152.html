<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Replace autogenerated parser with hand-written parser - astral-sh/ruff #9152</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Replace autogenerated parser with hand-written parser</h1>

    <div class="meta">
        <span class="state-icon state-closed"></span>
        <a href="https://github.com/astral-sh/ruff/pull/9152">#9152</a>
        opened by <a href="https://github.com/LaBatata101">@LaBatata101</a>
        on 2023-12-15 21:59
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a></div>
            <div class="timeline-body"><p>This PR replaces the autogenerated lalrpop parser in favor of a handwritten parser. Beyond the performance improvements, one of the main differences between the handwritten parser and the autogenerated parser is, the new parser is error persistent. That is, the parser can create an AST even if the source code contains invalid syntax. This also means that, the parser now collects all syntax errors found in the source code, while the old parser would stop parsing after finding the first invalid syntax.</p>
<p>The new parser also enables us to create more helpful error messages, for example, in the old parser the following code would generate this error message:</p>
<pre><code>yield from *a
</code></pre>
<p>Resulting error message &quot;invalid syntax. Got unexpected token &#x27;*&#x27; &quot;, in the new parser the error message is <code>starred expression &quot;*a</code> is not allowed in a <code>yield from</code> statement&quot;</p>
<p>The new parser still preserves the old behavior of returning only the first syntax error it encounters. The Python syntax supported by the parser is of the version 3.12.</p>
Summary of Changes
Changes in the AST
<ul>
<li>Change <code>Identifier</code> node to use <code>SmolStr</code> instead of <code>String</code></li>
<li>Add <code>Invalid</code> node to <code>Expr</code>, <code>Pattern</code> and <code>FStringElement</code></li>
</ul>
Changes to error types
<ul>
<li>Refactor <code>ParseError</code> and <code>LexicalError</code> to use <code>TextRange</code> for the error location instead of <code>TextSize</code>.</li>
<li>Add <code>FStringError</code> to <code>ParseError</code>, the lexer used to check if the <code>{</code> in the f-string was unclosed, now this check happens in the parser.</li>
<li>Add new error in the lexer to check if a Unicode escape sequence has a <code>{</code> and <code>}</code></li>
<li>The following <code>LexicalErrorType</code> were moved to <code>ParseErrorType</code>:<ul>
<li><code>PositionalArgumentError</code></li>
<li><code>UnpackedArgumentError</code></li>
<li><code>DuplicateArgumentError</code></li>
<li><code>DuplicateKeywordArgumentError</code></li>
<li><code>AssignmentError</code></li>
</ul>
</li>
</ul>
<p>A couple of errors checks that are found during the parse phase were being checked in the lexing phase, now these error checks are in the parser code. For example, the lexer used to check if the <code>(</code>, <code>[</code> or <code>{</code> had its closing counterpart.</p>
Linter
<p>~~The changes made in the linter code are mostly due to the type of <code>Identifier</code> changing  from <code>String</code> to <code>SmolStr</code>.~~</p>
Formatter
<p>The changes made in the formatter code are to handle the new <code>Invalid</code> nodes, the way I chose to handle these nodes in the fromatter was by just displaying the text as it was written in the source code.</p>
Misc
<p>The <code>StringType</code> is a helper type used when parsing string/f-string literals. Since the parser now handles invalid syntax, we need a way to represent an invalid string/f-string when parsing string/f-string literals. So we add the <code>Invalid</code> type to deal with that.</p>
<p>Here&#x27;s how the parser handles invalid strings:</p>
<p>For a single invalid string literal, e.g., a string with invalid escape sequence <code>&quot;a \xxx&quot;</code>, the resulting AST node for that will be an <code>Expr::Invalid</code>. The current implementation for string literal parsing has one limitation when it comes to implicit  concatenated strings. We can&#x27;t know yet which specific string within the implicit concatenated strings are invalid. That is, the resulting AST node won&#x27;t have an <code>Invalid</code> node for the invalid string literal.</p>
<p>Fixes #8914</p>
Test Plan
<p>Tested with <code>cargo test --lib</code>.
The previous parser tests were moved to the <code>ruff_python_parser/src/parser/tests</code>.
I also added more tests in <code>ruff_python_parser/src/parser/tests/parser.rs</code></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/codspeed-hq[bot]">@codspeed-hq[bot]</a> on 2023-12-15 22:07</div>
            <div class="timeline-body"><a href="https://codspeed.io/astral-sh/ruff/branches/LaBatata101:new-parser">CodSpeed Performance Report</a>
Merging #9152 will <strong>degrade performances by 6.04%</strong>
<p>Comparing <code>LaBatata101:new-parser</code> (f8e577d) with <code>main</code> (fe79798)</p>
Summary
<p><code>‚ùå 3</code> regressions
<code>‚úÖ 27</code> untouched benchmarks</p>
<blockquote>
<p>:warning: <em>Please fix the performance issues or <a href="https://codspeed.io/astral-sh/ruff/branches/LaBatata101:new-parser">acknowledge them on CodSpeed</a>.</em></p>
</blockquote>
Benchmarks breakdown
<p>|     | Benchmark | <code>main</code> | <code>LaBatata101:new-parser</code> | Change |
| --- | --------- | ----------------------- | ------------------- | ------ |
| ‚ùå | <code>parser[large/dataset.py]</code> | 63.6 ms | 67.5 ms | -5.81% |
| ‚ùå | <code>parser[numpy/ctypeslib.py]</code> | 10.8 ms | 11.5 ms | -6.04% |
| ‚ùå | <code>parser[unicode/pypinyin.py]</code> | 3.8 ms | 3.9 ms | -4.7% |</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/functions.rs</code>:1 on 2023-12-15 22:49</div>
            <div class="timeline-body"><p>This file needs a better name</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2023-12-15 22:49</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> reviewed on 2023-12-16 00:35</div>
            <div class="timeline-body"><p>I&#x27;m really excited to see this. Thanks for all the work that went into it!</p>
<p>I haven&#x27;t reviewed yet, but one clarifying question:</p>
<blockquote>
<p>The new parser still preserves the old behavior of returning only the first syntax error it encounters. The Python syntax supported by the parser is of the version 3.12.</p>
</blockquote>
<p>Do we attempt to lint after encountering a syntax error? Or do we bail (as on <code>main</code>)?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> reviewed on 2023-12-16 00:42</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on <code>crates/ruff_linter/src/rules/flake8_gettext/mod.rs</code>:10 on 2023-12-16 00:42</div>
            <div class="timeline-body"><p>We should either change our settings types to use <code>SmolStr</code> or (less work) use iterations to avoid these allocations:</p>
<pre><code>functions_names
    .iter()
    .any(|function_name| function_name == id)
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">parser</span> added by <a href="https://github.com/dhruvmanila">@dhruvmanila</a> on 2023-12-16 01:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">performance</span> added by <a href="https://github.com/dhruvmanila">@dhruvmanila</a> on 2023-12-16 01:09</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2023-12-16 01:32</div>
            <div class="timeline-body"><blockquote>
<p>I&#x27;m really excited to see this. Thanks for all the work that went into it!</p>
<p>I haven&#x27;t reviewed yet, but one clarifying question:</p>
<blockquote>
<p>The new parser still preserves the old behavior of returning only the first syntax error it encounters. The Python syntax supported by the parser is of the version 3.12.</p>
</blockquote>
<p>Do we attempt to lint after encountering a syntax error? Or do we bail (as on <code>main</code>)?</p>
</blockquote>
<p>I think we could lint after encountering syntax errors but I have no idea how to do that at the moment.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> reviewed on 2023-12-16 15:49</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on <code>crates/ruff_python_parser/src/lexer.rs</code>:245 on 2023-12-16 15:49</div>
            <div class="timeline-body"><p>How much work would it be, in your opinion, to separate the <code>SmolStr</code> changes out to a separate PR, with this PR as the upstream? It feels like they&#x27;re slightly independent from the changes to the parser and error recovery etc., and so separating them out would make it easier to merge this PR and the <code>SmolStr</code> PR (since they can be reviewed and considered independently), and easier to understand the impact of the <code>SmolStr</code> change.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/lexer.rs</code>:245 on 2023-12-16 16:51</div>
            <div class="timeline-body"><p>Probably won&#x27;t be much work, most of the changes related to <code>SmolStr</code> are in one commit.</p>
<p>I just need to learn how to do that, any help would appreciated.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2023-12-16 16:51</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/zanieb">@zanieb</a> reviewed on 2023-12-16 17:46</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/zanieb">@zanieb</a> on <code>crates/ruff_python_parser/src/lexer.rs</code>:245 on 2023-12-16 17:46</div>
            <div class="timeline-body"><p>You can <code>git rebase -i main</code> then just &quot;drop&quot; that commit, noting its hash. Then you can create a new branch from your parser branch, and <code>git cherry-pick &lt;commit&gt;</code> the commit onto it. You can then open a pull request from that branch with your parser branch as the &quot;base&quot;.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on <code>crates/ruff_python_parser/src/lexer.rs</code>:245 on 2023-12-16 18:01</div>
            <div class="timeline-body"><p>@zanieb - the problem with this suggestion (not sure if you have ideas‚Ä¶) is that I don‚Äôt believe @LaBatata101 will be able to create a PR on Ruff that uses this current PR as a branch, since this branch isn‚Äôt in Ruff, it‚Äôs in a fork.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> reviewed on 2023-12-16 18:01</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/zanieb">@zanieb</a> reviewed on 2023-12-16 19:28</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/zanieb">@zanieb</a> on <code>crates/ruff_python_parser/src/lexer.rs</code>:245 on 2023-12-16 19:28</div>
            <div class="timeline-body"><p>Ah true. You can create a second pull request with <code>main</code> as the base and it&#x27;ll just duplicate all of the changes from here until this is merged (but we can review the single commit), or you can just wait until this is merged to open the second pull request, or you can open it over on your fork and link to it if you want feedback sooner ü§∑‚Äç‚ôÄÔ∏è</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2023-12-18 02:38</div>
            <div class="timeline-body"><p>This PR is fantastic! So many users will be surprised that Ruff will get even faster for them, and not just a little! And I can&#x27;t wait to remove the complexity of the generated parser by some simple Rust code (where changing a single grammar rule doesn&#x27;t change 10k lines ü§£ )</p>
<blockquote>
<p>Here&#x27;s the benchmark results, runned on an Intel Core i5-8265U.</p>
</blockquote>
<p>I&#x27;m confused by the results because they indicate that the new parser is slower, but codspeed suggests otherwise. Could you rerun them?</p>
<p>It will take me a while to get through reviewing 60k changes üòÜ and I have to finish some work this week to avoid losing context before my Christmas/New Year break. I plan to do an in-depth review in the week of the 8th of January. I hope that&#x27;s okay with you.</p>
<p>An important decision we have to make is how we plan to roll out this change because changing the parser changes the foundation of Ruff. Bugs can have far-reaching consequences, from Ruff panicking during formatting / linting to silently changing the program semantics and making Ruff useless in the worst case (because it consistently crashes).</p>
<p>Our ecosystem checks and tests give us good coverage for valid programs. But we have little coverage for invalid programs, to which Ruff is exposed when used inside an Editor (and error recovery in parsers is hard). That&#x27;s why it&#x27;s worth considering how we can increase our test coverage before enabling this parser in production (not the same as merging PRs). Here are some options that I&#x27;ve been thinking about:</p>
<ol>
<li>Enable the new parser when running Ruff with <code>--preview</code> before switching the default</li>
<li>Use fuzzing and compare the parser/linter/ formatter output between Ruff using the generated and hand-written parser. @addisoncrump or @qarmin might be able to help us with setting up fuzzing. They have done excellent fuzzing work in the past.</li>
<li>Run Ruff over a more extensive set of repositories (by extending the ecosystem check and running it locally). However, this will only help a little with invalid syntax because users rarely commit invalid files.</li>
</ol>
<p>Implementing one or two requires we find a way to switch the parser at runtime. Changing the parser at runtime requires that both parsers are API compatible: they use the same AST, the same or at least similar error recovery, etc. We can either refact our current parser to <code>SmolStr</code> OR change your parser to emit <code>String</code>s for now and later change it to <code>SmolStr</code> everywhere. Implementing error recovery in our existing parser doesn&#x27;t make sense. But, we can pretend that your new parser doesn&#x27;t support error recovery by returning an <code>Err</code> if the parser emits any diagnostic.</p>
<p>We can figure out how to best test the parser together and how we can come up with a compatible API, but I&#x27;m happy to defer to you because you probably know it the best.</p>
Invalid syntax representation
<p>I haven&#x27;t studied it in detail, but it seems that your AST design uses <code>Invalid</code> nodes when encountering invalid syntax, similar to what Biome / Swift, and, to some extent, Roslyn do. I would like to learn more about what alternatives you considered and why you decided on this design (and the granularity of invalid nodes) vs. creating missing placeholder nodes or other designs.</p>
Linting / Formatting programs containing invalid syntax
<p>For now, I think it might be best to opt out of linting and formatting invalid ASTs to reduce the scope of this PR and get time to think through the implications thoroughly.</p>
<p>For example, returning the unformatted code for an invalid expression may remove the parentheses of an expression or lead to invalid syntax if the parent formatting rule assumes how the child gets formatted. What worked well for Biome is to return an <code>Err(FormatError::InvalidSyntax)</code> for invalid nodes that aren&#x27;t statements.</p>
Thanks
<p>Thanks again for working on this. I&#x27;m thrilled by the changes and want to see this happening. Let&#x27;s figure out together how to roll this change out and then enjoy how our users will be stunned that Ruff just got significantely faster!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to <a href="https://github.com/MichaReiser">@MichaReiser</a> by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2023-12-18 03:03</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/addisoncrump">@addisoncrump</a> on 2023-12-18 13:49</div>
            <div class="timeline-body"><p>Yup, setting up a differential fuzzer here should be straightforward. @LaBatata101, should I PR this to your fork?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/qarmin">@qarmin</a> on 2023-12-18 16:08</div>
            <div class="timeline-body"><p><a href="https://github.com/astral-sh/ruff/files/13705891/623.py.zip">623.py.zip</a> - eats all available memory with <code>ruff . --select ALL --no-cache</code></p>
<p>https://github.com/qarmin/Automated-Fuzzer/releases/download/test/FILES_999.zip - contains &quot;small&quot; python files set, that crashes in multiple ways with same command as above</p>
<pre><code>panicked at crates/ruff_python_parser/src/parser/mod.rs:3167:20:
called `Option::unwrap()` on a `None` value
Backtrace:    0: ruff_cli::panic::catch_unwind::{{closure}}
   1: &lt;alloc::boxed::Box&lt;F,A&gt; as core::ops::function::Fn&lt;Args&gt;&gt;::call
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/alloc/src/boxed.rs:2021:9
   2: std::panicking::rust_panic_with_hook
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/panicking.rs:735:13
   3: std::panicking::begin_panic_handler::{{closure}}
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/panicking.rs:601:13
   4: std::sys_common::backtrace::__rust_end_short_backtrace
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/sys_common/backtrace.rs:170:18
   5: rust_begin_unwind
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/panicking.rs:597:5
   6: core::panicking::panic_fmt
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/core/src/panicking.rs:72:14
   7: core::panicking::panic
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/core/src/panicking.rs:127:5
   8: ruff_python_parser::parser::Parser&lt;I&gt;::parse_slice
   9: ruff_python_parser::parser::Parser&lt;I&gt;::parse_lhs
  10: ruff_python_parser::parser::Parser&lt;I&gt;::expr_bp
</code></pre>
<pre><code>panicked at crates/ruff_python_parser/src/parser/mod.rs:564:9:
assertion failed: self.eat(TokenKind::Dedent)
Backtrace:    0: ruff_cli::panic::catch_unwind::{{closure}}
   1: &lt;alloc::boxed::Box&lt;F,A&gt; as core::ops::function::Fn&lt;Args&gt;&gt;::call
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/alloc/src/boxed.rs:2021:9
   2: std::panicking::rust_panic_with_hook
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/panicking.rs:735:13
   3: std::panicking::begin_panic_handler::{{closure}}
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/panicking.rs:601:13
   4: std::sys_common::backtrace::__rust_end_short_backtrace
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/sys_common/backtrace.rs:170:18
   5: rust_begin_unwind
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/std/src/panicking.rs:597:5
   6: core::panicking::panic_fmt
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/core/src/panicking.rs:72:14
   7: core::panicking::panic
             at /rustc/a28077b28a02b92985b3a3faecf92813155f1ea1/library/core/src/panicking.rs:127:5
   8: ruff_python_parser::parser::Parser&lt;I&gt;::handle_unexpected_indentation
   9: ruff_python_parser::parser::functions::parse_tokens
  10: ruff_python_parser::parser::functions::parse_program
  11: ruff_linter::rules::eradicate::detection::comment_contains_code
  12: ruff_linter::rules::eradicate::rules::commented_out_code::commented_out_code
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2023-12-18 16:35</div>
            <div class="timeline-body"><blockquote>
<p>Yup, setting up a differential fuzzer here should be straightforward. @LaBatata101, should I PR this to your fork?</p>
</blockquote>
<p>Yes, that would be nice!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/addisoncrump">@addisoncrump</a> on 2023-12-18 16:38</div>
            <div class="timeline-body"><p>Great. I&#x27;ll set this up sometime in the coming days, it&#x27;s quite late to start today. Definitely use the existing fuzzers, both mine and @qarmin&#x27;s, as they find different kinds of problems. lmk if you need any guidance here, but the README should tell you what you need to know.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2023-12-18 17:06</div>
            <div class="timeline-body"><p>I&#x27;m a big fan of toggling use of the new parser with <code>--preview</code> if feasible. It seems like it may be challenging? Although easier if the <code>SmolString</code> changes are split out.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2023-12-18 23:54</div>
            <div class="timeline-body"><blockquote>
<p>I&#x27;m confused by the results because they indicate that the new parser is slower, but codspeed suggests otherwise. Could you rerun them?</p>
</blockquote>
<p>I realized that my computer it&#x27;s not very reliable for benchmarks, every time I run I get a 2~4% difference in the results. I guess my old HDD is the culprit, sometimes my computer gets randomly slower. So it&#x27;s for one of you guys to run the benchmark and see if the result matches.</p>
<blockquote>
<p>It will take me a while to get through reviewing 60k changes üòÜ and I have to finish some work this week to avoid losing context before my Christmas/New Year break.</p>
</blockquote>
<p>Most of those 60k changes are from snapshot files.</p>
<blockquote>
<p>I plan to do an in-depth review in the week of the 8th of January. I hope that&#x27;s okay with you.</p>
</blockquote>
<p>No problem.</p>
<blockquote>
<p>We can either refact our current parser to SmolStr OR change your parser to emit Strings for now and later change it to SmolStr everywhere.
I&#x27;m currently working on a PR to change the current parser to use <code>SmolStr</code></p>
</blockquote>
<blockquote>
<p>I haven&#x27;t studied it in detail, but it seems that your AST design uses Invalid nodes when encountering invalid syntax, similar to what Biome / Swift, and, to some extent, Roslyn do. I would like to learn more about what alternatives you considered and why you decided on this design (and the granularity of invalid nodes) vs. creating missing placeholder nodes or other designs.</p>
</blockquote>
<p>I didn&#x27;t research this very deeply, but from what I found, there were two ways to do that, use an <code>Invalid</code> node and making every field of the AST node an <code>Option</code>. Using <code>Option</code> for every field of the node, creates two problems. The first problem is, we can&#x27;t distinguish when a field of the node is actually optional or its an invalid syntax. The second one is, I would have to change basically the entire code base to support this üòÜ. So I went with the <code>Invalid</code> node strategy, which felt more natural and ergonomic.
The only exception to this is the <code>Identifier</code>, where I consider an identifier as invalid if it has an empty string in the <code>id</code> field. So if I have some code like this:</p>
<pre><code>def 1(): ...
</code></pre>
<p>where we have a <code>Number</code> token instead of an <code>Id</code> token. The AST will look like this:</p>
<pre><code>Module(
    ModModule {
        range: 0..13,
        body: [
            FunctionDef(
                StmtFunctionDef {
                    range: 1..13,
                    is_async: false,
                    decorator_list: [],
                    name: Identifier {
                        id: &quot;&quot;,
                        range: 5..6,
                    },
                    type_params: None,
                    parameters: Parameters {
                        ...
                    },
                    returns: None,
                    body: [
                        ...
                    ],
                },
            ),
        ],
    },
)
</code></pre>
<p>In the <code>Identifier</code> struct, there&#x27;s a function called <code>is_valid</code> that checks if <code>id</code> is empty. Probably, not the best way to represent invalid syntax in this situation.</p>
<p>Another limitation, in the current implementation, is in implicit concatenated f-strings with strings, where an <code>Invalid</code> node isn&#x27;t created when one of the strings is invalid. For example, <code>f&quot;hello&quot; &quot;\xxx&quot; f&quot;world&quot;</code>, the second string has an invalid escape sequence, resulting in the following AST</p>
<pre><code>Module(
        ModModule {
            range: 0..26,
            body: [
                Expr(
                    StmtExpr {
                        range: 1..25,
                        value: FString(
                            ExprFString {
                                range: 1..25,
                                value: FStringValue {
                                    inner: Concatenated(
                                        [
                                            FString(
                                                FString {
                                                    range: 1..9,
                                                    elements: [
                                                        Literal(
                                                            FStringLiteralElement {
                                                                range: 3..8,
                                                                value: &quot;hello&quot;,
                                                            },
                                                        ),
                                                    ],
                                                },
                                            ),
                                            FString(
                                                FString {
                                                    range: 17..25,
                                                    elements: [
                                                        Literal(
                                                            FStringLiteralElement {
                                                                range: 19..24,
                                                                value: &quot;world&quot;,
                                                            },
                                                        ),
                                                    ],
                                                },
                                            ),
                                        ],
                                    ),
                                },
                            },
                        ),
                    },
                ),
            ],
        },
    ),
</code></pre>
<p>What do you mean by &quot;granularity of invalid nodes&quot;?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2023-12-19 08:35</div>
            <div class="timeline-body"><blockquote>
<p>I realized that my computer it&#x27;s not very reliable for benchmarks, every time I run I get a 2~4% difference in the results. I guess my old HDD is the culprit, sometimes my computer gets randomly slower. So it&#x27;s for one of you guys to run the benchmark and see if the result matches.</p>
</blockquote>
<p>That&#x27;s okay. The codspeed benchmarks are probably good enough. I recommend removing the results from the PR summary to avoid confusion.</p>
<blockquote>
<p>Most of those 60k changes are from snapshot files.</p>
</blockquote>
<p>That&#x27;s good to know. And most of the deleted 80k is the generated parser :)</p>
<blockquote>
<p>I didn&#x27;t research this very deeply, but from what I found, there were two ways to do that, use an Invalid node and making every field of the AST node an Option....</p>
</blockquote>
<p>That sounds reasonable and we don&#x27;t need to finalize the representation of invalid programs as part of this PR. This is something we can iterate on later. I just find it useful to understand the motiviation. I believe TypeScript uses a third option that I&#x27;m somewhat interested (in the Future) that avoids Invalid nodes. TypeScript&#x27;s recovery (from what I understand) synthesizes nodes where necessary: For example, it creates an empty identifier node if the right side of a binary expression is missing <code>a + </code> gets parsed as <code>ident(a)</code> <code>+</code> <code>ident(&quot;&quot;)</code>. I haven&#x27;t looked into how it handles invalid tokens but I believe it simply terminates the previous statement, fills missing places with synthesized nodes, and starts a new statement that contains as much as it understands. But again, that&#x27;s something we can explore later. Is this something you would be interested in?</p>
<blockquote>
<p>What do you mean by &quot;granularity of invalid nodes&quot;?</p>
</blockquote>
<p>There are multiple invalid nodes. I think I saw invalid nodes for statements and expressions. Maybe there are more. How did you decide on which &quot;invalid&quot; nodes to add?</p>
<p>@LaBatata101 how much work do you think it would be to make the parser switchable at runtime and is this something you&#x27;re interested in working on? It would help us with shipping the new parser incrementally (local Debug builds first, --preview only, switch over production) for a smooth release.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2023-12-20 22:16</div>
            <div class="timeline-body"><blockquote>
<p>That sounds reasonable and we don&#x27;t need to finalize the representation of invalid programs as part of this PR. This is something we can iterate on later. I just find it useful to understand the motiviation... But again, that&#x27;s something we can explore later. Is this something you would be interested in?</p>
</blockquote>
<p>Yes!</p>
<blockquote>
<p>There are multiple invalid nodes. I think I saw invalid nodes for statements and expressions. Maybe there are more. How did you decide on which &quot;invalid&quot; nodes to add?</p>
</blockquote>
<p>The current invalid nodes the AST has are for <code>Expression</code>, <code>Pattern</code> and <code>FStringElement</code>. The reason for having <code>Invalid</code> nodes in those types are similar, because in the current implementation of the parser, the functions used to parse them always needs to return the one of those types. So when encountering an unexpected token or when the lexer returns an <code>Err</code> (which gets transformed into a <code>TokenKind::Invalid</code> or <code>Tok::Invalid</code>) during the parsing, I use the <code>Invalid</code> node to handle these situations.</p>
<p>So the current presence of <code>Invalid</code> nodes is due to the way I implemented the parser, which requires that parsing functions for AST nodes always return the corresponding node type, regardless of what happens.</p>
<blockquote>
<p>how much work do you think it would be to make the parser switchable at runtime and is this something you&#x27;re interested in working on? It would help us with shipping the new parser incrementally (local Debug builds first, --preview only, switch over production) for a smooth release.</p>
</blockquote>
<p>Honestly, I don&#x27;t know how much work that would be, but I can try it anyway.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2023-12-20 22:37</div>
            <div class="timeline-body"><p>@LaBatata101</p>
<blockquote>
<p>Honestly, I don&#x27;t know how much work that would be, but I can try it anyway.</p>
</blockquote>
<p>You may want to hold off on that for a minute we&#x27;re discussing internally if we want to support two parsers or just switch over with lots of manual testing.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2023-12-20 22:55</div>
            <div class="timeline-body"><blockquote>
<p>You may want to hold off on that for a minute we&#x27;re discussing internally if we want to support two parsers or just switch over with lots of manual testing.</p>
</blockquote>
<p>Ok, I was only going to try that after fixing the bugs found by the fuzzer which should take a while.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/addisoncrump">@addisoncrump</a> on 2023-12-31 00:42</div>
            <div class="timeline-body"><p>I&#x27;ve just implemented the fuzzer for equivalency between the new and the old parsers. To a degree, it might be a good thing to keep both implementations around and maintained after this is merged since the fuzzer will effectively instantly find discrepancies in future optimisations or updates.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/github-actions[bot]">@github-actions[bot]</a> on 2024-01-03 21:16</div>
            <div class="timeline-body">

<code>ruff-ecosystem</code> results
Linter (stable)
<p>‚úÖ ecosystem check detected no linter changes.</p>
Linter (preview)
<p>‚úÖ ecosystem check detected no linter changes.</p>
Formatter (stable)
<p>‚úÖ ecosystem check detected no format changes.</p>
Formatter (preview)
<p>‚úÖ ecosystem check detected no format changes.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:233 on 2024-01-08 09:47</div>
            <div class="timeline-body"><p>What&#x27;s the reason for returning an empty range in this case. It seems inconsistent to me that the non empty case includes the range of comments but the &quot;empty&quot; module does not.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:250 on 2024-01-08 09:48</div>
            <div class="timeline-body"><p>Nit. I prefer to use <code>assert_eq!(&amp;self.ctx, &amp;[])</code> and <code>assert_eq!(&amp;self.ctx_stack, &amp;[])</code> because it generates more helpful error messages in case the context isn&#x27;t empty (it shows its content)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:270 on 2024-01-08 09:50</div>
            <div class="timeline-body"><p>What happens if <code>self.ctx_stack</code> is empty. Aren&#x27;t we risking that <code>self.ctx</code> than points to a stale value?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:309 on 2024-01-08 09:52</div>
            <div class="timeline-body"><p>Nit:</p>
<pre><code>                    self.source.text_len(),
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:314 on 2024-01-08 09:53</div>
            <div class="timeline-body"><p>How much lookahead does the parser require? It might be worth to limit the allowed lookahead to only a few tokens or even having explicit lookahead methods. It can sometimes be tempting to use a larger lookahead even when it isn&#x27;t strictly necessary. Limiting the lookahead can push us to re-consider if we can implement the same without requiring as much lookahead (e.g by adding an explicit assertion that the lookahead is never larger than <code>n</code>)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:421 on 2024-01-08 09:56</div>
            <div class="timeline-body"><p>Does this <code>TODO</code> still need to be addressed?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:429 on 2024-01-08 09:57</div>
            <div class="timeline-body"><pre><code>                self.source.text_len() - TextSize::new(1));
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:416 on 2024-01-08 09:58</div>
            <div class="timeline-body"><p>Would it be an option to instead &quot;patch&quot; the range in <code>parse_expression_starts_at</code> or what&#x27;s the reason that this function is called with out of bound offsets?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:459 on 2024-01-08 10:00</div>
            <div class="timeline-body"><p>This feels a bit suspicious (something that <code>parse_separated</code> doesn&#x27;t know). Would it be worth changing <code>func</code> (the parsing function?) to return the <code>TextRange</code> of the last parsed item instead?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:527 on 2024-01-08 10:02</div>
            <div class="timeline-body"><p>What happens if the <code>Dedent</code> token is missing. Will this result in an infinite loop?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/functions.rs</code>:1 on 2024-01-08 10:04</div>
            <div class="timeline-body"><p>I think we should move the functions in here into the <code>lib.rs</code>, considering that they are the public interface of the parser crate.</p>
<p>I would move the <code>parse_ok_tokens_lalrpop</code> and <code>parse_ok_tokens_new</code> into their corresponding modules <code>parser/mod.rs</code> and <code>lalrpop/mod.rs</code></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/functions.rs</code>:344 on 2024-01-08 10:06</div>
            <div class="timeline-body"><p>I recommend moving <code>ParenthesizedExpr</code> into the <code>lalrpop</code> module and making it private (it&#x27;s not a public type)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/addisoncrump">@addisoncrump</a> on 2024-01-08 11:10</div>
            <div class="timeline-body"><p>@MichaReiser, I&#x27;m quite confident the differential fuzzer depends on <code>parse_ok_tokens_{lalrpop,new}</code> being public. Can we somehow conditionally make these publically available?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2024-01-08 12:41</div>
            <div class="timeline-body"><blockquote>
<p>@MichaReiser, I&#x27;m quite confident the differential fuzzer depends on <code>parse_ok_tokens_{lalrpop,new}</code> being public. Can we somehow conditionally make these publically available?</p>
</blockquote>
<p>Oh I see. Do you know if the fuzzer runs concurrently? We could otherwise simply use the environment variable to toggle between the two implementations.</p>
<p>Another idea for fuzzing (I recommend implementing this as a separate PR) would be to compare the linter and formatter results (mainly for files that have no syntax errors). This ensures that the new parser works well with the tool based on it (may help to identify potential issues due to the parser generating different ranges for the same nodes)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/addisoncrump">@addisoncrump</a> on 2024-01-08 13:40</div>
            <div class="timeline-body"><p>Oh, yikes, do you not intend to use the same parsers for formatters and linters?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/addisoncrump">@addisoncrump</a> on 2024-01-08 14:02</div>
            <div class="timeline-body"><p>Okay, I reread your message :joy: I understand now.</p>
<p>Regarding setting the environmental variable: I&#x27;ll admit, this rubs me the wrong way. Why does an internal function check the environment? This is a code smell; this should be checked earlier and passed as a configuration value, no? It is doable for now to implement it like so.</p>
<p>A fuzzer comparing the linter and formatter results would find a strict subset of the issues of the current differential fuzzer. If your concern is purely functional, we can replace the existing differential fuzzer with the one you are describing.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2024-01-08 14:35</div>
            <div class="timeline-body"><blockquote>
<p>Regarding setting the environmental variable: I&#x27;ll admit, this rubs me the wrong way. Why does an internal function check the environment? This is a code smell; this should be checked earlier and passed as a configuration value, no? It is doable for now to implement it like so.</p>
</blockquote>
<p>I share that sentiment that it should be an option if we want to support two different parsers in the long term. I think doing it here is fine because this isn&#x27;t our goal. We only allow switching to evaluate the new parser. The old parser will be removed as soon as we do the switch over. In that sense, adding a public option to define the parser would prevent us from removing the old parser later without a breaking API (not that we care, since the parser crate is internal).</p>
<blockquote>
<p>A fuzzer comparing the linter and formatter results would find a strict subset of the issues of the current differential fuzzer. If your concern is purely functional, we can replace the existing differential fuzzer with the one you are describing.</p>
</blockquote>
<p>I think having both fuzzers is useful:</p>
<ul>
<li>Parser: Compares both valid and invalid programs. Easier to narrow down the issue because it is scoped to the parser.</li>
<li>Formatter / Linter: Main focus on valid programs. Identifies compatibility issues with the formatter/linter code.</li>
</ul>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_codegen/src/generator.rs</code>:1196 on 2024-01-08 14:59</div>
            <div class="timeline-body"><p>I wonder if it is possible that simply printing a program that contains syntax errors produces new syntax errors. For example, let&#x27;s say we had</p>
<pre><code>a = (4 + 
    4ident ===
    bcd
)
</code></pre>
<p>The <code>4identifier</code> is not a valid identifier and neither is the <code>===</code> operator. Now, what I fear is that we&#x27;ll reprint this as</p>
<pre><code>a = 4 + 4ident ===
    bcd
</code></pre>
<p>which now parses as two statements because the source code generator (as far as I remember) doesn&#x27;t retain parentheses.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/tests/function.rs</code>:17 on 2024-01-08 15:27</div>
            <div class="timeline-body"><p>I try to avoid macros for test generation (okay, not true, I try to avoid macros in general, it&#x27;s a last resort option in my view) because they make tests harder to read and they don&#x27;t work well with IDEs and other dev tools (e.g. jumping to the failing test doesn&#x27;t work).</p>
<p>Not using macros will require some more boilerblate but that&#x27;s a worth trade in my view, considering that it makes the tests more familiar to readers</p>
<pre><code>
fn parse_program(code: &amp;str) -&gt; Result&lt;Suite, ParseError&gt; {
    crate::parser::parse_suite(code)
}

#[test]
fn test_function_no_args_with_ranges() {
    let parsed = parse_program(&quot;def f(): pass&quot;)
    assert_debug_snapshot!(parsed)
}
</code></pre>
<p>The <code>parse_program</code> helper function is probably overkill. But a utility function can be helpful in case we need to perform more setup logic (to avoid code duplication)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/tests/function.rs</code>:47 on 2024-01-08 15:28</div>
            <div class="timeline-body"><p>Same here. I don&#x27;t think the added complexity of using a macro justifies the briefer syntax.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2024-01-08 15:41</div>
            <div class="timeline-body"><p>This is some preliminary feedback. I haven&#x27;t read through all the code yet.</p>
<p>Overall I&#x27;m very impressed by the changes and this goes into the direction I want our parser to go.</p>
<p>My main concern right now is the representation of invalid syntax and how downstream dependencies handle it. For example, I&#x27;m not sure if parsing a program and printing it with our code generator results in the same code (and doesn&#x27;t introduce new or different syntax errors). I don&#x27;t know yet what the solution for this is.</p>
<p>I&#x27;ve a few notes but these are things we can address after merging.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 16:24</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/tests/function.rs</code>:17 on 2024-01-08 16:24</div>
            <div class="timeline-body"><p>Good point, those macros in the tests were already there, I will remove them.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 16:40</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:314 on 2024-01-08 16:40</div>
            <div class="timeline-body"><p>At the moment, there&#x27;s no way of knowing how much lookahead we need because of <a href="https://github.com/astral-sh/ruff/blob/d4a4d056bc4db660500a89a3486ac5f7bf98dd50/crates/ruff_python_parser/src/parser/mod.rs#L1709">this</a> problem when parsing <code>WithItem</code>, but ideally it should be 1. I&#x27;m going to look how pyright handles this case.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 16:47</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:233 on 2024-01-08 16:47</div>
            <div class="timeline-body"><p>I don&#x27;t really know the reason why it is an empty range, the autogenerated parser does that so I just copied the behavior. Originally, the parser included the range of the comments and empty lines in the module.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 21:45</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:527 on 2024-01-08 21:45</div>
            <div class="timeline-body"><p>IIRC the lexer always creates a <code>Dedent</code> token for an <code>Indent</code> token, unless there&#x27;s a bug in the lexer, so an infinite loop is impossible. But I can add check for the <code>Eof</code> token just to make sure.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 22:10</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_codegen/src/generator.rs</code>:1196 on 2024-01-08 22:10</div>
            <div class="timeline-body"><p>For this case, the resulting AST will be</p>
<pre><code>Module(
        ModModule {
            range: 0..43,
            body: [
                Assign(
                    StmtAssign {
                        range: 1..20,
                        targets: [
                            Name(
                                ExprName {
                                    range: 1..2,
                                    id: &quot;a&quot;,
                                    ctx: Store,
                                },
                            ),
                        ],
                        value: BinOp(
                            ExprBinOp {
                                range: 6..15,
                                left: NumberLiteral(
                                    ExprNumberLiteral {
                                        range: 6..7,
                                        value: Int(
                                            4,
                                        ),
                                    },
                                ),
                                op: Add,
                                right: NumberLiteral(
                                    ExprNumberLiteral {
                                        range: 14..15,
                                        value: Int(
                                            4,
                                        ),
                                    },
                                ),
                            },
                        ),
                    },
                ),
            ],
        },
    ),
</code></pre>
<p>Notice that only the binary operation appears, this is due to when parsing a parenthesized expression (or an expression inside <code>[]</code>, <code>{}</code>)  with unexpected tokens, in this case it would be <code>ident</code> (<code>4ident</code> is lexed as two different tokens), <code>===</code> and <code>bcd</code>, the parser will skip these tokens in an attempt to find the <code>)</code>. So the reprint it&#x27;s probably even worse ü§£, because it&#x27;ll generate this  <code>a = 4 + 4</code>.</p>
<p>The error message needs improvement for this case, because it doesn&#x27;t create <code>unexpected token</code> error messages, it only creates the <code>expecting &quot;)&quot;, found &quot;ident&quot;</code> error message.</p>
<p>Shouldn&#x27;t we use a CST for the code generator? An AST doesn&#x27;t seem very reliable to generate code as it was written.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2024-01-08 22:12</div>
            <div class="timeline-body"><p>Why the performance regressed ü§î</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 22:38</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:270 on 2024-01-08 22:38</div>
            <div class="timeline-body"><p><code>self.ctx_stack</code> will only be empty at the end of the parsing, if it&#x27;s empty during the parsing, <code>self.set_ctx</code> or <code>self.clear_ctx</code> got misused somehow. To avoid this, I think we need to add an <code>assert!(!self.ctx_stack.is_empty())</code> in <code>self.clear_ctx</code>.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 22:50</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:459 on 2024-01-08 22:50</div>
            <div class="timeline-body"><p>Do you mean the empty range that is returned?</p>
<p>It&#x27;s not worth changing <code>func</code> to return a <code>TextRange</code> because, we don&#x27;t need the range created by <code>parse_separated</code> since we only care about the range of the delimiters, e.g., <code>()</code>, <code>[]</code> etc.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 23:01</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:421 on 2024-01-08 23:01</div>
            <div class="timeline-body"><p>Yes, there&#x27;s some test (I don&#x27;t remember right now) where the function return type annotation is parsed separately with <code>parse_type_annotation</code>, and there is an unexpected token there. The code is something like this:</p>
<pre><code>def f() -&gt; &quot;int /&quot;:
   pass
</code></pre>
<p>With the current code, the <code>value</code> field of the <code>Invalid</code> node for the unexpected token <code>/</code> will contain the entire source, in this case <code>int /</code>, instead of just <code>/</code>. I&#x27;m not sure how to solve this yet.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-08 23:11</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:416 on 2024-01-08 23:11</div>
            <div class="timeline-body"><p>The main problem is that <code>parse_expression_starts_at</code> passes to the parser a subset of the source code while maintaining the range of the whole source code. If we could pass the entire source code without breaking the behavior of <code>parse_expression_starts_at</code>, it would solve this problem.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-01-08 23:20</div>
            <div class="timeline-body"><p>@LaBatata101 - Have you rebased / merged in main? We upgraded Rust and it had a big impact on lexer / parser perf. So you might just be comparing against the wrong baseline now.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on 2024-01-09 00:43</div>
            <div class="timeline-body"><blockquote>
<p>@LaBatata101 - Have you rebased / merged in main? We upgraded Rust and it had a big impact on lexer / parser perf. So you might just be comparing against the wrong baseline now.</p>
</blockquote>
<p>I haven&#x27;t merged main yet.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2024-01-09 11:20</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:314 on 2024-01-09 11:20</div>
            <div class="timeline-body"><p>Ah interesting. Could we try parsing it as a parenthesized expression if the parser is at a <code>(</code> and and &quot;fix up&quot; the range if there&#x27;s no following <code>as</code> keyword? That would avoid the need for the lookahead. It may require a special <code>parse_parenthesized_expression</code> method that returns the unparenthesized range as well.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2024-01-09 11:24</div>
            <div class="timeline-body"><p>I ran some hyperfine benchmarks (CPython and airflow) and the new parser is between 20 and 30% faster. Which is pretty impressive.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2024-01-09 11:26</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_codegen/src/generator.rs</code>:1196 on 2024-01-09 11:26</div>
            <div class="timeline-body"><p>Hmm that&#x27;s a serious problem. It&#x27;s okay for the parser to skip tokens but these tokens must be attached to the AST. I assumed it would do so by creating an <code>InvalidExpr</code> for the invalid nodes. Let me spend some time today to take a closer look at the parser&#x27;s error recovery.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-09 12:54</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_codegen/src/generator.rs</code>:1196 on 2024-01-09 12:54</div>
            <div class="timeline-body"><p>Probably won&#x27;t be much work to create an <code>InvalidExpr</code> for the skipped tokens.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2024-01-09 12:56</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:71 on 2024-01-09 12:56</div>
            <div class="timeline-body"><p>I think it should be possible to remove most usages of <code>ctx</code> by instead pass the context to the specific parsing function:</p>
<ul>
<li><code>parse_body</code>: Create a <code>Clause</code> enum with variants for each possible clause that can have a body. Add an explicit <code>parent_clause</code> argument to <code>parse_body</code>.</li>
<li><code>parse_paremters</code>: Create a dedicated <code>FunctionKind</code> enum with a variant for <code>Lambda</code> and <code>FunctionDefinition</code>. Explicilty pass the <code>function_kind</code> to <code>parse_parameters</code>.</li>
</ul>
<p>Removing the need for <code>ctx_stack</code> is probably the trickiest but we can do it by using the call-stack by:</p>
<ul>
<li>Copying the existing <code>ctx</code> flags before changing them</li>
<li>Changing the context flags</li>
<li>Call into the sub-parsing</li>
<li>Restoring the context flags afterwards</li>
</ul>
<p>I don&#x27;t fully understand <code>last_ctx</code> yet, so there might still be a need for the structure as it is today. But passing contexts explicitly where possible improves readability and helps to remove some variants from the parsing context.</p>
<p>This won&#x27;t give you access to the parent context while parsing, but I wonder if that&#x27;s even necessary. All we need to know is if we&#x27;re inside of a for target. We can keep that context flag set for the entire target expression (and we can explicilty set it back to <code>false</code> if there&#x27;s an expression where it needs to be restored to false).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:71 on 2024-01-09 13:29</div>
            <div class="timeline-body"><p>If I&#x27;m not mistaken, <code>last_ctx</code>is mainly being used to check if the parsed expression was parenthesized.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-09 13:29</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-09 21:57</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:314 on 2024-01-09 21:57</div>
            <div class="timeline-body"><blockquote>
<p>Could we try parsing it as a parenthesized expression if the parser is at a ( and and &quot;fix up&quot; the range if there&#x27;s no following as keyword?</p>
</blockquote>
<p>Wouldn&#x27;t work because if we have something like <code>(a as A, b)</code> and try to parse as a parenthesized expression, this example will be parsed as a tuple, resulting in an invalid syntax because of the <code>as</code> keyword.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2024-01-11 08:39</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:71 on 2024-01-11 08:39</div>
            <div class="timeline-body"><p>I wonder if we could remove <code>last_ctx</code> by changing <code>parse_expr</code> to return a <code>ParsedExpression</code> struct that has two fields:</p>
<ul>
<li>The parsed expression</li>
<li>A boolean field whether the expression was parenthesized</li>
</ul>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-11 12:55</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:71 on 2024-01-11 12:55</div>
            <div class="timeline-body"><p>That might work.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-11 23:25</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:71 on 2024-01-11 23:25</div>
            <div class="timeline-body"><blockquote>
<p>I wonder if we could remove <code>last_ctx</code> by changing <code>parse_expr</code> to return a <code>ParsedExpression</code> struct that has two fields:</p>
<pre><code>* The parsed expression

* A boolean field whether the expression was parenthesized</code></pre>
</blockquote>
<p>To be able to remove <code>last_ctx</code> we need to create another solution for that problem in <code>parse_with_items</code>.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-12 20:58</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:76 on 2024-01-12 20:58</div>
            <div class="timeline-body"><p>Is it possible to treat <code>ParsedExpr</code> as an <code>Expr</code> so that I don&#x27;t have to type <code>.expr</code> every time?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/MichaReiser">@MichaReiser</a> reviewed on 2024-01-13 11:05</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:76 on 2024-01-13 11:05</div>
            <div class="timeline-body"><p>You can implement Deref on <code>ParsedExpr</code></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/LaBatata101">@LaBatata101</a> reviewed on 2024-01-13 13:40</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/LaBatata101">@LaBatata101</a> on <code>crates/ruff_python_parser/src/parser/mod.rs</code>:76 on 2024-01-13 13:40</div>
            <div class="timeline-body"><p>Oh right, forgot about Deref.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to <a href="https://github.com/dhruvmanila">@dhruvmanila</a> by <a href="https://github.com/dhruvmanila">@dhruvmanila</a> on 2024-02-15 07:20</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Unassigned <a href="https://github.com/MichaReiser">@MichaReiser</a> by <a href="https://github.com/dhruvmanila">@dhruvmanila</a> on 2024-02-15 07:20</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/dhruvmanila">@dhruvmanila</a> on 2024-02-19 04:14</div>
            <div class="timeline-body"><p>Closing in favor of #10036. Big thanks to @LaBatata101 for their work on the new parser.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/dhruvmanila">@dhruvmanila</a> on 2024-02-19 04:14</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:00:00 UTC
    </footer>
</body>
</html>
