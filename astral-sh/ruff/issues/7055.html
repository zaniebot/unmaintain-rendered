<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluate Profile-Guided Optimization (PGO) and LLVM BOLT - astral-sh/ruff #7055</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Evaluate Profile-Guided Optimization (PGO) and LLVM BOLT</h1>

    <div class="meta">
        <span class="state state-open">Open</span>
        <a href="https://github.com/astral-sh/ruff/issues/7055">#7055</a>
        opened by <a href="https://github.com/zamazan4ik">@zamazan4ik</a>
        on 2023-09-01 23:29
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Issue opened by <a href="https://github.com/zamazan4ik">@zamazan4ik</a> on 2023-09-01 23:29</div>
            <div class="timeline-body"><p>Hi!</p>
<p>Recently I did a lot of PGO benchmarks on different software - all available results are <a href="https://github.com/zamazan4ik/awesome-pgo">here</a>. According to my tests, PGO can help with achieving better performance in many workloads, including compiler-like (compilers, static analysis, code formatters, etc.). Since Ruff cares about performance, I think it would be a good idea to test PGO on it.</p>
<p>I can suggest to do the following things:</p>
<ul>
<li>Evaluate PGO on Ruff</li>
<li>If it benefits Ruff - add a note to the Ruff documentation about building with PGO. In this case, users and maintainers who build their own Ruff packages will be aware of PGO as an additional way to optimize Ruff</li>
<li>Optimize provided by Ruff team binaries on the CI (like it's already done for other projects like Rustc)</li>
<li>After that, I suggest trying to apply <a href="https://github.com/llvm/llvm-project/blob/main/bolt/README.md">LLVM BOLT</a> as an additional post-PGO step. Rustc already does it on some platforms</li>
</ul>
<p>For the Rust projects, I suggest PGO optimizing with <a href="https://github.com/Kobzol/cargo-pgo">cargo-pgo</a>.</p>
<p>I already tried to optimize Ruff with PGO on my local machines but unfortunately met a bug in Rustc on the LTO and PGO boundary. More details about the bug are available at https://github.com/rust-lang/rust/issues/115344#issuecomment-1703458011 . So I suggest leaving this issue as-is. And later when the bug in the upstream will be fixed, try to apply PGO to Ruff once again.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2023-09-02 11:27</div>
            <div class="timeline-body"><p>Thanks for this. I'm happy to support an evaluation to see if Ruff can benefit from PGO, at which point we can evaluate the tradeoffs of integrating it into our production pipeline. Is there anything we can do on our end to resolve that upstream bug (e.g., changes we can make to Ruff itself)?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">performance</span> added by @charliermarsh on 2023-09-02 11:27</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zamazan4ik">@zamazan4ik</a> on 2023-09-02 12:41</div>
            <div class="timeline-body"><blockquote>
<p>Is there anything we can do on our end to resolve that upstream bug (e.g., changes we can make to Ruff itself)?</p>
</blockquote>
<p>Right now disabling LTO is the only way to avoid the bug. But I do not recommend doing it since LTO provides performance benefits too but with less CI tweaking (enabling one flag with LTO vs implementing 2-stage builds with PGO). So I suggest just waiting for the fix in the upstream and then trying to test LTO + PGO once again.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FilipAndersson245">@FilipAndersson245</a> on 2025-03-02 15:53</div>
            <div class="timeline-body"><p>The fix for LTO + PGO have now been merged so now you could probably test it out on nightly.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FilipAndersson245">@FilipAndersson245</a> on 2025-03-27 21:05</div>
            <div class="timeline-body"><p>I did a run trying to run the existing benchmark suit as intrinsic and optimization using  <code>cargo pgo</code>
The performance numbers are quite shockingly large, so maybe I have done something wrong, them being upwards of <strong>15 - 35 %</strong> faster across the board except regressions in <code>red_knot_check_file[cold]</code> and<code>red_knot_check_file[incremental]</code></p>
<details>

<summary> release vs release + pgo</summary>

<pre><code>formatter/numpy/globals.py
                        time:   [16.068 Âµs 16.094 Âµs 16.123 Âµs]
                        thrpt:  [183.01 MiB/s 183.34 MiB/s 183.64 MiB/s]
                 change:
                        time:   [-27.731% -27.136% -26.566%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+36.177% +37.241% +38.372%]
                        Performance has improved.
Benchmarking formatter/unicode/pypinyin.py
Benchmarking formatter/unicode/pypinyin.py: Warming up for 3.0000 s
Benchmarking formatter/unicode/pypinyin.py: Collecting 100 samples in estimated 5.1385 s (101k iterations)
Benchmarking formatter/unicode/pypinyin.py: Analyzing
formatter/unicode/pypinyin.py
                        time:   [50.687 Âµs 50.829 Âµs 51.016 Âµs]
                        thrpt:  [82.364 MiB/s 82.667 MiB/s 82.899 MiB/s]
                 change:
                        time:   [-37.815% -37.629% -37.438%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+59.841% +60.331% +60.811%]
                        Performance has improved.
Found 11 outliers among 100 measurements (11.00%)
  4 (4.00%) low mild
  2 (2.00%) high mild
  5 (5.00%) high severe
Benchmarking formatter/pydantic/types.py
Benchmarking formatter/pydantic/types.py: Warming up for 3.0000 s
Benchmarking formatter/pydantic/types.py: Collecting 100 samples in estimated 6.0132 s (15k iterations)
Benchmarking formatter/pydantic/types.py: Analyzing
formatter/pydantic/types.py
                        time:   [394.65 Âµs 395.97 Âµs 397.35 Âµs]
                        thrpt:  [64.183 MiB/s 64.407 MiB/s 64.622 MiB/s]
                 change:
                        time:   [-28.378% -27.866% -27.383%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+37.709% +38.630% +39.621%]
                        Performance has improved.
Found 12 outliers among 100 measurements (12.00%)
  2 (2.00%) low mild
  2 (2.00%) high mild
  8 (8.00%) high severe
Benchmarking formatter/numpy/ctypeslib.py
Benchmarking formatter/numpy/ctypeslib.py: Warming up for 3.0000 s
Benchmarking formatter/numpy/ctypeslib.py: Collecting 100 samples in estimated 5.9845 s (30k iterations)
Benchmarking formatter/numpy/ctypeslib.py: Analyzing
formatter/numpy/ctypeslib.py
                        time:   [197.94 Âµs 198.16 Âµs 198.40 Âµs]
                        thrpt:  [83.926 MiB/s 84.030 MiB/s 84.121 MiB/s]
                 change:
                        time:   [-29.788% -29.348% -28.956%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+40.757% +41.538% +42.427%]
                        Performance has improved.
Found 8 outliers among 100 measurements (8.00%)
  4 (4.00%) high mild
  4 (4.00%) high severe
Benchmarking formatter/large/dataset.py
Benchmarking formatter/large/dataset.py: Warming up for 3.0000 s
Benchmarking formatter/large/dataset.py: Collecting 100 samples in estimated 9.3978 s (10k iterations)
Benchmarking formatter/large/dataset.py: Analyzing
formatter/large/dataset.py
                        time:   [935.23 Âµs 943.75 Âµs 957.62 Âµs]
                        thrpt:  [42.484 MiB/s 43.108 MiB/s 43.502 MiB/s]
                 change:
                        time:   [-34.664% -34.278% -33.721%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+50.878% +52.156% +53.054%]
                        Performance has improved.
Found 6 outliers among 100 measurements (6.00%)
  2 (2.00%) high mild
  4 (4.00%) high severe

     Running benches/lexer.rs (target/x86_64-unknown-linux-gnu/release/deps/lexer-0b629c0008811500)
Benchmarking lexer/numpy/globals.py
Benchmarking lexer/numpy/globals.py: Warming up for 3.0000 s
Benchmarking lexer/numpy/globals.py: Collecting 100 samples in estimated 5.0022 s (2.8M iterations)
Benchmarking lexer/numpy/globals.py: Analyzing
lexer/numpy/globals.py  time:   [1.8047 Âµs 1.8086 Âµs 1.8131 Âµs]
                        thrpt:  [1.5893 GiB/s 1.5932 GiB/s 1.5967 GiB/s]
                 change:
                        time:   [-18.632% -18.416% -18.200%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+22.249% +22.573% +22.899%]
                        Performance has improved.
Found 3 outliers among 100 measurements (3.00%)
  2 (2.00%) high mild
  1 (1.00%) high severe
Benchmarking lexer/unicode/pypinyin.py
Benchmarking lexer/unicode/pypinyin.py: Warming up for 3.0000 s
Benchmarking lexer/unicode/pypinyin.py: Collecting 100 samples in estimated 5.0074 s (793k iterations)
Benchmarking lexer/unicode/pypinyin.py: Analyzing
lexer/unicode/pypinyin.py
                        time:   [6.3298 Âµs 6.3567 Âµs 6.3865 Âµs]
                        thrpt:  [657.93 MiB/s 661.02 MiB/s 663.82 MiB/s]
                 change:
                        time:   [-20.689% -20.430% -20.102%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+25.160% +25.675% +26.086%]
                        Performance has improved.
Found 9 outliers among 100 measurements (9.00%)
  7 (7.00%) high mild
  2 (2.00%) high severe
Benchmarking lexer/pydantic/types.py
Benchmarking lexer/pydantic/types.py: Warming up for 3.0000 s
Benchmarking lexer/pydantic/types.py: Collecting 100 samples in estimated 5.0163 s (96k iterations)
Benchmarking lexer/pydantic/types.py: Analyzing
lexer/pydantic/types.py time:   [53.077 Âµs 53.451 Âµs 53.853 Âµs]
                        thrpt:  [473.57 MiB/s 477.13 MiB/s 480.50 MiB/s]
                 change:
                        time:   [-13.919% -13.373% -12.736%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+14.595% +15.438% +16.170%]
                        Performance has improved.
Found 9 outliers among 100 measurements (9.00%)
  3 (3.00%) low mild
  4 (4.00%) high mild
  2 (2.00%) high severe
Benchmarking lexer/numpy/ctypeslib.py
Benchmarking lexer/numpy/ctypeslib.py: Warming up for 3.0000 s
Benchmarking lexer/numpy/ctypeslib.py: Collecting 100 samples in estimated 5.0036 s (232k iterations)
Benchmarking lexer/numpy/ctypeslib.py: Analyzing
lexer/numpy/ctypeslib.py
                        time:   [21.120 Âµs 21.191 Âµs 21.282 Âµs]
                        thrpt:  [782.41 MiB/s 785.77 MiB/s 788.40 MiB/s]
                 change:
                        time:   [-15.534% -15.195% -14.850%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+17.440% +17.917% +18.390%]
                        Performance has improved.
Found 5 outliers among 100 measurements (5.00%)
  4 (4.00%) high mild
  1 (1.00%) high severe
Benchmarking lexer/large/dataset.py
Benchmarking lexer/large/dataset.py: Warming up for 3.0000 s
Benchmarking lexer/large/dataset.py: Collecting 100 samples in estimated 5.4378 s (50k iterations)
Benchmarking lexer/large/dataset.py: Analyzing
lexer/large/dataset.py  time:   [107.49 Âµs 108.07 Âµs 108.74 Âµs]
                        thrpt:  [374.12 MiB/s 376.45 MiB/s 378.48 MiB/s]
                 change:
                        time:   [-20.211% -19.657% -18.969%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+23.410% +24.466% +25.331%]
                        Performance has improved.
Found 6 outliers among 100 measurements (6.00%)
  3 (3.00%) high mild
  3 (3.00%) high severe

     Running benches/linter.rs (target/x86_64-unknown-linux-gnu/release/deps/linter-7592b2d887318a47)
Benchmarking linter/default-rules/numpy/globals.py
Benchmarking linter/default-rules/numpy/globals.py: Warming up for 3.0000 s
Benchmarking linter/default-rules/numpy/globals.py: Collecting 100 samples in estimated 5.0054 s (288k iterations)
Benchmarking linter/default-rules/numpy/globals.py: Analyzing
linter/default-rules/numpy/globals.py
                        time:   [12.055 Âµs 12.087 Âµs 12.117 Âµs]
                        thrpt:  [243.52 MiB/s 244.11 MiB/s 244.76 MiB/s]
                 change:
                        time:   [-13.122% -12.858% -12.592%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+14.406% +14.755% +15.105%]
                        Performance has improved.
Found 14 outliers among 100 measurements (14.00%)
  1 (1.00%) low severe
  6 (6.00%) low mild
  7 (7.00%) high mild
Benchmarking linter/default-rules/unicode/pypinyin.py
Benchmarking linter/default-rules/unicode/pypinyin.py: Warming up for 3.0000 s
Benchmarking linter/default-rules/unicode/pypinyin.py: Collecting 100 samples in estimated 5.1417 s (111k iterations)
Benchmarking linter/default-rules/unicode/pypinyin.py: Analyzing
linter/default-rules/unicode/pypinyin.py
                        time:   [27.881 Âµs 27.921 Âµs 27.962 Âµs]
                        thrpt:  [150.27 MiB/s 150.49 MiB/s 150.71 MiB/s]
                 change:
                        time:   [-17.750% -17.500% -17.268%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+20.872% +21.212% +21.580%]
                        Performance has improved.
Found 7 outliers among 100 measurements (7.00%)
  1 (1.00%) low severe
  3 (3.00%) low mild
  1 (1.00%) high mild
  2 (2.00%) high severe
Benchmarking linter/default-rules/pydantic/types.py
Benchmarking linter/default-rules/pydantic/types.py: Warming up for 3.0000 s
Benchmarking linter/default-rules/pydantic/types.py: Collecting 100 samples in estimated 5.9911 s (20k iterations)
Benchmarking linter/default-rules/pydantic/types.py: Analyzing
linter/default-rules/pydantic/types.py
                        time:   [177.24 Âµs 177.73 Âµs 178.29 Âµs]
                        thrpt:  [143.04 MiB/s 143.50 MiB/s 143.89 MiB/s]
                 change:
                        time:   [-20.934% -20.444% -19.917%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+24.870% +25.698% +26.476%]
                        Performance has improved.
Found 4 outliers among 100 measurements (4.00%)
  2 (2.00%) high mild
  2 (2.00%) high severe
Benchmarking linter/default-rules/numpy/ctypeslib.py
Benchmarking linter/default-rules/numpy/ctypeslib.py: Warming up for 3.0000 s
Benchmarking linter/default-rules/numpy/ctypeslib.py: Collecting 100 samples in estimated 5.2986 s (15k iterations)
Benchmarking linter/default-rules/numpy/ctypeslib.py: Analyzing
linter/default-rules/numpy/ctypeslib.py
Benchmarking linter/default-rules/large/dataset.py
                        time:   [77.537 Âµs 77.762 Âµs 78.006 Âµs]
Benchmarking linter/default-rules/large/dataset.py: Warming up for 3.0000 s                        thrpt:  [213.46 MiB/s 214.13 MiB/s 214.75 MiB/s]

                 change:
                        time:   [-20.205% -19.269% -17.846%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+21.722% +23.868% +25.321%]
                        Performance has improved.
Found 8 outliers among 100 measurements (8.00%)
  2 (2.00%) low mild
  1 (1.00%) high mild
  5 (5.00%) high severe

Warning: Unable to complete 100 samples in 5.0s. You may wish to increase target time to 9.0s, enable flat sampling, or reduce sample count to 50.
Benchmarking linter/default-rules/large/dataset.py: Collecting 100 samples in estimated 8.9828 s (5050 iterations)
Benchmarking linter/default-rules/large/dataset.py: Analyzing
linter/default-rules/large/dataset.py
                        time:   [400.08 Âµs 401.51 Âµs 403.17 Âµs]
                        thrpt:  [100.91 MiB/s 101.33 MiB/s 101.69 MiB/s]
                 change:
                        time:   [-20.305% -19.578% -18.860%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+23.244% +24.344% +25.478%]
                        Performance has improved.
Found 10 outliers among 100 measurements (10.00%)
  1 (1.00%) low mild
  4 (4.00%) high mild
  5 (5.00%) high severe

Benchmarking linter/all-rules/numpy/globals.py
Benchmarking linter/all-rules/numpy/globals.py: Warming up for 3.0000 s
Benchmarking linter/all-rules/numpy/globals.py: Collecting 100 samples in estimated 5.0381 s (50k iterations)
Benchmarking linter/all-rules/numpy/globals.py: Analyzing
linter/all-rules/numpy/globals.py
                        time:   [92.703 Âµs 92.837 Âµs 93.001 Âµs]
                        thrpt:  [31.727 MiB/s 31.783 MiB/s 31.829 MiB/s]
                 change:
                        time:   [-35.828% -34.470% -33.310%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+49.947% +52.601% +55.832%]
                        Performance has improved.
Found 6 outliers among 100 measurements (6.00%)
  3 (3.00%) high mild
  3 (3.00%) high severe
Benchmarking linter/all-rules/unicode/pypinyin.py
Benchmarking linter/all-rules/unicode/pypinyin.py: Warming up for 3.0000 s
Benchmarking linter/all-rules/unicode/pypinyin.py: Collecting 100 samples in estimated 6.3394 s (20k iterations)
Benchmarking linter/all-rules/unicode/pypinyin.py: Analyzing
linter/all-rules/unicode/pypinyin.py
                        time:   [296.94 Âµs 297.32 Âµs 297.79 Âµs]
                        thrpt:  [14.110 MiB/s 14.132 MiB/s 14.151 MiB/s]
                 change:
                        time:   [-34.956% -34.302% -33.843%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+51.157% +52.211% +53.742%]
                        Performance has improved.
Found 14 outliers among 100 measurements (14.00%)
  2 (2.00%) low severe
  3 (3.00%) low mild
  9 (9.00%) high severe
Benchmarking linter/all-rules/pydantic/types.py
Benchmarking linter/all-rules/pydantic/types.py: Warming up for 3.0000 s

Warning: Unable to complete 100 samples in 5.0s. You may wish to increase target time to 7.7s, enable flat sampling, or reduce sample count to 50.
Benchmarking linter/all-rules/pydantic/types.py: Collecting 100 samples in estimated 7.6522 s (5050 iterations)
Benchmarking linter/all-rules/pydantic/types.py: Analyzing
linter/all-rules/pydantic/types.py
                        time:   [1.4221 ms 1.4251 ms 1.4283 ms]
                        thrpt:  [17.856 MiB/s 17.895 MiB/s 17.934 MiB/s]
                 change:
                        time:   [-27.874% -26.459% -25.285%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+33.842% +35.978% +38.646%]
                        Performance has improved.
Found 7 outliers among 100 measurements (7.00%)
  4 (4.00%) high mild
  3 (3.00%) high severe
Benchmarking linter/all-rules/numpy/ctypeslib.py
Benchmarking linter/all-rules/numpy/ctypeslib.py: Warming up for 3.0000 s
Benchmarking linter/all-rules/numpy/ctypeslib.py: Collecting 100 samples in estimated 8.0091 s (10k iterations)
Benchmarking linter/all-rules/numpy/ctypeslib.py: Analyzing
linter/all-rules/numpy/ctypeslib.py
                        time:   [757.58 Âµs 769.61 Âµs 784.93 Âµs]
                        thrpt:  [21.214 MiB/s 21.636 MiB/s 21.979 MiB/s]
                 change:
                        time:   [-22.442% -20.697% -18.957%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+23.391% +26.098% +28.936%]
                        Performance has improved.
Found 13 outliers among 100 measurements (13.00%)
  2 (2.00%) high mild
  11 (11.00%) high severe
Benchmarking linter/all-rules/large/dataset.py
Benchmarking linter/all-rules/large/dataset.py: Warming up for 3.0000 s
Benchmarking linter/all-rules/large/dataset.py: Collecting 100 samples in estimated 5.1512 s (1900 iterations)
Benchmarking linter/all-rules/large/dataset.py: Analyzing
linter/all-rules/large/dataset.py
                        time:   [2.4131 ms 2.4227 ms 2.4340 ms]
                        thrpt:  [16.715 MiB/s 16.793 MiB/s 16.860 MiB/s]
                 change:
                        time:   [-26.431% -26.070% -25.708%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+34.603% +35.263% +35.926%]
                        Performance has improved.
Found 18 outliers among 100 measurements (18.00%)
  3 (3.00%) high mild
  15 (15.00%) high severe

Benchmarking linter/all-with-preview-rules/numpy/globals.py
Benchmarking linter/all-with-preview-rules/numpy/globals.py: Warming up for 3.0000 s
Benchmarking linter/all-with-preview-rules/numpy/globals.py: Collecting 100 samples in estimated 5.4173 s (40k iterations)
Benchmarking linter/all-with-preview-rules/numpy/globals.py: Analyzing
linter/all-with-preview-rules/numpy/globals.py
                        time:   [125.57 Âµs 126.25 Âµs 126.95 Âµs]
                        thrpt:  [23.242 MiB/s 23.372 MiB/s 23.498 MiB/s]
                 change:
                        time:   [-31.469% -31.144% -30.832%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+44.575% +45.230% +45.919%]
                        Performance has improved.
Found 23 outliers among 100 measurements (23.00%)
  9 (9.00%) low severe
  1 (1.00%) low mild
  4 (4.00%) high mild
  9 (9.00%) high severe
Benchmarking linter/all-with-preview-rules/unicode/pypinyin.py
Benchmarking linter/all-with-preview-rules/unicode/pypinyin.py: Warming up for 3.0000 s
Benchmarking linter/all-with-preview-rules/unicode/pypinyin.py: Collecting 100 samples in estimated 5.6560 s (15k iterations)
Benchmarking linter/all-with-preview-rules/unicode/pypinyin.py: Analyzing
linter/all-with-preview-rules/unicode/pypinyin.py
                        time:   [365.21 Âµs 366.27 Âµs 367.62 Âµs]
                        thrpt:  [11.430 MiB/s 11.472 MiB/s 11.505 MiB/s]
                 change:
                        time:   [-32.968% -31.999% -31.262%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+45.479% +47.056% +49.182%]
                        Performance has improved.
Found 8 outliers among 100 measurements (8.00%)
  5 (5.00%) high mild
  3 (3.00%) high severe
Benchmarking linter/all-with-preview-rules/pydantic/types.py
Benchmarking linter/all-with-preview-rules/pydantic/types.py: Warming up for 3.0000 s
Benchmarking linter/all-with-preview-rules/pydantic/types.py: Collecting 100 samples in estimated 5.0496 s (2500 iterations)
Benchmarking linter/all-with-preview-rules/pydantic/types.py: Analyzing
linter/all-with-preview-rules/pydantic/types.py
                        time:   [1.8838 ms 1.8906 ms 1.8973 ms]
                        thrpt:  [13.442 MiB/s 13.489 MiB/s 13.538 MiB/s]
                 change:
                        time:   [-19.419% -18.561% -17.859%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+21.742% +22.791% +24.099%]
                        Performance has improved.
Benchmarking linter/all-with-preview-rules/numpy/ctypeslib.py
Benchmarking linter/all-with-preview-rules/numpy/ctypeslib.py: Warming up for 3.0000 s

Warning: Unable to complete 100 samples in 5.0s. You may wish to increase target time to 5.3s, enable flat sampling, or reduce sample count to 60.
Benchmarking linter/all-with-preview-rules/numpy/ctypeslib.py: Collecting 100 samples in estimated 5.2874 s (5050 iterations)
Benchmarking linter/all-with-preview-rules/numpy/ctypeslib.py: Analyzing
linter/all-with-preview-rules/numpy/ctypeslib.py
                        time:   [976.90 Âµs 978.07 Âµs 979.52 Âµs]
                        thrpt:  [16.999 MiB/s 17.024 MiB/s 17.045 MiB/s]
                 change:
                        time:   [-20.480% -20.084% -19.718%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+24.561% +25.131% +25.755%]
                        Performance has improved.
Found 18 outliers among 100 measurements (18.00%)
  6 (6.00%) low severe
  1 (1.00%) low mild
  2 (2.00%) high mild
  9 (9.00%) high severe
Benchmarking linter/all-with-preview-rules/large/dataset.py
Benchmarking linter/all-with-preview-rules/large/dataset.py: Warming up for 3.0000 s
Benchmarking linter/all-with-preview-rules/large/dataset.py: Collecting 100 samples in estimated 5.3097 s (1600 iterations)
Benchmarking linter/all-with-preview-rules/large/dataset.py: Analyzing
linter/all-with-preview-rules/large/dataset.py
                        time:   [3.1891 ms 3.2278 ms 3.2733 ms]
                        thrpt:  [12.429 MiB/s 12.604 MiB/s 12.757 MiB/s]
                 change:
                        time:   [-25.917% -24.593% -23.316%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+30.405% +32.613% +34.983%]
                        Performance has improved.
Found 7 outliers among 100 measurements (7.00%)
  4 (4.00%) high mild
  3 (3.00%) high severe

     Running benches/parser.rs (target/x86_64-unknown-linux-gnu/release/deps/parser-270962935a2a1ec7)
Benchmarking parser/numpy/globals.py
Benchmarking parser/numpy/globals.py: Warming up for 3.0000 s
Benchmarking parser/numpy/globals.py: Collecting 100 samples in estimated 5.0039 s (727k iterations)
Benchmarking parser/numpy/globals.py: Analyzing
parser/numpy/globals.py time:   [7.0009 Âµs 7.1563 Âµs 7.3420 Âµs]
                        thrpt:  [401.89 MiB/s 412.32 MiB/s 421.47 MiB/s]
                 change:
                        time:   [-29.217% -27.034% -25.104%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+33.519% +37.051% +41.278%]
                        Performance has improved.
Found 21 outliers among 100 measurements (21.00%)
  5 (5.00%) high mild
  16 (16.00%) high severe
Benchmarking parser/unicode/pypinyin.py
Benchmarking parser/unicode/pypinyin.py: Warming up for 3.0000 s
Benchmarking parser/unicode/pypinyin.py: Collecting 100 samples in estimated 5.0718 s (177k iterations)
Benchmarking parser/unicode/pypinyin.py: Analyzing
parser/unicode/pypinyin.py
                        time:   [27.987 Âµs 28.210 Âµs 28.479 Âµs]
                        thrpt:  [147.54 MiB/s 148.95 MiB/s 150.14 MiB/s]
                 change:
                        time:   [-27.387% -25.990% -24.753%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+32.895% +35.117% +37.717%]
                        Performance has improved.
Found 15 outliers among 100 measurements (15.00%)
  1 (1.00%) high mild
  14 (14.00%) high severe
Benchmarking parser/pydantic/types.py
Benchmarking parser/pydantic/types.py: Warming up for 3.0000 s
Benchmarking parser/pydantic/types.py: Collecting 100 samples in estimated 5.2629 s (25k iterations)
Benchmarking parser/pydantic/types.py: Analyzing
Benchmarking parser/numpy/ctypeslib.py
Benchmarking parser/numpy/ctypeslib.py: Warming up for 3.0000 s
parser/pydantic/types.py
                        time:   [206.13 Âµs 206.48 Âµs 206.94 Âµs]
                        thrpt:  [123.24 MiB/s 123.52 MiB/s 123.72 MiB/s]
                 change:
                        time:   [-24.331% -22.698% -21.351%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+27.147% +29.362% +32.154%]
                        Performance has improved.
Found 22 outliers among 100 measurements (22.00%)
  1 (1.00%) low severe
  5 (5.00%) low mild
  5 (5.00%) high mild
  11 (11.00%) high severe
Benchmarking parser/numpy/ctypeslib.py: Collecting 100 samples in estimated 5.3555 s (61k iterations)
Benchmarking parser/numpy/ctypeslib.py: Analyzing
Benchmarking parser/large/dataset.py
Benchmarking parser/large/dataset.py: Warming up for 3.0000 s
parser/numpy/ctypeslib.py
                        time:   [88.399 Âµs 88.516 Âµs 88.653 Âµs]
                        thrpt:  [187.82 MiB/s 188.12 MiB/s 188.36 MiB/s]
                 change:
                        time:   [-21.877% -20.960% -19.300%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+23.916% +26.518% +28.004%]
                        Performance has improved.
Found 15 outliers among 100 measurements (15.00%)
  1 (1.00%) low severe
  1 (1.00%) low mild
  6 (6.00%) high mild
  7 (7.00%) high severe
Benchmarking parser/large/dataset.py: Collecting 100 samples in estimated 5.5732 s (10k iterations)
Benchmarking parser/large/dataset.py: Analyzing
parser/large/dataset.py time:   [553.17 Âµs 554.19 Âµs 555.65 Âµs]
                        thrpt:  [73.218 MiB/s 73.411 MiB/s 73.547 MiB/s]
                 change:
                        time:   [-25.011% -24.716% -24.415%] (p = 0.00 &lt; 0.05)
                        thrpt:  [+32.301% +32.831% +33.354%]
                        Performance has improved.
Found 8 outliers among 100 measurements (8.00%)
  3 (3.00%) high mild
  5 (5.00%) high severe

     Running benches/red_knot.rs (target/x86_64-unknown-linux-gnu/release/deps/red_knot-e9bf6985c0c146a9)
Benchmarking red_knot_check_file[cold]
Benchmarking red_knot_check_file[cold]: Warming up for 3.0000 s
Benchmarking red_knot_check_file[cold]: Collecting 100 samples in estimated 5.8327 s (300 iterations)
Benchmarking red_knot_check_file[cold]: Analyzing
red_knot_check_file[cold]
                        time:   [14.992 ms 15.019 ms 15.053 ms]
                        change: [-13.754% -13.504% -13.269%] (p = 0.00 &lt; 0.05)
                        Performance has improved.
Found 11 outliers among 100 measurements (11.00%)
  3 (3.00%) low mild
  8 (8.00%) high severe
Benchmarking red_knot_check_file[incremental]

Benchmarking red_knot_check_file[incremental]: Warming up for 3.0000 s
Benchmarking red_knot_check_file[incremental]: Collecting 100 samples in estimated 6.0624 s (300 iterations)
Benchmarking red_knot_check_file[incremental]: Analyzing
red_knot_check_file[incremental]
                        time:   [842.39 Âµs 848.82 Âµs 857.62 Âµs]
                        change: [-11.198% -9.9440% -8.6129%] (p = 0.00 &lt; 0.05)
                        Performance has improved.
Found 7 outliers among 100 measurements (7.00%)
  4 (4.00%) high mild
  3 (3.00%) high severe
</code></pre>
</details>
@zamazan4ik do you have any insights in if this may be correct?

<p>My system configuration.
OS: Ubuntu 24.04 LTS on Windows 10 x86_64
Kernel: 6.6.36.6-microsoft-standard-WSL2+
CPU: AMD Ryzen 9 7950X (32) @ 4.499GHz</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zamazan4ik">@zamazan4ik</a> on 2025-03-28 09:51</div>
            <div class="timeline-body"><p>Thank you for the measurements! I am pretty sure that your results are correct. PGO for some scenarios can do really good performance improvements ðŸ˜‰</p>
<p>As a next step, I would suggest recompiling Ruff itself with PGO and test CPU performance  improvements on some typical Ruff workloads. Maybe Ruff maintainers could help here at least with providing some good applications to be used in the benchmark routine.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FilipAndersson245">@FilipAndersson245</a> on 2025-04-11 11:56</div>
            <div class="timeline-body"><p>@charliermarsh based on my previous comment this seem quite good to implement to further the performance of ruff.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2025-04-11 12:01</div>
            <div class="timeline-body"><p>This does look promising but I think we should verify those numbers when running ruff over actual projects because it might very well be that the optimization now overfits on our very limited benchmarks (it's the same 4 files except for the red knot test).</p>
<p>You could evaluate the runtime for some of the projects that run as part of our ecosystem check https://github.com/astral-sh/ruff/blob/613951d848c077146bf7b529b73e8b7ebe0f019b/python/ruff-ecosystem/ruff_ecosystem/defaults.py#L14-L140 It might also be good to use those as input for PGO</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FilipAndersson245">@FilipAndersson245</a> on 2025-04-11 14:42</div>
            <div class="timeline-body"><p>@MichaReiser
I did some new experimenting running ruff on a few popular packages</p>
<pre><code>scikit-learn
numpy
pandas
matplotlib
pydantic
scipy
pytorch
</code></pre>
<p>I ran <code>check</code> and <code>format</code> on all these to gather data. Then I ran <code>main</code> and my <code>ruff-pgo-ecosystem3</code> on Cpython.</p>
<p>these where the results</p>
<p><code>hyperfine -N --export-markdown format.md -i --warmup 50 -r 1000 &quot;./ruff-main format ./crates/ruff_linter/resources/test/cpython/&quot; &quot;./ruff-pgo-ecosystem3 format ./crates/ruff_linter/resources/test/cpython/&quot;</code></p>
<p>| Command | Mean [ms] | Min [ms] | Max [ms] | Relative |
|:---|---:|---:|---:|---:|
| <code>./ruff-main format ./crates/ruff_linter/resources/test/cpython/</code> | 30.4 Â± 1.5 | 27.1 | 48.8 | 1.00 |
| <code>./ruff-pgo-ecosystem3 format ./crates/ruff_linter/resources/test/cpython/</code> | 30.9 Â± 2.1 | 27.7 | 63.0 | 1.02 Â± 0.09 |</p>
<p><code>hyperfine -N  -i --export-markdown check.md --warmup 5 -r 100 &quot;./ruff-main check ./crates/ruff_linter/resources/test/cpython/&quot; &quot;./ruff-pgo-ecosystem3 check ./crates/ruff_linter/resources/test/cpython/&quot;</code></p>
<p>| Command | Mean [ms] | Min [ms] | Max [ms] | Relative |
|:---|---:|---:|---:|---:|
| <code>./ruff-main check ./crates/ruff_linter/resources/test/cpython/</code> | 348.6 Â± 20.8 | 328.8 | 484.7 | 1.15 Â± 0.07 |
| <code>./ruff-pgo-ecosystem3 check ./crates/ruff_linter/resources/test/cpython/</code> | 302.2 Â± 5.3 | 293.0 | 320.5 | 1.00 |</p>
<p>Not as impressive, but still quite significantly faster checks compared to main.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MichaReiser">@MichaReiser</a> on 2025-04-11 15:06</div>
            <div class="timeline-body"><p>Yeah, that definitely looks promising. Are you interested in adding PGO support to Ruff? It isn't something that the team has time to focus on right now but it seems high impact. It would probably require selecting a few good input samples first and then figuring out how we integrate it into the release process.</p>
<p>I'd be a bit more hesitant of adding PGO if it complicates our release process by a lot or complicates downstream packaging.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FilipAndersson245">@FilipAndersson245</a> on 2025-04-11 18:32</div>
            <div class="timeline-body"><p>I could give it a go</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/17369.html">astral-sh/ruff#17369</a> on 2025-04-12 20:11</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-09 23:34:51 UTC
    </footer>
</body>
</html>
