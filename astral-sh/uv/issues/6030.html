<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>`uv pip install` fails to install `llama-cpp-python` - astral-sh/uv #6030</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1><code>uv pip install</code> fails to install <code>llama-cpp-python</code></h1>

    <div class="meta">
        <span class="state-icon state-closed"></span>
        <a href="https://github.com/astral-sh/uv/issues/6030">#6030</a>
        opened by <a href="https://github.com/alonsosilvaallende">@alonsosilvaallende</a>
        on 2024-08-12 09:29
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/alonsosilvaallende">@alonsosilvaallende</a></div>
            <div class="timeline-body"><p>Thank you very much for this package. I&#x27;m encountering the following issue. In an emptly virtual environment, when I run</p>
<pre><code>uv pip install llama-cpp-python --verbose
</code></pre>
<p>I obtain</p>
<pre><code>DEBUG uv 0.2.35
DEBUG Searching for Python interpreter in system path
DEBUG Found `cpython-3.10.12-linux-x86_64-gnu` at `/home/asilva/test-llama-cpp/.venv/bin/python3` (active virtual environment)
DEBUG Using Python 3.10.12 environment at test-llama-cpp/.venv/bin/python3
DEBUG Acquired lock for `test-llama-cpp/.venv`
DEBUG At least one requirement is not satisfied: llama-cpp-python
DEBUG Using request timeout of 30s
DEBUG Solving with installed Python version: 3.10.12
DEBUG Adding direct dependency: llama-cpp-python*
DEBUG Found fresh response for: https://pypi.org/simple/llama-cpp-python/
DEBUG Searching for a compatible version of llama-cpp-python (*)
DEBUG Selecting: llama-cpp-python==0.2.87 [compatible] (llama_cpp_python-0.2.87.tar.gz)
DEBUG Acquired lock for `/home/asilva/.cache/uv/built-wheels-v3/pypi/llama-cpp-python/0.2.87`
DEBUG No cache entry for: https://files.pythonhosted.org/packages/a2/63/7b9fe4c6b9d52e1ed2c2689711cdbb60314cf13474c626accd4213cf937c/llama_cpp_python-0.2.87.tar.gz
DEBUG Downloading source distribution: llama-cpp-python==0.2.87
error: Failed to download and build `llama-cpp-python==0.2.87`
  Caused by: Failed to extract archive
  Caused by: failed to unpack `/home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h`
  Caused by: File exists (os error 17) when symlinking ../ggml/include/ggml-alloc.h to /home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h
</code></pre>
<p>Current uv version: uv 0.2.35</p>
<p>Current platform:
PRETTY_NAME=&quot;Ubuntu 22.04.4 LTS&quot;
NAME=&quot;Ubuntu&quot;
VERSION_ID=&quot;22.04&quot;
VERSION=&quot;22.04.4 LTS (Jammy Jellyfish)&quot;
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL=&quot;https://www.ubuntu.com/&quot;
SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;
BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;
PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;
UBUNTU_CODENAME=jammy</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/baggiponte">@baggiponte</a> on 2024-08-12 09:47</div>
            <div class="timeline-body"><p>Uhm, I cannot decipher the last line:</p>
<pre><code>Caused by: File exists (os error 17) when symlinking ../ggml/include/ggml-alloc.h to /home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h
</code></pre>
<p>There might be another version of ggml-alloc somewhere in the machine?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/alonsosilvaallende">@alonsosilvaallende</a> on 2024-08-12 10:04</div>
            <div class="timeline-body"><blockquote>
<p>Uhm, I cannot decipher the last line:</p>
<pre><code>Caused by: File exists (os error 17) when symlinking ../ggml/include/ggml-alloc.h to /home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h
</code></pre>
<p>There might be another version of ggml-alloc somewhere in the machine?</p>
</blockquote>
<p>Thank you very much for your answer @baggiponte
Any pointers on how to check if that is the case and how to remove it?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/alonsosilvaallende">@alonsosilvaallende</a> on 2024-08-12 11:44</div>
            <div class="timeline-body"><p>I tested other versions of llama-cpp-python. Up to version <code>llama-cpp-python=0.2.85</code> it works without any problem. The last two versions <code>llama-cpp-python=0.2.86</code> and <code>llama-cpp-python=0.2.87</code> do not work with <code>uv</code> anymore.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">compatibility</span> added by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 14:36</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 14:47</div>
            <div class="timeline-body"><p>I can take a look. My guess is we&#x27;re refusing to overwrite a file with a symlink, or something like that.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to <a href="https://github.com/charliermarsh">@charliermarsh</a> by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 14:48</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 17:53</div>
            <div class="timeline-body"><p>I think there might be something wrong with this source distribution. If you untar it, every entry is duplicated: <code>tar -tf llama_cpp_python-0.2.87.tar.gz</code>:</p>
<pre><code>...
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-bpe.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-bpe.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-spm.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-spm.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-random.py
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-random.py
...
</code></pre>
<p>I don&#x27;t see the same issue with the prior release. Do you mind reporting this on the library itself?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">compatibility</span> removed by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 17:55</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">upstream</span> added by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 17:55</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-12 17:55</div>
            <div class="timeline-body"><p>Nevermind, I commented on <a href="https://github.com/abetlen/llama-cpp-python/issues/1670">abetlen/llama-cpp-python#1670</a>.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/henryiii">@henryiii</a> on 2024-08-13 02:41</div>
            <div class="timeline-body"><p>scikit-build-core 0.10.2 should fix this (thanks to @abetlen)!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/alonsosilvaallende">@alonsosilvaallende</a> on 2024-08-13 03:29</div>
            <div class="timeline-body"><p>Great. Thank you very much. Should I close it then or leave it open until fixed in case other people are having the same issue?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2024-08-13 03:39</div>
            <div class="timeline-body"><p>Best to close it so we know we don&#x27;t need to do anything here. Thanks!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/zanieb">@zanieb</a> on 2024-08-13 03:39</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/alonsosilvaallende">@alonsosilvaallende</a> on 2024-08-13 14:28</div>
            <div class="timeline-body"><p>For others looking at this issue, this has been solved in <code>llama-cpp-python==0.2.88</code></p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:32:41 UTC
    </footer>
</body>
</html>
