<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>cannot install package if module is used in top level of setup.py - astral-sh/uv #3742</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>cannot install package if module is used in top level of setup.py</h1>

    <div class="meta">
        <span class="state state-closed">Closed</span>
        <a href="https://github.com/astral-sh/uv/issues/3742">#3742</a>
        opened by <a href="https://github.com/brian316">@brian316</a>
        on 2024-05-22 16:35
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Issue opened by <a href="https://github.com/brian316">@brian316</a> on 2024-05-22 16:35</div>
            <div class="timeline-body"><h1>Issue</h1>
<p>I cannot install a library if a module not in standard library is used during build process... in this case <code>torch</code></p>
<h1>Setup</h1>
<ul>
<li>The command you invoked <code>uv pip install -e .  -vvv</code></li>
<li>The current uv platform: &quot;Ubuntu 22.04.4 LTS&quot;</li>
<li>The current uv version 0.1.45.</li>
</ul>
<p>This code comes from the following open-source project
https://github.com/idiap/fast-transformers/</p>
<p>Code:</p>
<pre><code class="language-python">#!/usr/bin/env python
#
# Copyright (c) 2020 Idiap Research Institute, http://www.idiap.ch/
# Written by Angelos Katharopoulos &lt;angelos.katharopoulos@idiap.ch&gt;,
# Apoorv Vyas &lt;avyas@idiap.ch&gt;
#

&quot;&quot;&quot;Setup fast transformers&quot;&quot;&quot;

from functools import lru_cache
from itertools import dropwhile
import os
from os import path
from setuptools import find_packages, setup
from subprocess import DEVNULL, call
import sys


try:
    import torch
    from torch.utils.cpp_extension import BuildExtension, CppExtension
except ImportError as e:
    raise ImportError(
        (&quot;PyTorch is required to install pytorch-fast-transformers. Please &quot;
         &quot;install your favorite version of PyTorch, we support 1.3.1, 1.5.0 &quot;
         &quot;and &gt;=1.6&quot;),
        name=e.name,
        path=e.path
    ) from e


@lru_cache(None)
def cuda_toolkit_available():
    try:
        call([&quot;nvcc&quot;], stdout=DEVNULL, stderr=DEVNULL)
        return True
    except FileNotFoundError:
        return False


def collect_docstring(lines):
    &quot;&quot;&quot;Return document docstring if it exists&quot;&quot;&quot;
    lines = dropwhile(lambda x: not x.startswith('&quot;&quot;&quot;'), lines)
    doc = &quot;&quot;
    for line in lines:
        doc += line
        if doc.endswith('&quot;&quot;&quot;\n'):
            break

    return doc[3:-4].replace(&quot;\r&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot; &quot;)


def collect_metadata():
    meta = {}
    with open(path.join(&quot;fast_transformers&quot;, &quot;__init__.py&quot;)) as f:
        lines = iter(f)
        meta[&quot;description&quot;] = collect_docstring(lines)
        for line in lines:
            if line.startswith(&quot;__&quot;):
                key, value = map(lambda x: x.strip(), line.split(&quot;=&quot;))
                meta[key[2:-2]] = value[1:-1]

    return meta


@lru_cache()
def _get_cpu_extra_compile_args():
    base_args = [&quot;-fopenmp&quot;, &quot;-ffast-math&quot;]

    if sys.platform == &quot;darwin&quot;:
        return [&quot;-Xpreprocessor&quot;] + base_args
    else:
        return base_args


@lru_cache()
def _get_gpu_extra_compile_args():
    if torch.cuda.is_available():
        return []
    else:
        return [&quot;-arch=compute_60&quot;]


def get_extensions():
    extensions = [
        CppExtension(
            &quot;fast_transformers.hashing.hash_cpu&quot;,
            sources=[
                &quot;fast_transformers/hashing/hash_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        ),
        CppExtension(
            &quot;fast_transformers.aggregate.aggregate_cpu&quot;,
            sources=[
               &quot;fast_transformers/aggregate/aggregate_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        ),
        CppExtension(
            &quot;fast_transformers.clustering.hamming.cluster_cpu&quot;,
            sources=[
               &quot;fast_transformers/clustering/hamming/cluster_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        ),
        CppExtension(
            &quot;fast_transformers.sparse_product.sparse_product_cpu&quot;,
            sources=[
                &quot;fast_transformers/sparse_product/sparse_product_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        ),
        CppExtension(
            &quot;fast_transformers.sparse_product.clustered_sparse_product_cpu&quot;,
            sources=[
                &quot;fast_transformers/sparse_product/clustered_sparse_product_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        ),
        CppExtension(
            &quot;fast_transformers.causal_product.causal_product_cpu&quot;,
            sources=[
                &quot;fast_transformers/causal_product/causal_product_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        ),
        CppExtension(
            &quot;fast_transformers.local_product.local_product_cpu&quot;,
            sources=[
                &quot;fast_transformers/local_product/local_product_cpu.cpp&quot;
            ],
            extra_compile_args=_get_cpu_extra_compile_args()
        )
    ]
    if cuda_toolkit_available():
        from torch.utils.cpp_extension import CUDAExtension
        extensions += [
            CUDAExtension(
                &quot;fast_transformers.hashing.hash_cuda&quot;,
                sources=[
                    &quot;fast_transformers/hashing/hash_cuda.cu&quot;,
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.aggregate.aggregate_cuda&quot;,
                sources=[
                    &quot;fast_transformers/aggregate/aggregate_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.aggregate.clustered_aggregate_cuda&quot;,
                sources=[
                    &quot;fast_transformers/aggregate/clustered_aggregate_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.clustering.hamming.cluster_cuda&quot;,
                sources=[
                    &quot;fast_transformers/clustering/hamming/cluster_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.sparse_product.sparse_product_cuda&quot;,
                sources=[
                    &quot;fast_transformers/sparse_product/sparse_product_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.sparse_product.clustered_sparse_product_cuda&quot;,
                sources=[
                    &quot;fast_transformers/sparse_product/clustered_sparse_product_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.causal_product.causal_product_cuda&quot;,
                sources=[
                    &quot;fast_transformers/causal_product/causal_product_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            ),
            CUDAExtension(
                &quot;fast_transformers.local_product.local_product_cuda&quot;,
                sources=[
                    &quot;fast_transformers/local_product/local_product_cuda.cu&quot;
                ],
                extra_compile_args=_get_gpu_extra_compile_args()
            )
        ]
    return extensions


def setup_package():
    with open(&quot;README.rst&quot;) as f:
        long_description = f.read()
    meta = collect_metadata()
    version_suffix = os.getenv(&quot;FAST_TRANSFORMERS_VERSION_SUFFIX&quot;, &quot;&quot;)
    setup(
        name=&quot;pytorch-fast-transformers&quot;,
        version=meta[&quot;version&quot;] + version_suffix,
        description=meta[&quot;description&quot;],
        long_description=long_description,
        long_description_content_type=&quot;text/x-rst&quot;,
        maintainer=meta[&quot;maintainer&quot;],
        maintainer_email=meta[&quot;email&quot;],
        url=meta[&quot;url&quot;],
        license=meta[&quot;license&quot;],
        classifiers=[
            &quot;Intended Audience :: Science/Research&quot;,
            &quot;Intended Audience :: Developers&quot;,
            &quot;License :: OSI Approved :: MIT License&quot;,
            &quot;Topic :: Scientific/Engineering&quot;,
            &quot;Programming Language :: Python&quot;,
            &quot;Programming Language :: Python :: 3&quot;,
            &quot;Programming Language :: Python :: 3.6&quot;,
        ],
        packages=find_packages(exclude=[&quot;docs&quot;, &quot;tests&quot;, &quot;scripts&quot;, &quot;examples&quot;]),
        ext_modules=get_extensions(),
        cmdclass={&quot;build_ext&quot;: BuildExtension},
        install_requires=[&quot;torch&quot;]
    )


if __name__ == &quot;__main__&quot;:
    setup_package()

</code></pre>
<h1>Stacktrace</h1>
<pre><code>‚ùØ uv pip install -e . -vvv
 uv_requirements::specification::from_source source=-e .
    0.000922s  INFO uv_interpreter::virtualenv Found a virtualenv through VIRTUAL_ENV at: /home/dev/work/open-source/fast-transformers/.venv
    0.001004s DEBUG uv_interpreter::interpreter Cached interpreter info for Python 3.10.12, skipping probing: .venv/bin/python
    0.001013s DEBUG uv::commands::pip::install Using Python 3.10.12 environment at .venv/bin/python
    0.001044s DEBUG uv_fs Trying to lock if free: .venv/.lock
    0.001114s DEBUG uv::commands::pip::install At least one requirement is not satisfied: file:///home/dev/work/open-source/fast-transformers
 uv_client::linehaul::linehaul 
    0.001354s DEBUG uv_client::base_client Using registry request timeout of 30s
 uv_resolver::flat_index::from_entries 
 uv_installer::downloader::build_editables 
      0.001934s   0ms DEBUG uv_distribution::source Building (editable) file:///home/dev/work/open-source/fast-transformers
   uv_dispatch::setup_build version_id=&quot;file:///home/dev/work/open-source/fast-transformers&quot;, subdirectory=None
 uv_resolver::resolver::solve 
   uv_resolver::resolver::solve_tracked 
        0.002494s   0ms DEBUG uv_resolver::resolver Solving with target Python version 3.10.12
     uv_resolver::resolver::choose_version package=root
     uv_resolver::resolver::get_dependencies package=root, version=0a0.dev0
          0.002537s   0ms DEBUG uv_resolver::resolver Adding direct dependency: setuptools&gt;=40.8.0
     uv_resolver::resolver::choose_version package=setuptools
     uv_resolver::resolver::process_request request=Versions setuptools
       uv_client::registry_client::simple_api package=setuptools
         uv_client::cached_client::get_cacheable 
           uv_client::cached_client::read_and_parse_cache file=/home/dev/.cache/uv/simple-v7/pypi/setuptools.rkyv
     uv_resolver::resolver::process_request request=Prefetch setuptools &gt;=40.8.0
 uv_client::cached_client::from_path_sync path=&quot;/home/dev/.cache/uv/simple-v7/pypi/setuptools.rkyv&quot;
              0.003245s   0ms DEBUG uv_client::cached_client Found fresh response for: https://pypi.org/simple/setuptools/
       uv_resolver::version_map::from_metadata 
          0.003627s   1ms DEBUG uv_resolver::resolver Searching for a compatible version of setuptools (&gt;=40.8.0)
          0.003638s   1ms DEBUG uv_resolver::resolver Selecting: setuptools==70.0.0 (setuptools-70.0.0-py3-none-any.whl)
       uv_distribution::distribution_database::get_or_build_wheel_metadata dist=setuptools==70.0.0
     uv_resolver::resolver::get_dependencies package=setuptools, version=70.0.0
         uv_client::registry_client::wheel_metadata built_dist=setuptools==70.0.0
           uv_client::cached_client::get_serde 
             uv_client::cached_client::get_cacheable 
               uv_client::cached_client::read_and_parse_cache file=/home/dev/.cache/uv/wheels-v1/pypi/setuptools/setuptools-70.0.0-py3-none-any.msgpack
 uv_client::cached_client::from_path_sync path=&quot;/home/dev/.cache/uv/wheels-v1/pypi/setuptools/setuptools-70.0.0-py3-none-any.msgpack&quot;
                  0.003790s   0ms DEBUG uv_client::cached_client Found fresh response for: https://files.pythonhosted.org/packages/de/88/70c5767a0e43eb4451c2200f07d042a4bcd7639276003a9c54a68cfcc1f8/setuptools-70.0.0-py3-none-any.whl.metadata
        0.003915s   1ms DEBUG uv_resolver::resolver::batch_prefetch Tried 2 versions: root 1, setuptools 1
     uv_dispatch::install resolution=&quot;setuptools==70.0.0&quot;, venv=&quot;/home/dev/.cache/uv/.tmpEGmPw6/.venv&quot;
          0.003992s   0ms DEBUG uv_dispatch Installing in setuptools==70.0.0 in /home/dev/.cache/uv/.tmpEGmPw6/.venv
          0.004053s   0ms DEBUG uv_installer::plan Requirement already cached: setuptools==70.0.0
          0.004065s   0ms DEBUG uv_dispatch Installing build requirement: setuptools==70.0.0
       uv_installer::installer::install num_wheels=1
        0.006135s   4ms DEBUG uv_build Calling `setuptools.build_meta:__legacy__.get_requires_for_build_editable()`
     uv_build::run_python_script script=&quot;get_requires_for_build_editable&quot;, python_version=3.10.12
error: Failed to build editables
  Caused by: Failed to build editable: `file:///home/dev/work/open-source/fast-transformers`
  Caused by: Build backend failed to determine extra requires with `build_editable()` with exit status: 1
--- stdout:

--- stderr:
Traceback (most recent call last):
  File &quot;&lt;string&gt;&quot;, line 20, in &lt;module&gt;
ModuleNotFoundError: No module named 'torch'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;&lt;string&gt;&quot;, line 14, in &lt;module&gt;
  File &quot;/home/dev/.cache/uv/.tmpEGmPw6/.venv/lib/python3.10/site-packages/setuptools/build_meta.py&quot;, line 448, in get_requires_for_build_editable
    return self.get_requires_for_build_wheel(config_settings)
  File &quot;/home/dev/.cache/uv/.tmpEGmPw6/.venv/lib/python3.10/site-packages/setuptools/build_meta.py&quot;, line 325, in get_requires_for_build_wheel
    return self._get_build_requires(config_settings, requirements=['wheel'])
  File &quot;/home/dev/.cache/uv/.tmpEGmPw6/.venv/lib/python3.10/site-packages/setuptools/build_meta.py&quot;, line 295, in _get_build_requires
    self.run_setup()
  File &quot;/home/dev/.cache/uv/.tmpEGmPw6/.venv/lib/python3.10/site-packages/setuptools/build_meta.py&quot;, line 487, in run_setup
    super().run_setup(setup_script=setup_script)
  File &quot;/home/dev/.cache/uv/.tmpEGmPw6/.venv/lib/python3.10/site-packages/setuptools/build_meta.py&quot;, line 311, in run_setup
    exec(code, locals())
  File &quot;&lt;string&gt;&quot;, line 23, in &lt;module&gt;
ImportError: PyTorch is required to install pytorch-fast-transformers. Please install your favorite version of PyTorch, we support 1.3.1, 1.5.0 and &gt;=1.6
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-22 16:36</div>
            <div class="timeline-body"><p>This is all correct behavior. You can try running with <code>--no-build-isolation</code> if you want to discover packages in your environment.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/brian316">@brian316</a> on 2024-05-22 16:42</div>
            <div class="timeline-body"><p>appreciate you!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @brian316 on 2024-05-22 16:42</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-22 16:43</div>
            <div class="timeline-body"><p>No prob. The downside is you have to make sure you have <em>all</em> of the build dependencies installed upfront which can be a little tedious and error-prone, but some packages require it (especially if they depend on Torch at build-time).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/brian316">@brian316</a> on 2024-05-22 16:52</div>
            <div class="timeline-body"><p>is there any workaround for that? like having torch and fast-transformers in 1 requirements.txt file?</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-09 23:34:58 UTC
    </footer>
</body>
</html>
