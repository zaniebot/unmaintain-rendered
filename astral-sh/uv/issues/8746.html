<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>`uv add` fails on `torch` &quot;no wheel for current platform&quot; Docker Linux on Mac ARM - astral-sh/uv #8746</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1><code>uv add</code> fails on <code>torch</code> &quot;no wheel for current platform&quot; Docker Linux on Mac ARM</h1>

    <div class="meta">
        <span class="state-icon state-closed"></span>
        <a href="https://github.com/astral-sh/uv/issues/8746">#8746</a>
        opened by <a href="https://github.com/bepuca">@bepuca</a>
        on 2024-11-01 07:01
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/bepuca">@bepuca</a></div>
            <div class="timeline-body">

<p>The situation is the following:</p>
<ul>
<li>I work on workloads that usually require GPUs. The problem is these machines are expensive (usually use VMs), so I try to do as much as possible on my laptop, a Mac with Apple Sillicon.</li>
<li>I collaborate with other colleagues who do not have Mac.</li>
<li>For these reasons, we leverage <a href="https://code.visualstudio.com/docs/devcontainers/containers">devcontainers</a> to ensure we all operate on the same environment (a linux one).</li>
</ul>
<p>Now, because of these reasons, I need to install Pytorch + CUDA in these environments, even if in many of the computers it is used, there is no GPU. Ideally, there will be a mechanism for installing CUDA version when GPU is available (or based on env var) and cpu version otherwise, but this is another story.</p>
<p>The problem I have now is I cannot seem to add pytorch+cuda to the project when running it inside a Docker container running linux ARM inside a Mac with Apple Sillicon. But when I do <code>uv pip install torch --index-url https://download.pytorch.org/whl/cu121</code>, it works. It installs and can import normally. I would expect, then, to be able to do <code>uv add torch</code> and work the same. I know Pytorch installations are a beast of their own, so maybe I am missing something. In that case, I&#x27;d love to understand.</p>
Minimal Example
<p>The file structure looks like this:</p>
<pre><code>.
â”œâ”€â”€ .devcontainer
|   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ devcontainer.json
â”œâ”€â”€ pyproject.toml
â””â”€â”€.python_version
</code></pre>
<p><strong>Dockerfile</strong></p>
<pre><code>FROM mcr.microsoft.com/devcontainers/base:jammy

# Install uv
COPY --from=ghcr.io/astral-sh/uv:0.4.29 /uv /uvx /bin/
</code></pre>
<p><strong>devcontainer.json</strong></p>
<pre><code>{
    &quot;name&quot;: &quot;minimal&quot;,
    &quot;build&quot;: { &quot;dockerfile&quot;: &quot;Dockerfile&quot; },
    &quot;workspaceFolder&quot;: &quot;/workspaces/${localWorkspaceFolderBasename}&quot;,
    &quot;remoteEnv&quot;: {
        // Ensure venv is always first in PATH
        &quot;PATH&quot;: &quot;${containerWorkspaceFolder}/.venv/bin:${containerEnv:PATH}&quot;,
    },
    &quot;remoteUser&quot;: &quot;vscode&quot;,
}
</code></pre>
<p><strong>pyproject.toml</strong></p>
<pre><code>[project]
name = &quot;minimal&quot;
version = &quot;0.1.0&quot;
requires-python = &quot;&gt;=3.11&quot;
dependencies = [
]

[[tool.uv.index]]
name = &quot;pytorch-cu121&quot;
url = &quot;https://download.pytorch.org/whl/cu121&quot;
explicit = true

[tool.uv.sources]
torch = { index = &quot;pytorch-cu121&quot; }
</code></pre>
<p><strong>.python_version</strong></p>
<pre><code>3.11
</code></pre>
<p>To reproduce you will need:</p>
<ul>
<li>A Mac with AppleSillicon</li>
<li>VSCode with the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers">devcontainer extension</a> installed</li>
<li>Docker in your machine</li>
</ul>
<p>Then, open the command palette of VSCode (if not directly prompted) and &quot;reopen in container&quot;.</p>
<p>Now, when I try to do in the terminal:</p>
<pre><code>$uv add torch
Resolved 24 packages in 396ms
error: Distribution `torch==2.5.1+cu121 @ registry+https://download.pytorch.org/whl/cu121` can&#x27;t be installed because it doesn&#x27;t have a source distribution or wheel for the current platform
</code></pre>
<p>But if I use <code>uv pip install torch --index-url https://download.pytorch.org/whl/cu121</code> it succeeds without issue.</p>
<p>Am I doing something wrong? Can I fix it somehow? I&#x27;d really like to port the project to <code>uv</code> but this is a big blocker. An working but less appealing alternative, is if I can have a solution for the problem described in #8745 (assuming then I can install pytorch without issues).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Renamed from &quot;`uv add` fails on `torch` saying no wheel for current platform&quot; to &quot;`uv add` fails on `torch` &quot;no wheel for current platform&quot; Docker on Mac ARM&quot; by <a href="https://github.com/bepuca">@bepuca</a> on 2024-11-01 07:04</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FishAlchemist">@FishAlchemist</a> on 2024-11-01 07:26</div>
            <div class="timeline-body"><p>Let me just say up front that I&#x27;m typing this on my phone, so I&#x27;ll keep it short.</p>
<p>PyTorch Index appears to have never offered pre-built wheels for macOS, which means UV cannot locate Mac-compatible PyTorch packages from it.
(PyTorch wheels for macOS are on PyPI, not on PyTorch Index.)</p>
<p>You need to use PEP 508 to prevent UV from finding wheels from PyTorch Index.</p>
<p>You can refer to <a href="https://github.com/astral-sh/uv/pull/6523">astral-sh/uv#6523</a>, or check the document for the explanation of PEP 508.
https://docs.astral.sh/uv/concepts/dependencies/#dependency-specifiers-pep-508</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/bepuca">@bepuca</a> on 2024-11-01 08:59</div>
            <div class="timeline-body"><p>Thank you very much for the response. I think is a bit more tricky than that. I did find the issue with the docs you linked, and this is where I based my example from.</p>
<p>The issue is that <strong>the platform is Linux</strong> because all is happening inside a Linux Docker container:</p>
<pre><code>$ uv run python -c &quot;import platform; print(platform.system())&quot;
Linux
</code></pre>
<p>Therefore, the wheels I would expect to be found are <strong>arm linux</strong> ones, not macOS. Looking through the wheels in the torch index, I am not sure they offer a cuda version for aarch64. If that is the case, then how come pip install does find something and install it? I manage to do what I am describing with Poetry and I have a hard time understanding the difference.</p>
<p>I realize this might be going more in the direction on me having a flawed understanding rather than anything wrong per se with uv. Thus I understand if you want to close the issue.</p>
<p>That being said, I read multiple times the instructions you linked and failed to succeed. If I manage to make this work, I&#x27;d be happy to contribute there too so others don&#x27;t struggle.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Renamed from &quot;`uv add` fails on `torch` &quot;no wheel for current platform&quot; Docker on Mac ARM&quot; to &quot;`uv add` fails on `torch` &quot;no wheel for current platform&quot; Docker Linux on Mac ARM&quot; by <a href="https://github.com/bepuca">@bepuca</a> on 2024-11-01 09:09</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FishAlchemist">@FishAlchemist</a> on 2024-11-01 10:06</div>
            <div class="timeline-body"><p>When using Linux aarch64, it might be necessary to specify the version. It is unclear to me why UV would select a newer version that is incompatible with the platform.
While <code>uv pip install</code> picks the correct old version, <code>uv add</code> select an unavailable newer one.
<img src="https://github.com/user-attachments/assets/3dff4049-487a-4db2-a83a-9dd6ee83f79a" alt="image"></p>
There are only these wheels on PyTorch Index (cu121)
<p><img src="https://github.com/user-attachments/assets/37256acc-22ce-4b47-a3e8-414dfdfd5ec1" alt="image"></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FishAlchemist">@FishAlchemist</a> on 2024-11-01 10:37</div>
            <div class="timeline-body"><p>https://download.pytorch.org/whl/cu124/torch
<strong>Supplement</strong>: By choosing CUDA 12.4, you should be able to install 2.4.0, 2.4.1, 2.5.0, and 2.5.1.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/bepuca">@bepuca</a> on 2024-11-01 10:46</div>
            <div class="timeline-body"><p>You are correct, when I do so, <code>uv add</code> still fails but <code>uv pip</code> would do the following:</p>
<pre><code>$ uv pip install torch --index-url https://download.pytorch.org/whl/cu124 --python-platform aarch64-manylinux_2_31 --dry-run

Resolved 9 packages in 4.72s
Would download 9 packages
Would install 9 packages
 + filelock==3.13.1
 + fsspec==2024.2.0
 + jinja2==3.1.3
 + markupsafe==2.1.5
 + mpmath==1.3.0
 + networkx==3.2.1
 + sympy==1.13.1
 + torch==2.5.1
 + typing-extensions==4.9.0
</code></pre>
<p>But then I understand in this circumstance uv would be expected to have the same behavior?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FishAlchemist">@FishAlchemist</a> on 2024-11-01 10:56</div>
            <div class="timeline-body"><p>So, lockfile doesn&#x27;t work on Linux arch64, right?
(Waiting for a response from the maintenance code)
<strong>pyproject.toml</strong></p>
<pre><code>...
requires-python = &quot;&gt;=3.11&quot;
dependencies = [
    &quot;torch==2.5.1 ; platform_system == &#x27;Darwin&#x27;&quot;,
    &quot;torch==2.5.1+cu124 ; platform_system != &#x27;Darwin&#x27;&quot;,
]

[tool.uv.sources]
torch = [{ index = &quot;pytorch-cu124&quot;, marker = &quot;platform_system != &#x27;Darwin&#x27;&quot; }]

[[tool.uv.index]]
name = &quot;pytorch-cu124&quot;
url = &quot;https://download.pytorch.org/whl/cu124&quot;
explicit = true
</code></pre>
<p><strong>uv.lock</strong></p>
<pre><code>name = &quot;torch&quot;
version = &quot;2.5.1+cu124&quot;
source = { registry = &quot;https://download.pytorch.org/whl/cu124&quot; }
resolution-markers = [
    &quot;python_full_version &lt; &#x27;3.12&#x27; and platform_system != &#x27;Darwin&#x27;&quot;,
    &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_system != &#x27;Darwin&#x27;&quot;,
]

wheels = [
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl&quot;, hash = &quot;sha256:6b2966ede9affe2fd69e0765691ca723ec870e0c34c7761f4d5b8e318383fdaf&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-win_amd64.whl&quot;, hash = &quot;sha256:6c8a7003ef1327479ede284b6e5ab3527d3900c2b2d401af15bcc50f2245a59f&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl&quot;, hash = &quot;sha256:bf6484bfe5bc4f92a4a1a1bf553041505e19a911f717065330eb061afe0e14d7&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-win_amd64.whl&quot;, hash = &quot;sha256:3c3f705fb125edbd77f9579fa11a138c56af8968a10fc95834cdd9fdf4f1f1a6&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp313-cp313-linux_x86_64.whl&quot;, hash = &quot;sha256:e9bebf91ede89267577911da4b0709ac6113a0cff6a1c2202c046b1ec2a51601&quot; },
]
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-01 13:23</div>
            <div class="timeline-body"><p>This is a manifestation of <a href="https://github.com/astral-sh/uv/issues/5182">astral-sh/uv#5182</a>. I described the problem in more detail here: <a href="https://github.com/astral-sh/uv/issues/8536">astral-sh/uv#8536</a>#issuecomment-2436123242. But it&#x27;s most difficult with PyTorch, where there&#x27;s no source distribution, and the wheel version tags differ across platforms. I think what @FishAlchemist has is on the right track. What&#x27;s the issue with that solution? (I don&#x27;t think PyTorch publishes ARM Linux wheels, at least I don&#x27;t se them on https://download.pytorch.org/whl/torch/.)</p>
<p>For reference, <code>uv pip install torch --index-url https://download.pytorch.org/whl/cu121</code> may not even be giving you the CUDA-accelerated PyTorch. You&#x27;d have to look at the selected local version tag.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">question</span> added by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-01 13:23</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/FishAlchemist">@FishAlchemist</a> on 2024-11-01 14:04</div>
            <div class="timeline-body"><p>@charliermarsh
Since these wheels exist, even though they&#x27;re not CUDA versions, there should still be supported, right? Or is this not a standard format, making it difficult to search for?
<img src="https://github.com/user-attachments/assets/58b45de0-8ec4-40a3-ac10-e5f3e432d331" alt="image">
Edit(Record):
requires-python = &quot;&gt;=3.11&quot;
From PyPI:
torch-2.5.0-cp311-cp311-manylinux2014_aarch64.whl
torch-2.5.0-cp312-cp312-manylinux2014_aarch64.whl
https://github.com/pytorch/pytorch/blob/main/RELEASE.md#operating-systems
<img src="https://github.com/user-attachments/assets/077b05c8-40f2-47cb-bf8f-6cadda613b5b" alt="image"></p>
<hr>
<p>@bepuca
By the way, I&#x27;ve only found NGC supporting it online.
https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/bepuca">@bepuca</a> on 2024-11-01 17:25</div>
            <div class="timeline-body"><p>Alright, I am a bit confused with the whole thing as I get a bit lost on the details of the wheels and the implications. What in the end, understood, is that somehow the wheels for aarch64 are a bit obscure and using indexes for them makes it hard or impossible for uv to properly resolve. Then, what seems to solve my problem is this:</p>
<p><code>pyproject.toml</code></p>
<pre><code>[project]
name = &quot;minimal&quot;
version = &quot;0.1.0&quot;
description = &quot;Add your description here&quot;
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.11&quot;
dependencies = [
    &quot;torch&gt;=2.5.1&quot;,
]

[tool.uv.sources]
torch = [
    { index = &quot;pytorch-cu124&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; }
]

[[tool.uv.index]]
name = &quot;pytorch-cu124&quot;
url = &quot;https://download.pytorch.org/whl/cu124&quot;
explicit = true
</code></pre>
<p>I have not double checked this does install the cuda version properly in x86_64 but I think it will work. What I do not understand is why like this the wheel can be resolved. In any case, it does not seem PyTorch releases CUDA compatible wheels for aarch64 anyway. Not sure if this is the expected way of how things should work or not, but if it is, I am happy with the result as I can work with this. Thank you very much for all the support.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-01 18:49</div>
            <div class="timeline-body"><p>Ahh I missed that there are aarch64 wheels way down there. I can post an example of how to get this working.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-01 19:07</div>
            <div class="timeline-body"><p>So the <code>pyproject.toml</code> you have above looks right. If you inspect the lockfile:</p>
<pre><code>[[package]]
name = &quot;torch&quot;
version = &quot;2.5.1&quot;
source = { registry = &quot;https://pypi.org/simple&quot; }
resolution-markers = [
    &quot;python_full_version &lt; &#x27;3.12&#x27; and platform_machine != &#x27;x86_64&#x27;&quot;,
    &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine != &#x27;x86_64&#x27;&quot;,
]
dependencies = [
    { name = &quot;filelock&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
    { name = &quot;fsspec&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
    { name = &quot;jinja2&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
    { name = &quot;networkx&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
    { name = &quot;setuptools&quot;, marker = &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine != &#x27;x86_64&#x27;&quot; },
    { name = &quot;sympy&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
    { name = &quot;typing-extensions&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
]
wheels = [
    { url = &quot;https://files.pythonhosted.org/packages/d1/35/e8b2daf02ce933e4518e6f5682c72fd0ed66c15910ea1fb4168f442b71c4/torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl&quot;, hash = &quot;sha256:de5b7d6740c4b636ef4db92be922f0edc425b65ed78c5076c43c42d362a45457&quot;, size = 906474467 },
    { url = &quot;https://files.pythonhosted.org/packages/40/04/bd91593a4ca178ece93ca55f27e2783aa524aaccbfda66831d59a054c31e/torch-2.5.1-cp311-cp311-manylinux2014_aarch64.whl&quot;, hash = &quot;sha256:340ce0432cad0d37f5a31be666896e16788f1adf8ad7be481196b503dad675b9&quot;, size = 91919450 },
    { url = &quot;https://files.pythonhosted.org/packages/0d/4a/e51420d46cfc90562e85af2fee912237c662ab31140ab179e49bd69401d6/torch-2.5.1-cp311-cp311-win_amd64.whl&quot;, hash = &quot;sha256:603c52d2fe06433c18b747d25f5c333f9c1d58615620578c326d66f258686f9a&quot;, size = 203098237 },
    { url = &quot;https://files.pythonhosted.org/packages/d0/db/5d9cbfbc7968d79c5c09a0bc0bc3735da079f2fd07cc10498a62b320a480/torch-2.5.1-cp311-none-macosx_11_0_arm64.whl&quot;, hash = &quot;sha256:31f8c39660962f9ae4eeec995e3049b5492eb7360dd4f07377658ef4d728fa4c&quot;, size = 63884466 },
    { url = &quot;https://files.pythonhosted.org/packages/8b/5c/36c114d120bfe10f9323ed35061bc5878cc74f3f594003854b0ea298942f/torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl&quot;, hash = &quot;sha256:ed231a4b3a5952177fafb661213d690a72caaad97d5824dd4fc17ab9e15cec03&quot;, size = 906389343 },
    { url = &quot;https://files.pythonhosted.org/packages/6d/69/d8ada8b6e0a4257556d5b4ddeb4345ea8eeaaef3c98b60d1cca197c7ad8e/torch-2.5.1-cp312-cp312-manylinux2014_aarch64.whl&quot;, hash = &quot;sha256:3f4b7f10a247e0dcd7ea97dc2d3bfbfc90302ed36d7f3952b0008d0df264e697&quot;, size = 91811673 },
    { url = &quot;https://files.pythonhosted.org/packages/5f/ba/607d013b55b9fd805db2a5c2662ec7551f1910b4eef39653eeaba182c5b2/torch-2.5.1-cp312-cp312-win_amd64.whl&quot;, hash = &quot;sha256:73e58e78f7d220917c5dbfad1a40e09df9929d3b95d25e57d9f8558f84c9a11c&quot;, size = 203046841 },
    { url = &quot;https://files.pythonhosted.org/packages/57/6c/bf52ff061da33deb9f94f4121fde7ff3058812cb7d2036c97bc167793bd1/torch-2.5.1-cp312-none-macosx_11_0_arm64.whl&quot;, hash = &quot;sha256:8c712df61101964eb11910a846514011f0b6f5920c55dbf567bff8a34163d5b1&quot;, size = 63858109 },
    { url = &quot;https://files.pythonhosted.org/packages/69/72/20cb30f3b39a9face296491a86adb6ff8f1a47a897e4d14667e6cf89d5c3/torch-2.5.1-cp313-cp313-manylinux1_x86_64.whl&quot;, hash = &quot;sha256:9b61edf3b4f6e3b0e0adda8b3960266b9009d02b37555971f4d1c8f7a05afed7&quot;, size = 906393265 },
]

[[package]]
name = &quot;torch&quot;
version = &quot;2.5.1+cu124&quot;
source = { registry = &quot;https://download.pytorch.org/whl/cu124&quot; }
resolution-markers = [
    &quot;python_full_version &lt; &#x27;3.12&#x27; and platform_machine == &#x27;x86_64&#x27;&quot;,
    &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine == &#x27;x86_64&#x27;&quot;,
]
dependencies = [
    { name = &quot;filelock&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
    { name = &quot;fsspec&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
    { name = &quot;jinja2&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
    { name = &quot;networkx&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
    { name = &quot;nvidia-cublas-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cuda-cupti-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cuda-nvrtc-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cuda-runtime-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cudnn-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cufft-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-curand-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cusolver-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-cusparse-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-nccl-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-nvjitlink-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;nvidia-nvtx-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;setuptools&quot;, marker = &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine == &#x27;x86_64&#x27;&quot; },
    { name = &quot;sympy&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
    { name = &quot;triton&quot;, marker = &quot;python_full_version &lt; &#x27;3.13&#x27; and platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
    { name = &quot;typing-extensions&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
]
wheels = [
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl&quot;, hash = &quot;sha256:6b2966ede9affe2fd69e0765691ca723ec870e0c34c7761f4d5b8e318383fdaf&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-win_amd64.whl&quot;, hash = &quot;sha256:6c8a7003ef1327479ede284b6e5ab3527d3900c2b2d401af15bcc50f2245a59f&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl&quot;, hash = &quot;sha256:bf6484bfe5bc4f92a4a1a1bf553041505e19a911f717065330eb061afe0e14d7&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-win_amd64.whl&quot;, hash = &quot;sha256:3c3f705fb125edbd77f9579fa11a138c56af8968a10fc95834cdd9fdf4f1f1a6&quot; },
    { url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp313-cp313-linux_x86_64.whl&quot;, hash = &quot;sha256:e9bebf91ede89267577911da4b0709ac6113a0cff6a1c2202c046b1ec2a51601&quot; },
]
</code></pre>
<p>You&#x27;re getting the PyPI-based PyTorch on ARM, and the CUDA-enabled PyTorch on x86.</p>
<p>You could also write the requirements like this:</p>
<pre><code>[project]
name = &quot;minimal&quot;
version = &quot;0.1.0&quot;
description = &quot;Add your description here&quot;
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.11&quot;
dependencies = [
    &quot;torch==2.5.1 ; platform_machine != &#x27;x86_64&#x27;&quot;,
    &quot;torch==2.5.1+cu124 ; platform_machine == &#x27;x86_64&#x27;&quot;,
]

[tool.uv.sources]
torch = [
    { index = &quot;pytorch-cu124&quot; }
]

[[tool.uv.index]]
name = &quot;pytorch-cu124&quot;
url = &quot;https://download.pytorch.org/whl/cu124&quot;
explicit = true
</code></pre>
<p>Then you&#x27;d get the CUDA-enabled PyTorch from the PyTorch index on x86, and the non-CUDA-enabled PyTorch from the PyTorch index on ARM.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/bepuca">@bepuca</a> on 2024-11-01 19:21</div>
            <div class="timeline-body"><p>Awesome! Thank you very much for taking the time, that does clarify. It was the missing piece to start migrating projects to <code>uv</code> ðŸŽ‰</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-01 19:58</div>
            <div class="timeline-body"><p>Awesome, glad I could help!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-01 19:58</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/thistlillo">@thistlillo</a> on 2025-04-10 07:58</div>
            <div class="timeline-body"><p>I had the same problem on an Intel iMac without an nVidia card. Running uv to re-create the environment (originally built on an M1 MacBook), I get this error message:</p>
<pre><code>$-&gt; uv pip install -r requirements.txt 
  Ã— No solution found when resolving dependencies:
  â•°â”€â–¶ Because torch==2.6.0 has no wheels with a matching platform tag (e.g., `macosx_15_0_x86_64`) and you require torch==2.6.0, we can conclude that your requirements are unsatisfiable.

      hint: Wheels are available for `torch` (v2.6.0) on the following platforms: `manylinux_2_28_aarch64`, `manylinux1_x86_64`, `macosx_11_0_arm64`, `win_amd64`
</code></pre>
<p>But running this simple command (that installs torch 2.6.0), installation of PyTorch runs fine:</p>
<pre><code>$-&gt; uv pip install torch torchvision torchaudio
Resolved 13 packages in 267ms
Prepared 13 packages in 3.28s
Installed 13 packages in 279ms
...

</code></pre>
<p>After removing the <code>PyTorch</code> lines from <code>requirements.txt</code>, I was able to recreate the environment.</p>
<p>However, nothing works. I need to decode this error message:</p>
<pre><code>A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with &#x27;pybind11&gt;=2.12&#x27;.

If you are a user of the module, the easiest solution will be to
downgrade to &#x27;numpy&lt;2&#x27; or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.
</code></pre>
<p>I have never been able to re-create an environment from the list of packages. Never, with any tool.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/noopurphalak">@noopurphalak</a> on 2025-08-27 04:02</div>
            <div class="timeline-body"><blockquote>
<p>So the <code>pyproject.toml</code> you have above looks right. If you inspect the lockfile:</p>
<p>[[package]]
name = &quot;torch&quot;
version = &quot;2.5.1&quot;
source = { registry = &quot;https://pypi.org/simple&quot; }
resolution-markers = [
&quot;python_full_version &lt; &#x27;3.12&#x27; and platform_machine != &#x27;x86_64&#x27;&quot;,
&quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine != &#x27;x86_64&#x27;&quot;,
]
dependencies = [
{ name = &quot;filelock&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
{ name = &quot;fsspec&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
{ name = &quot;jinja2&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
{ name = &quot;networkx&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
{ name = &quot;setuptools&quot;, marker = &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine != &#x27;x86_64&#x27;&quot; },
{ name = &quot;sympy&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
{ name = &quot;typing-extensions&quot;, marker = &quot;platform_machine != &#x27;x86_64&#x27;&quot; },
]
wheels = [
{ url = &quot;https://files.pythonhosted.org/packages/d1/35/e8b2daf02ce933e4518e6f5682c72fd0ed66c15910ea1fb4168f442b71c4/torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl&quot;, hash = &quot;sha256:de5b7d6740c4b636ef4db92be922f0edc425b65ed78c5076c43c42d362a45457&quot;, size = 906474467 },
{ url = &quot;https://files.pythonhosted.org/packages/40/04/bd91593a4ca178ece93ca55f27e2783aa524aaccbfda66831d59a054c31e/torch-2.5.1-cp311-cp311-manylinux2014_aarch64.whl&quot;, hash = &quot;sha256:340ce0432cad0d37f5a31be666896e16788f1adf8ad7be481196b503dad675b9&quot;, size = 91919450 },
{ url = &quot;https://files.pythonhosted.org/packages/0d/4a/e51420d46cfc90562e85af2fee912237c662ab31140ab179e49bd69401d6/torch-2.5.1-cp311-cp311-win_amd64.whl&quot;, hash = &quot;sha256:603c52d2fe06433c18b747d25f5c333f9c1d58615620578c326d66f258686f9a&quot;, size = 203098237 },
{ url = &quot;https://files.pythonhosted.org/packages/d0/db/5d9cbfbc7968d79c5c09a0bc0bc3735da079f2fd07cc10498a62b320a480/torch-2.5.1-cp311-none-macosx_11_0_arm64.whl&quot;, hash = &quot;sha256:31f8c39660962f9ae4eeec995e3049b5492eb7360dd4f07377658ef4d728fa4c&quot;, size = 63884466 },
{ url = &quot;https://files.pythonhosted.org/packages/8b/5c/36c114d120bfe10f9323ed35061bc5878cc74f3f594003854b0ea298942f/torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl&quot;, hash = &quot;sha256:ed231a4b3a5952177fafb661213d690a72caaad97d5824dd4fc17ab9e15cec03&quot;, size = 906389343 },
{ url = &quot;https://files.pythonhosted.org/packages/6d/69/d8ada8b6e0a4257556d5b4ddeb4345ea8eeaaef3c98b60d1cca197c7ad8e/torch-2.5.1-cp312-cp312-manylinux2014_aarch64.whl&quot;, hash = &quot;sha256:3f4b7f10a247e0dcd7ea97dc2d3bfbfc90302ed36d7f3952b0008d0df264e697&quot;, size = 91811673 },
{ url = &quot;https://files.pythonhosted.org/packages/5f/ba/607d013b55b9fd805db2a5c2662ec7551f1910b4eef39653eeaba182c5b2/torch-2.5.1-cp312-cp312-win_amd64.whl&quot;, hash = &quot;sha256:73e58e78f7d220917c5dbfad1a40e09df9929d3b95d25e57d9f8558f84c9a11c&quot;, size = 203046841 },
{ url = &quot;https://files.pythonhosted.org/packages/57/6c/bf52ff061da33deb9f94f4121fde7ff3058812cb7d2036c97bc167793bd1/torch-2.5.1-cp312-none-macosx_11_0_arm64.whl&quot;, hash = &quot;sha256:8c712df61101964eb11910a846514011f0b6f5920c55dbf567bff8a34163d5b1&quot;, size = 63858109 },
{ url = &quot;https://files.pythonhosted.org/packages/69/72/20cb30f3b39a9face296491a86adb6ff8f1a47a897e4d14667e6cf89d5c3/torch-2.5.1-cp313-cp313-manylinux1_x86_64.whl&quot;, hash = &quot;sha256:9b61edf3b4f6e3b0e0adda8b3960266b9009d02b37555971f4d1c8f7a05afed7&quot;, size = 906393265 },
]</p>
<p>[[package]]
name = &quot;torch&quot;
version = &quot;2.5.1+cu124&quot;
source = { registry = &quot;https://download.pytorch.org/whl/cu124&quot; }
resolution-markers = [
&quot;python_full_version &lt; &#x27;3.12&#x27; and platform_machine == &#x27;x86_64&#x27;&quot;,
&quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine == &#x27;x86_64&#x27;&quot;,
]
dependencies = [
{ name = &quot;filelock&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
{ name = &quot;fsspec&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
{ name = &quot;jinja2&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
{ name = &quot;networkx&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
{ name = &quot;nvidia-cublas-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cuda-cupti-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cuda-nvrtc-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cuda-runtime-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cudnn-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cufft-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-curand-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cusolver-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-cusparse-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-nccl-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-nvjitlink-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;nvidia-nvtx-cu12&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;setuptools&quot;, marker = &quot;python_full_version &gt;= &#x27;3.12&#x27; and platform_machine == &#x27;x86_64&#x27;&quot; },
{ name = &quot;sympy&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
{ name = &quot;triton&quot;, marker = &quot;python_full_version &lt; &#x27;3.13&#x27; and platform_machine == &#x27;x86_64&#x27; and platform_system == &#x27;Linux&#x27;&quot; },
{ name = &quot;typing-extensions&quot;, marker = &quot;platform_machine == &#x27;x86_64&#x27;&quot; },
]
wheels = [
{ url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl&quot;, hash = &quot;sha256:6b2966ede9affe2fd69e0765691ca723ec870e0c34c7761f4d5b8e318383fdaf&quot; },
{ url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-win_amd64.whl&quot;, hash = &quot;sha256:6c8a7003ef1327479ede284b6e5ab3527d3900c2b2d401af15bcc50f2245a59f&quot; },
{ url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl&quot;, hash = &quot;sha256:bf6484bfe5bc4f92a4a1a1bf553041505e19a911f717065330eb061afe0e14d7&quot; },
{ url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-win_amd64.whl&quot;, hash = &quot;sha256:3c3f705fb125edbd77f9579fa11a138c56af8968a10fc95834cdd9fdf4f1f1a6&quot; },
{ url = &quot;https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp313-cp313-linux_x86_64.whl&quot;, hash = &quot;sha256:e9bebf91ede89267577911da4b0709ac6113a0cff6a1c2202c046b1ec2a51601&quot; },
]
You&#x27;re getting the PyPI-based PyTorch on ARM, and the CUDA-enabled PyTorch on x86.</p>
<p>You could also write the requirements like this:</p>
<p>[project]
name = &quot;minimal&quot;
version = &quot;0.1.0&quot;
description = &quot;Add your description here&quot;
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.11&quot;
dependencies = [
&quot;torch==2.5.1 ; platform_machine != &#x27;x86_64&#x27;&quot;,
&quot;torch==2.5.1+cu124 ; platform_machine == &#x27;x86_64&#x27;&quot;,
]</p>
<p>[tool.uv.sources]
torch = [
{ index = &quot;pytorch-cu124&quot; }
]</p>
<p>[[tool.uv.index]]
name = &quot;pytorch-cu124&quot;
url = &quot;https://download.pytorch.org/whl/cu124&quot;
explicit = true
Then you&#x27;d get the CUDA-enabled PyTorch from the PyTorch index on x86, and the non-CUDA-enabled PyTorch from the PyTorch index on ARM.</p>
</blockquote>
<p>I did all this, then if I do <code>uv pip freeze</code>, I don&#x27;t see the <code>torch</code> package entry in it. Also, if I try to make a <code>pipeline</code> with <code>transformers</code>, I get the error <code>name &#x27;torch&#x27; is not defined</code>. Can you help on this? I also tried doing <code>uv sync</code>, but it doesn&#x27;t help either.</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:35:11 UTC
    </footer>
</body>
</html>
