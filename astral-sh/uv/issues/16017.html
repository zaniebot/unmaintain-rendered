<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>rocm7.0 and rocm7.9 should be supported as torch backends, you might also need rocm7.0+gfx110X as a label - astral-sh/uv #16017</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>rocm7.0 and rocm7.9 should be supported as torch backends, you might also need rocm7.0+gfx110X as a label</h1>

    <div class="meta">
        <span class="state-icon state-open"></span>
        <a href="https://github.com/astral-sh/uv/issues/16017">#16017</a>
        opened by <a href="https://github.com/doctorpangloss">@doctorpangloss</a>
        on 2025-09-24 17:00
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/doctorpangloss">@doctorpangloss</a></div>
            <div class="timeline-body">Summary
<p>The ROCm situation is kind of complicated</p>
<p>There are flat indices that are more supported than the pytorch ones, all here https://rocm.nightlies.amd.com/v2 - for example with support for all gfx1100, gfx1101, gfx1102 GPUs: https://rocm.nightlies.amd.com/v2/gfx110X-dgpu/torch/ . pytorch.org binaries don&#x27;t have all the GPU backends built in</p>
<p>you can see this allows alignment of the rocm, torch and container runtimes - https://hub.docker.com/r/rocm/pytorch/tags?name=rocm7.0</p>
<p>NVIDIA chooses to bundle all its GPU architectures with +cu128 builds, so +cu128_sm8x isn&#x27;t something that appears in the wild. But everything else implicitly does bundle a limited number of GPU architectures, such as SageAttention and flash_attn.</p>
<p>I understand from a product point of view you are authoring a JFrog / Artifactory thing as a solution to this problem. Of course, it is just string comparisons in 90% of cases, which you could do on the client, and in principle, for the 10% of cases, all the metadata that your backend is going to be storing from extracted wheels could be distributed with <code>uv</code> in a sqlite file, it is probably less than 10MB of static compressed text content. It is your prerogative.</p>
Platform
<p>Ubuntu</p>
Version
<p>0.8.22</p>
Python version
<p>Python 3.12.6</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">bug</span> added by <a href="https://github.com/doctorpangloss">@doctorpangloss</a> on 2025-09-24 17:00</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:40:28 UTC
    </footer>
</body>
</html>
