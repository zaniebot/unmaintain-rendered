<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Support resumable downloads - astral-sh/uv #16934</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Support resumable downloads</h1>

    <div class="meta">
        <span class="state-icon state-open"></span>
        <a href="https://github.com/astral-sh/uv/issues/16934">#16934</a>
        opened by <a href="https://github.com/wrp">@wrp</a>
        on 2025-12-02 17:47
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/wrp">@wrp</a></div>
            <div class="timeline-body"><p>If a download is interrupted, uv should cache partial data and resume on the next run using HTTP range requests.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">wish</span> added by <a href="https://github.com/konstin">@konstin</a> on 2025-12-02 19:02</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/notatallshaw">@notatallshaw</a> on 2025-12-05 15:43</div>
            <div class="timeline-body"><p>FYI pip implements this within a single command, i.e. if you do <code>pip install</code> and the typical connection retry fails it will start a new HTTP session and attempt to retry from the existing location if the remote index supports reading files from arbitrary byte locations: https://pip.pypa.io/en/stable/cli/pip/#cmdoption-resume-retries</p>
<p>If that fails pip does not attempt to implement this across command attempts. So far we&#x27;ve not had anyone complaint, and it appears to have solved the UX for users on unreliable networks.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/skorotkiewicz">@skorotkiewicz</a> on 2025-12-06 16:21</div>
            <div class="timeline-body"><p>@notatallshaw I also have this problem with UV all the time. I think resumable downloads would be best, because now I have to download the whole package again, e.g., fails 688/700 MB, and then I have to start downloading again from 0 MB.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/MUTED64">@MUTED64</a> on 2025-12-15 09:37</div>
            <div class="timeline-body"><p>Also need this feature.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2025-12-15 11:22</div>
            <div class="timeline-body"><p>If you&#x27;re hitting errors with downloads, can you share the error messages you get and some details about your network setup?</p>
<p>uv uses streaming unpacks, a lot of registries don&#x27;t support range requests and generally failures that require a manual restart are a bad experience, so I&#x27;m interested in improving the reliably of a download as it is running.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/mert-kurttutan">@mert-kurttutan</a> on 2025-12-24 10:50</div>
            <div class="timeline-body"><p>@konstin Hi there,</p>
<p>I got a similar error where I try to download torch+cuda13 version. It kept giving fetching error (for different Nvidia whl each time). But, if I try to download some of the wheels that were failed during <code>uv pip install</code>, I can download easily and quickly. This is done all inside venv created by <code>uv venv</code>. Here is my log:</p>
<pre><code>[mert@nixos:~/Desktop/projects/tt]$ uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
Resolved 28 packages in 5.52s
  × Failed to download `nvidia-cudnn-cu13==9.13.0.50`
  ├─▶ Failed to fetch: `https://pypi.nvidia.com/nvidia-cudnn-cu13/nvidia_cudnn_cu13-9.13.0.50-py3-none-manylinux_2_27_x86_64.whl`
  ├─▶ Request failed after 3 retries
  ├─▶ error sending request for url (https://pypi.nvidia.com/nvidia-cudnn-cu13/nvidia_cudnn_cu13-9.13.0.50-py3-none-manylinux_2_27_x86_64.whl)
  ╰─▶ operation timed out
  help: `nvidia-cudnn-cu13` (v9.13.0.50) was included because `torch` (v2.9.1+cu130) depends on `nvidia-cudnn-cu13`
(.venv) 
[mert@nixos:~/Desktop/projects/tt]$ uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
Resolved 28 packages in 3.90s
  × Failed to download `nvidia-cuda-nvrtc==13.0.48`
  ├─▶ Failed to fetch: `https://pypi.nvidia.com/nvidia-cuda-nvrtc/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl`
  ├─▶ Request failed after 3 retries
  ├─▶ error sending request for url (https://pypi.nvidia.com/nvidia-cuda-nvrtc/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl)
  ╰─▶ operation timed out
  help: `nvidia-cuda-nvrtc` (v13.0.48) was included because `torch` (v2.9.1+cu130) depends on `nvidia-cuda-nvrtc`
(.venv) 
[mert@nixos:~/Desktop/projects/tt]$ uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
Resolved 28 packages in 3.32s
  × Failed to download `nvidia-curand==10.4.0.35`
  ├─▶ Failed to fetch: `https://pypi.nvidia.com/nvidia-curand/nvidia_curand-10.4.0.35-py3-none-manylinux_2_27_x86_64.whl`
  ├─▶ Request failed after 3 retries
  ├─▶ error sending request for url (https://pypi.nvidia.com/nvidia-curand/nvidia_curand-10.4.0.35-py3-none-manylinux_2_27_x86_64.whl)
  ╰─▶ operation timed out
  help: `nvidia-curand` (v10.4.0.35) was included because `torch` (v2.9.1+cu130) depends on `nvidia-curand`
(.venv) 
[mert@nixos:~/Desktop/projects/tt/bounty-new]$ uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
Resolved 28 packages in 3.57s
  × Failed to download `nvidia-nvjitlink==13.0.39`
  ├─▶ Failed to fetch: `https://pypi.nvidia.com/nvidia-nvjitlink/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl`
  ├─▶ Request failed after 3 retries
  ├─▶ error sending request for url (https://pypi.nvidia.com/nvidia-nvjitlink/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl)
  ╰─▶ operation timed out
  help: `nvidia-nvjitlink` (v13.0.39) was included because `torch` (v2.9.1+cu130) depends on `nvidia-nvjitlink`
(.venv) 
[mert@nixos:~/Desktop/projects/tt]$ wget https://pypi.nvidia.com/nvidia-nvjitlink/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl
--2025-12-24 13:42:33--  https://pypi.nvidia.com/nvidia-nvjitlink/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl
Resolving pypi.nvidia.com (pypi.nvidia.com)... 23.207.210.151, 23.207.210.148
Connecting to pypi.nvidia.com (pypi.nvidia.com)|23.207.210.151|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 40709605 (39M) [application/x-gzip]
Saving to: ‘nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl’

nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2 100%[==============================================================================================================================================================&gt;]  38,82M  1,68MB/s    in 26s     

2025-12-24 13:42:59 (1,50 MB/s) - ‘nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl’ saved [40709605/40709605]

(.venv) 
[mert@nixos:~/Desktop/projects/tt]$ ls
 unet_3d   nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl

</code></pre>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:41:11 UTC
    </footer>
</body>
</html>
