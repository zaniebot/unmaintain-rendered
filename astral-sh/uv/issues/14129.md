```yaml
number: 14129
title: How to pin a specific cuda version?
type: issue
state: closed
author: sorenwacker
labels:
  - question
assignees: []
created_at: 2025-06-18T14:56:15Z
updated_at: 2025-06-19T08:25:07Z
url: https://github.com/astral-sh/uv/issues/14129
synced_at: 2026-01-10T01:57:32Z
```

# How to pin a specific cuda version?

---

_Issue opened by @sorenwacker on 2025-06-18 14:56_

### Question

I need a specific CUDA version on my deployment system, but I cannot figure out how to do this properly.
My pyproject.toml has these relevant entries:

```
dependencies = [
  ...
  "torch~=2.7.1",
  "torchvision~=0.22.1",
  "torchaudio~=2.7.1",
  "torchmetrics~=1.7.3",
  ...
]

...

[tool.uv.sources]
nx-cugraph-cu12 = { index = "nvidia" }

[[tool.uv.index]]
name = "nvidia"
url = "https://pypi.nvidia.com"
explicit = true

[[tool.uv.index]]
name = "torch-gpu"
url = "https://download.pytorch.org/whl/cu121"
explicit = true

```

But when I deploy this I get:

```
uv run python -c "import torch; print(f'Torch: {torch.__version__}, CUDA available: {torch.cuda.is_available()}, CUDA version: {torch.version.cuda}')"
Torch: 2.7.1+cu126, CUDA available: True, CUDA version: 12.6
```

What am I doing wrong?

### Platform

Ubuntu

### Version

_No response_

---

_Label `question` added by @sorenwacker on 2025-06-18 14:56_

---

_Comment by @charliermarsh on 2025-06-18 14:58_

You should add:

```toml
[tool.uv.sources]
torch = { index = "torch-gpu" }
torchvision = { index = "torch-gpu" }
torchaudio = { index = "torch-gpu" }
torchmetrics = { index = "torch-gpu" }
```

Since `torch-gpu` is marked as `explicit = true`, it will _only_ be used for dependencies that are assigned to it explicitly.

---

_Assigned to @charliermarsh by @charliermarsh on 2025-06-18 14:58_

---

_Comment by @sorenwacker on 2025-06-19 08:25_

Perfect, thank you!

---

_Closed by @sorenwacker on 2025-06-19 08:25_

---
