<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Installation of torch from pytorch CPU index fails with 'no wheels are available with a matching Python ABI' - astral-sh/uv #3437</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Installation of torch from pytorch CPU index fails with &#x27;no wheels are available with a matching Python ABI&#x27;</h1>

    <div class="meta">
        <span class="state-icon state-closed"></span>
        <a href="https://github.com/astral-sh/uv/issues/3437">#3437</a>
        opened by <a href="https://github.com/matthewfeickert">@matthewfeickert</a>
        on 2024-05-07 20:24
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/matthewfeickert">@matthewfeickert</a></div>
            <div class="timeline-body">

<ul>
<li>A minimal code snippet that reproduces the bug.</li>
</ul>
<pre><code>uv pip install --verbose --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio
</code></pre>
<ul>
<li>The command you invoked (e.g., <code>uv pip sync requirements.txt</code>), ideally including the <code>--verbose</code> flag.</li>
</ul>
<pre><code>$ docker run --rm -ti python:3.12 /bin/bash
root@4d525f9218ee:/# curl -LsSf https://astral.sh/uv/install.sh | sh
downloading uv 0.1.40 x86_64-unknown-linux-gnu
installing to /root/.cargo/bin
  uv
everything&#x27;s installed!

To add $HOME/.cargo/bin to your PATH, either restart your shell or run:

    source $HOME/.cargo/env (sh, bash, zsh)
    source $HOME/.cargo/env.fish (fish)
root@4d525f9218ee:/# . ~/.cargo/env
root@4d525f9218ee:/# uv venv
Using Python 3.12.3 interpreter at: usr/local/bin/python3
Creating virtualenv at: .venv
root@4d525f9218ee:/# . .venv/bin/activate
(.venv) root@4d525f9218ee:/# uv --version
uv 0.1.40
(.venv) root@4d525f9218ee:/# uv pip install --verbose --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio &amp;&gt; uv_install.txt
(.venv) root@4d525f9218ee:/# uv pip list  # nothing
(.venv) root@4d525f9218ee:/# uv pip install pip
Resolved 1 package in 198ms
Downloaded 1 package in 219ms
Installed 1 package in 10ms
 + pip==24.0
(.venv) root@4d525f9218ee:/# python -m pip install --verbose --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio &amp;&gt; pip_install.txt
(.venv) root@4d525f9218ee:/# python -m pip list  # expected result
Package           Version
----------------- ----------
filelock          3.13.1
fsspec            2024.2.0
Jinja2            3.1.3
MarkupSafe        2.1.5
mpmath            1.3.0
networkx          3.2.1
numpy             1.26.3
pillow            10.2.0
pip               24.0
sympy             1.12
torch             2.3.0+cpu
torchaudio        2.3.0+cpu
torchvision       0.18.0+cpu
typing_extensions 4.9.0
(.venv) root@4d525f9218ee:/# deactivate 
root@4d525f9218ee:/# rm -rf .venv
root@4d525f9218ee:/# uv venv &amp;&amp; . .venv/bin/activate
Using Python 3.12.3 interpreter at: usr/local/bin/python3
Creating virtualenv at: .venv
(.venv) root@4d525f9218ee:/# uv pip install --verbose torch torchvision torchaudio &amp;&gt; uv_pypi_install.txt
(.venv) root@4d525f9218ee:/# uv pip list  # install works, but want the cpu version instead of this
Package                  Version
------------------------ ----------
filelock                 3.14.0
fsspec                   2024.3.1
jinja2                   3.1.4
markupsafe               2.1.5
mpmath                   1.3.0
networkx                 3.3
numpy                    1.26.4
nvidia-cublas-cu12       12.1.3.1
nvidia-cuda-cupti-cu12   12.1.105
nvidia-cuda-nvrtc-cu12   12.1.105
nvidia-cuda-runtime-cu12 12.1.105
nvidia-cudnn-cu12        8.9.2.26
nvidia-cufft-cu12        11.0.2.54
nvidia-curand-cu12       10.3.2.106
nvidia-cusolver-cu12     11.4.5.107
nvidia-cusparse-cu12     12.1.0.106
nvidia-nccl-cu12         2.20.5
nvidia-nvjitlink-cu12    12.4.127
nvidia-nvtx-cu12         12.1.105
pillow                   10.3.0
sympy                    1.12
torch                    2.3.0
torchaudio               2.3.0
torchvision              0.18.0
typing-extensions        4.11.0
(.venv) root@4d525f9218ee:/#
</code></pre>
<p><a href="https://github.com/astral-sh/uv/files/15240454/uv_install.txt">uv_install.txt</a></p>
<p><a href="https://github.com/astral-sh/uv/files/15240456/pip_install.txt">pip_install.txt</a></p>
<p><a href="https://github.com/astral-sh/uv/files/15240497/uv_pypi_install.txt">uv_pypi_install.txt</a></p>
<ul>
<li>The current uv platform.</li>
</ul>
<p>Linux, though applies across platforms.</p>
<ul>
<li>The current uv version (<code>uv --version</code>).</li>
</ul>
<pre><code>uv 0.1.40
</code></pre>
Related Issues
<ul>
<li>https://github.com/astral-sh/uv/issues/2777</li>
</ul>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-07 20:28</div>
            <div class="timeline-body"><p>Did this work in previous versions?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/matthewfeickert">@matthewfeickert</a> on 2024-05-07 20:37</div>
            <div class="timeline-body"><blockquote>
<p>Did this work in previous versions?</p>
</blockquote>
<p>I&#x27;m not sure about past <code>uv</code> releases. I&#x27;m encountering this for the first time while trying to migrate the CI to use <code>uv</code> in https://github.com/CoffeaTeam/coffea.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-07 20:40</div>
            <div class="timeline-body"><p>Ah ok, no prob. Mostly was wondering if it was ‚Äúobviously a regression‚Äù from today‚Äôs release.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/matthewfeickert">@matthewfeickert</a> on 2024-05-07 20:43</div>
            <div class="timeline-body"><blockquote>
<p>Mostly was wondering if it was ‚Äúobviously a regression‚Äù from today‚Äôs release.</p>
</blockquote>
<p>Not that I know of, but I can later tonight replicate with an older <code>uv</code> release to check.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-08 02:59</div>
            <div class="timeline-body"><p>Can you try instead using <code>uv pip install --verbose --index-url https://download.pytorch.org/whl/cpu torch==2.3.0+cpu torchvision==0.18.0+cpu torchaudio==2.3.0+cpu</code>? I can&#x27;t reproduce this on ARM, but I think it differs on ARM vs. x86.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-08 02:59</div>
            <div class="timeline-body"><p>It&#x27;s explained here: <a href="https://github.com/astral-sh/uv/issues/1497">astral-sh/uv#1497</a>#issuecomment-2098896853</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/matthewfeickert">@matthewfeickert</a> on 2024-05-08 04:12</div>
            <div class="timeline-body"><blockquote>
<p>Can you try instead using <code>uv pip install --verbose --index-url https://download.pytorch.org/whl/cpu torch==2.3.0+cpu torchvision==0.18.0+cpu torchaudio==2.3.0+cpu</code>?</p>
</blockquote>
<p>Yeah, that works on <code>x86</code> Linux</p>
<pre><code>$ docker run --rm -ti -v /tmp:/tmp python:3.12 /bin/bash
root@9b29419d1e98:/# curl -LsSf https://astral.sh/uv/install.sh | sh
downloading uv 0.1.41 x86_64-unknown-linux-gnu
installing to /root/.cargo/bin
  uv
everything&#x27;s installed!

To add $HOME/.cargo/bin to your PATH, either restart your shell or run:

    source $HOME/.cargo/env (sh, bash, zsh)
    source $HOME/.cargo/env.fish (fish)
root@9b29419d1e98:/# . ~/.cargo/env
root@9b29419d1e98:/# uv venv
Using Python 3.12.3 interpreter at: usr/local/bin/python3
Creating virtualenv at: .venv
root@9b29419d1e98:/# . .venv/bin/activate
(.venv) root@9b29419d1e98:/# uv --version
uv 0.1.41
(.venv) root@9b29419d1e98:/# uv pip install --verbose --index-url https://download.pytorch.org/whl/cpu torch==2.3.0+cpu torchvision==0.18.0+cpu torchaudio==2.3.0+cpu &amp;&gt; /tmp/uv_install_cpu_moniker.txt
(.venv) root@9b29419d1e98:/# uv pip list
Package           Version
----------------- ----------
filelock          3.13.1
fsspec            2024.2.0
jinja2            3.1.3
markupsafe        2.1.5
mpmath            1.3.0
networkx          3.2.1
numpy             1.26.3
pillow            10.2.0
sympy             1.12
torch             2.3.0+cpu
torchaudio        2.3.0+cpu
torchvision       0.18.0+cpu
typing-extensions 4.9.0
(.venv) root@9b29419d1e98:/#
</code></pre>
<p><a href="https://github.com/astral-sh/uv/files/15243660/uv_install_cpu_moniker.txt">uv_install_cpu_moniker.txt</a></p>
<blockquote>
<p>It&#x27;s explained here: <a href="https://github.com/astral-sh/uv/issues/1497#issuecomment-2098896853">#1497 (comment)</a></p>
</blockquote>
<p>Huh. That is interesting. I take it that this isn&#x27;t fully expected, even though there are <a href="https://github.com/astral-sh/uv/blob/bd7860de1701da6fb3305bc379437be5d747dd97/PIP_COMPATIBILITY.md#local-version-identifiers">known differences with regards to local version identifiers</a>?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-08 04:24</div>
            <div class="timeline-body"><p>I haven&#x27;t really dug into it. My guess is it relates to some unclear decisions around how PyTorch chooses to publish their wheels (e.g., some variants include <code>+cpu</code> while others do not).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">compatibility</span> added by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-08 14:55</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-05-08 14:56</div>
            <div class="timeline-body"><p>Marking as <code>compatibility</code>. It&#x27;s not a bug in uv per se (given our documented limitations) but I wish that it worked.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/polarathene">@polarathene</a> on 2024-05-09 07:39</div>
            <div class="timeline-body"><p>You can avoid the extra specificity on those depending on <code>torch</code>, but due to <code>+cpu</code> you can&#x27;t use a semver range (<em>like <code>&gt;=2.0.0</code></em>) with <code>torch</code>:</p>
<pre><code>uv pip install --index-url https://download.pytorch.org/whl/cpu torch==2.3.0+cpu torchvision torchaudio
</code></pre>
<p><strong>NOTE:</strong> ARM64 needs to omit the <code>+cpu</code> or equivalent due to <a href="https://github.com/astral-sh/uv/issues/1497#issuecomment-2102236399">upstream inconsistency with packaging</a>. That may be resolved in future as PyTorch maintainers are open to contributions to drop the <code>+cpu</code> local identifier.</p>
<hr>
~~TLDR~~ (<em>unreliable, see gotcha</em>)
<p><strong>TL;DR:</strong> ~~Either:~~</p>
<ul>
<li>Add the <a href="https://github.com/astral-sh/uv/blob/main/PIP_COMPATIBILITY.md#local-version-identifiers">local identifier</a> (<em><code>+cpu</code> , <code>+cu121</code>, etc</em>) suffix to each package (<em>which mandates an explicit version?</em>), and they must be installed all together to resolve correctly it seems. (<em><strong>UPDATE:</strong> Only the top-level dependency needs the suffix that others would depend upon</em>)</li>
<li>~~Use PyPi as the primary index, with PyTorch as your extra index (<em>which <code>uv</code> will prioritize packages from</em>), then to ensure <code>torch</code> without a local identifier is resolvable from PyPi index you&#x27;ll need <code>--index-strategy unsafe-first-match</code>, and it&#x27;ll circle back to the PyTorch variant being successfully resolved~~ üéâ</li>
</ul>
<pre><code># Must provide an explicit torch version that the other two depend on to resolve:
$ uv pip install --index-url https://download.pytorch.org/whl/cpu torch==2.3.0+cpu torchvision torchaudio

Resolved 13 packages in 3.87s
Installed 13 packages in 234ms
 + filelock==3.13.1
 + fsspec==2024.2.0
 + jinja2==3.1.3
 + markupsafe==2.1.5
 + mpmath==1.3.0
 + networkx==3.2.1
 + numpy==1.26.3
 + pillow==10.2.0
 + sympy==1.12
 + torch==2.3.0+cpu
 + torchaudio==2.3.0+cpu
 + torchvision==0.18.0+cpu
 + typing-extensions==4.9.0
</code></pre>
<p><strong>NOTE:</strong> If you attempt to use <code>&gt;=</code> for resolution, you must quote wrap it to avoid shell redirection (<code>&gt;</code>) which creates a file (eg: <code>=0.0.0+cpu</code>); <code>uv</code> will not be aware of this to raise an error (<em>like it would when you use quote wrapping</em>):</p>
<pre><code>$ uv pip install --extra-index-url https://download.pytorch.org/whl/cpu torch==2.3.0+cpu torchvision&gt;=0.0.0+cpu &#x27;torchaudio&gt;=2.0.0+cpu&#x27;
error: Failed to parse `torchaudio&gt;=2.0.0+cpu`
  Caused by: Operator &gt;= is incompatible with versions containing non-empty local segments (`+cpu`)
</code></pre>
Resolution gotcha (cache affects selection?)
<p><strong>UPDATE:</strong> I am mistaken with the <code>--index-strategy</code> approach to resolve <code>torch</code>. While <code>uv</code> would happily resolve with this approach, the actual <code>torch</code> package selected seems to be chosen based on local cache as well:</p>
<pre><code># Failed to resolve (_related to prior discussions above with the `+cpu` target_)
$ uv pip install --index-strategy unsafe-first-match --extra-index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio

# Installed torch (PyPi) while torchvision + torchaudio were `+cu121` (PyTorch)...
$ uv pip install --index-strategy unsafe-first-match --extra-index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio
# ...
 + torch==2.3.0
 + torchaudio==2.3.0+cu121
 + torchvision==0.18.0+cu121

# Install the cuda 12.1 version from PyTorch adding it to cache:
$ uv pip install --index-strategy unsafe-first-match --extra-index-url https://download.pytorch.org/whl/cu121 torch==2.3.0+cu121 torchvision torchaudio
 - torch==2.3.0
 + torch==2.3.0+cu121

# Install again, but in a new venv (this time install without the `-cu121` suffix again):
$ uv pip install --index-strategy unsafe-first-match --extra-index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio

 + torch==2.3.0+cu121
 + torchaudio==2.3.0+cu121
 + torchvision==0.18.0+cu121
</code></pre>
<p>As can be seen above different resolution due to previous actions, now the cuda variant from PyTorch was installed instead of the PyPi torch pacakge</p>
<hr>
Original response
<pre><code>$ uv pip install torch

Resolved 21 packages in 3.35s
Downloaded 21 packages in 1m 03s
Installed 21 packages in 432ms
 + filelock==3.13.1
 + fsspec==2024.2.0
 + jinja2==3.1.3
 + markupsafe==2.1.5
 + mpmath==1.3.0
 + networkx==3.2.1
 + nvidia-cublas-cu12==12.1.3.1
 + nvidia-cuda-cupti-cu12==12.1.105
 + nvidia-cuda-nvrtc-cu12==12.1.105
 + nvidia-cuda-runtime-cu12==12.1.105
 + nvidia-cudnn-cu12==8.9.2.26
 + nvidia-cufft-cu12==11.0.2.54
 + nvidia-curand-cu12==10.3.2.106
 + nvidia-cusolver-cu12==11.4.5.107
 + nvidia-cusparse-cu12==12.1.0.106
 + nvidia-nccl-cu12==2.20.5
 + nvidia-nvjitlink-cu12==12.1.105
 + nvidia-nvtx-cu12==12.1.105
 + sympy==1.12
 + torch==2.3.0+cu121
 + typing-extensions==4.9.0

$ uv pip list

Package                  Version
------------------------ -----------
filelock                 3.13.1
fsspec                   2024.2.0
jinja2                   3.1.3
markupsafe               2.1.5
mpmath                   1.3.0
networkx                 3.2.1
nvidia-cublas-cu12       12.1.3.1
nvidia-cuda-cupti-cu12   12.1.105
nvidia-cuda-nvrtc-cu12   12.1.105
nvidia-cuda-runtime-cu12 12.1.105
nvidia-cudnn-cu12        8.9.2.26
nvidia-cufft-cu12        11.0.2.54
nvidia-curand-cu12       10.3.2.106
nvidia-cusolver-cu12     11.4.5.107
nvidia-cusparse-cu12     12.1.0.106
nvidia-nccl-cu12         2.20.5
nvidia-nvjitlink-cu12    12.1.105
nvidia-nvtx-cu12         12.1.105
sympy                    1.12
torch                    2.3.0+cu121
typing-extensions        4.9.0
</code></pre>
<p>So that installed with <code>torch</code> resolved to <code>torch 2.3.0+cu121</code>, yet when trying to add <code>torchaudio</code> or the more specific <code>torchaudio==2.3.0+cu121</code> it fails:</p>
<pre><code>$ uv pip install torchaudio==2.3.0+cu121

  √ó No solution found when resolving dependencies:
  ‚ï∞‚îÄ‚ñ∂ Because there is no version of torch==2.3.0 and torchaudio==2.3.0+cu121 depends on torch==2.3.0, we can conclude that torchaudio==2.3.0+cu121 cannot be used.
      And because you require torchaudio==2.3.0+cu121, we can conclude that the requirements are unsatisfiable.
</code></pre>
<p>Meanwhile, like with the suggested <code>+cpu</code> fix before my comment, the equivalent does resolve correctly:</p>
<pre><code>$ uv pip install --index-url https://download.pytorch.org/whl/cu121 torch==2.3.0+cu121 torchaudio==2.3.0+cu121

Resolved 23 packages in 3.98s
Downloaded 4 packages in 29.27s
Installed 23 packages in 339ms
 + filelock==3.13.1
 + fsspec==2024.2.0
 + jinja2==3.1.3
 + markupsafe==2.1.5
 + mpmath==1.3.0
 + networkx==3.2.1
 + nvidia-cublas-cu12==12.1.3.1
 + nvidia-cuda-cupti-cu12==12.1.105
 + nvidia-cuda-nvrtc-cu12==12.1.105
 + nvidia-cuda-runtime-cu12==12.1.105
 + nvidia-cudnn-cu12==8.9.2.26
 + nvidia-cufft-cu12==11.0.2.54
 + nvidia-curand-cu12==10.3.2.106
 + nvidia-cusolver-cu12==11.4.5.107
 + nvidia-cusparse-cu12==12.1.0.106
 + nvidia-nccl-cu12==2.20.5
 + nvidia-nvjitlink-cu12==12.1.105
 + nvidia-nvtx-cu12==12.1.105
 + sympy==1.12
 + torch==2.3.0+cu121
 + torchaudio==2.3.0+cu121
 + triton==2.3.0
 + typing-extensions==4.9.0
</code></pre>
<p>So there is some issue there with <code>uv</code> resolving <code>torch</code>?</p>
<ul>
<li>Even after it resolves and installs it separately as <code>torch==2.3.0+cu121</code>, it can only resolve with the explicit <code>torchaudio==2.3.0+cu121</code> at the same time, not as a 2nd install.</li>
<li>While <code>torch torchaudio</code> without the <code>+cu121</code> suffix fails to resolve.</li>
</ul>
<p>Definitely seems like some inconsistency with <code>uv</code>?</p>
<hr>
<p><strong>EDIT:</strong> Oh I see the linked issue references <a href="https://github.com/astral-sh/uv/blob/main/PIP_COMPATIBILITY.md#local-version-identifiers">this gotcha (<em>local identifiers support</em>) with <code>uv</code>, and specifically cites PyTorch</a> as an example.</p>
<p>So by setting it as an extra index URL instead, the PyTorch index will be preferred by <code>uv</code>, but you need the <code>unsafe-first-match</code> strategy so that it can find/resolve the <code>torch</code> package available at PyPi (<em>since PyTorch doesn&#x27;t provide it for an index focused on only that &quot;local identifier&quot; variant</em>), then <code>uv</code> will resolve it successfully and still prefer the PyTorch package anyway ü§∑‚Äç‚ôÇÔ∏è</p>
<pre><code>$ uv pip install \
    --index-strategy unsafe-first-match \
    --extra-index-url https://download.pytorch.org/whl/cu121 \
    torch torchaudio

Resolved 23 packages in 3.37s
Installed 23 packages in 264ms
 + filelock==3.13.1
 + fsspec==2024.2.0
 + jinja2==3.1.3
 + markupsafe==2.1.5
 + mpmath==1.3.0
 + networkx==3.2.1
 + nvidia-cublas-cu12==12.1.3.1
 + nvidia-cuda-cupti-cu12==12.1.105
 + nvidia-cuda-nvrtc-cu12==12.1.105
 + nvidia-cuda-runtime-cu12==12.1.105
 + nvidia-cudnn-cu12==8.9.2.26
 + nvidia-cufft-cu12==11.0.2.54
 + nvidia-curand-cu12==10.3.2.106
 + nvidia-cusolver-cu12==11.4.5.107
 + nvidia-cusparse-cu12==12.1.0.106
 + nvidia-nccl-cu12==2.20.5
 + nvidia-nvjitlink-cu12==12.1.105
 + nvidia-nvtx-cu12==12.1.105
 + sympy==1.12
 + torch==2.3.0+cu121
 + torchaudio==2.3.0+cu121
 + triton==2.3.0
 + typing-extensions==4.9.0
</code></pre>
<p>If you of course remove the extra index URL for PyTorch, then it&#x27;ll resolve the standard <code>torch==2.3.0</code> + <code>torchaudio==2.3.0</code> packages at PyPi and install those like you&#x27;d expect.</p>
<p>As long as the package is known to exist at PyTorch, it should always be preferred this way, even if there were a malicious version on PyPi from what I understand? Once <code>uv</code> supports the feature to lock the index to PyTorch for these specific packages that may help, but I assume that wouldn&#x27;t help drop the index strategy (<em>it may even not be able to resolve the PyPi <code>torch</code> package just so it can circle back to PyTorch?</em>).</p>
<p>Probably better to be explicit about the local identifier though, I am new to Python and was referencing someone elses <code>pip install</code> where the local identifier was implicit from the <code>--extra-index-url</code> (<em>a variable during builds to support the PyTorch variants</em>).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/wadhah101">@wadhah101</a> on 2024-06-01 12:28</div>
            <div class="timeline-body"><p>I am having almost the same problem, but the issue is</p>
<ul>
<li><p>I am using a <code>requirements.txt</code></p>
</li>
<li><p>that <code>requirements.txt</code> includes libraries that depend on torch=&quot;2.*&quot;, ( e.g, transformers )</p>
</li>
<li><p>Even if I install torch cpu using uv pip install torch=2.1.2+cpu,  then try to install the <code>requirements.txt</code> with pypi index, uv resolve the dependencies of <code>torch</code> in pypip which are are nvidia-cuda deps on linux x86 , to note , it doesn&#x27;t resolve torch itself again, So i end up with torch+cpu but with torch cuda deps installed, which massively bloats the images size</p>
</li>
<li></li>
</ul>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-06-01 12:33</div>
            <div class="timeline-body"><p>Unfortunately that&#x27;s not enough information for me to fully understand the issue, but you should consider using a constraints file in your second install, with <code>torch=2.1.2+cpu</code>? That would ensure that we respect the already-installed version during resolution.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/wadhah101">@wadhah101</a> on 2024-06-01 12:59</div>
            <div class="timeline-body"><p>Sadly specifying +cpu in constraint doesn&#x27;t work currently in uv here an example</p>
<p>requirements.txt</p>
<pre><code>easyocr==1.7.1
torch=2.1.*
</code></pre>
<p>constraint.txt</p>
<pre><code>torch==2.1.2+cpu
torchvision==0.16.2+cpu
</code></pre>
<p>when we compile the requirements to check what uv is going to resolve by default without constraints</p>
<pre><code>other packages 
....
torch==2.1.2
    # via
    #   easyocr
    #   torchvision
torchvision==0.16.2
    # via easyocr
...
</code></pre>
<p>running the command to install with torch cpu index
<code>uv pip install -r requirements.txt -c constraint.txt --extra-index-url &quot;https://pypi.org/simple https://download.pytorch.org/whl/cpu&quot;</code></p>
<p>we get</p>
<pre><code>  √ó No solution found when resolving dependencies:
  ‚ï∞‚îÄ‚ñ∂ Because there is no version of torch==2.1.2+cpu and you require torch==2.1.2+cpu, we can conclude that the requirements are
      unsatisfiable.
</code></pre>
<p>uv doesn&#x27;t qualify 2.1.2+cpu as 2.1.*  as it is not semver compliant ?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-06-01 14:23</div>
            <div class="timeline-body"><p>Thanks, I‚Äôll take a look when I can. The PyTorch stuff is always tricky.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/wadhah101">@wadhah101</a> on 2024-06-01 14:43</div>
            <div class="timeline-body"><p>Yeah, pytorch does things their own way and are not compliant with any
standard :// , they are big enough to gey away with it
I would be glad to contribute if you can point me to the relevant parts
where uv resolves the dependency tree for requirements</p>
<p>On Sat, Jun 1, 2024, 16:24 Charlie Marsh <em><strong>@</strong></em>.***&gt; wrote:</p>
<blockquote>
<p>Thanks, I‚Äôll take a look when I can. The PyTorch stuff is always tricky.</p>
<p>‚Äî
Reply to this email directly, view it on GitHub
<a href="https://github.com/astral-sh/uv/issues/3437#issuecomment-2143466601">astral-sh/uv#3437</a>, or
unsubscribe
<a href="https://github.com/notifications/unsubscribe-auth/AH4SAFWSOL6VXDXXU76ZLFLZFHKQTAVCNFSM6AAAAABHLV4XW6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBTGQ3DMNRQGE">https://github.com/notifications/unsubscribe-auth/AH4SAFWSOL6VXDXXU76ZLFLZFHKQTAVCNFSM6AAAAABHLV4XW6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBTGQ3DMNRQGE</a>
.
You are receiving this because you commented.Message ID:
<em><strong>@</strong></em>.***&gt;</p>
</blockquote>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/stefsmeets">@stefsmeets</a> on 2024-06-06 15:24</div>
            <div class="timeline-body"><p>Streamlit uses uv to install dependencies from a requirements.txt file which caused our app to fail. I managed to work around it by pinning the version number as suggested here.</p>
<pre><code>--extra-index-url https://download.pytorch.org/whl/cpu
torch==2.3.0+cpu
torchvision
torchaudio
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-22 20:35</div>
            <div class="timeline-body"><p>Ok, I believe this now works. You shouldn&#x27;t have to add <code>+cpu</code>, and we should just choose the right wheel depending on your platform.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-22 20:35</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to <a href="https://github.com/charliermarsh">@charliermarsh</a> by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-11-22 20:35</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:31:02 UTC
    </footer>
</body>
</html>
