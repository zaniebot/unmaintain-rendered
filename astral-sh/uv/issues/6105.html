<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Bytecode compilation hangs non-deterministically hangs in QEMU aarch64 docker - astral-sh/uv #6105</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Bytecode compilation hangs non-deterministically hangs in QEMU aarch64 docker</h1>

    <div class="meta">
        <span class="state-icon state-open"></span>
        <a href="https://github.com/astral-sh/uv/issues/6105">#6105</a>
        opened by <a href="https://github.com/nijel">@nijel</a>
        on 2024-08-15 11:33
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Issue opened by <a href="https://github.com/nijel">@nijel</a> on 2024-08-15 11:33</div>
            <div class="timeline-body"><!--
Thank you for taking the time to report an issue! We're glad to have you involved with uv.

If you're filing a bug report, please consider including the following information:

* A minimal code snippet that reproduces the bug.
* The command you invoked (e.g., `uv pip sync requirements.txt`), ideally including the `--verbose` flag.
* The current uv platform.
* The current uv version (`uv --version`).
-->

<p>I'm getting &quot;Bytecode timed out (60s)&quot; when running in CI on QEMU emulated arm64. It is expected that this setup is way slower than usual, but I couldn't find a way to change this timeout, as it seems hard-coded:</p>
<p>https://github.com/astral-sh/uv/blob/7551097a170e02093997b1cdaff1dd86fc30c27a/crates/uv-installer/src/compile.rs#L22</p>
<p>Having this configurable, it could be overridden in environments where byte code compilation might take long (it can be a combination of many modules being installed and a slow system).</p>
<p>I'm currently using <code>uv==0.2.36</code>.</p>
<p>The actual log:</p>
<pre><code>#9 405.5 &lt;jemalloc&gt;: MADV_DONTNEED does not work (memset will be used instead)
#9 405.5 &lt;jemalloc&gt;: (This is the expected behaviour if you are running under QEMU)
#9 406.8 Resolved 2 packages in 442ms
#9 466.2 Prepared 2 packages in 59.41s
#9 466.2 Installed 2 packages in 5ms
#9 526.4 error: Failed to bytecode-compile Python file in: app/venv/lib/python3.12/site-packages
#9 526.4   Caused by: Bytecode timed out (60s)
</code></pre>
<p>Full CI log is here: https://github.com/WeblateOrg/docker/actions/runs/10402861578/job/28808187107</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-15 11:53</div>
            <div class="timeline-body"><p>Interesting... I think that's a timeout we set <em>per file</em>, so it's intended to catch cases in which Python hangs but doesn't give us any indicator. Do you think it's plausible that a file is taking &gt; 60 seconds under QEMU? We can of course make it configurable.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/nijel">@nijel</a> on 2024-08-15 12:07</div>
            <div class="timeline-body"><p>Looking again at the log, it happens when installing cffi only, so there shouldn't be that much files to compile. It there way to log verbosely what is going on there (besides <code>--verbose</code> which I've tried)?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../../WeblateOrg/docker/pulls/2571.html">WeblateOrg/docker#2571</a> on 2024-08-15 12:57</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">needs-mre</span> added by @charliermarsh on 2024-08-15 16:16</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-08-15 16:17</div>
            <div class="timeline-body"><p>I'll have to ask @konstin when they're back from vacation.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to @konstin by @charliermarsh on 2024-08-15 16:17</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2024-08-15 16:22</div>
            <div class="timeline-body"><p>There's also <code>RUST_LOG=trace</code>, but I'm not sure you'll get much more helpful information.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/nijel">@nijel</a> on 2024-08-15 18:44</div>
            <div class="timeline-body"><p>Hmm, so far the issue didn't happen with verbose, will keep trying. On the other side, sometimes the job is terminated after uv doing something for six hours, most likely during byte compiling as well. Unfortunately it doesn't seem reproducible, it happens sometimes, making it harder to debug.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/nijel">@nijel</a> on 2024-08-16 07:03</div>
            <div class="timeline-body"><p>Here is the end of verbose log, which timed out after 6 hours:</p>
<pre><code>#9 423.7 DEBUG Finished building: pycparser==2.22
#9 462.3 DEBUG Finished building: cffi==1.17.0
#9 462.3 Prepared 2 packages in 58.82s
#9 462.3 Installed 2 packages in 6ms
#9 462.3 DEBUG Starting 4 bytecode compilation workers
#9 463.7 DEBUG Bytecode compilation worker exiting: Ok(())
#9 463.8 DEBUG Bytecode compilation worker exiting: Ok(())
</code></pre>
<p>No additional output for the rest of nearly 6 hours.</p>
<p>The command line executed here was:</p>
<pre><code>uv pip install \
    --no-cache-dir \
    --compile-bytecode \
    --no-binary :all: \
    cffi==1.17.0
</code></pre>
<p>Executed inside docker build on Qemu emulated arm64.</p>
<p>Full CI log here: https://github.com/WeblateOrg/docker/actions/runs/10411635489/job/28835914859</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2024-08-19 15:51</div>
            <div class="timeline-body"><p>I tried but couldn't reproduce this locally, it looks like a non-deterministic failure, and unfortunately i don't have any good idea where we could be happening or how QEMU plays into this.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Unassigned @konstin by @konstin on 2024-08-19 15:51</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/6958.html">astral-sh/uv#6958</a> on 2024-09-03 08:17</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/nijel">@nijel</a> on 2024-09-03 08:18</div>
            <div class="timeline-body"><p>QEMU just makes everything slow. It might be a race condition somewhere. The behavior ends up to be random - sometimes it just works, sometimes it ends up with <code>Bytecode timed out (60s)</code> and sometimes it hangs until GitHub kills it after few hours. I have enabled debug, but it really doesn't bring any useful info here:</p>
<pre><code> 1360.2 Prepared 199 packages in 14m 37s
1361.3 Installed 204 packages in 1.13s
1361.3 DEBUG Starting 4 bytecode compilation workers
1433.0 DEBUG Bytecode compilation worker exiting: Ok(())
1433.0 DEBUG Bytecode compilation worker exiting: Ok(())
1433.0 DEBUG Bytecode compilation worker exiting: Ok(())
1433.0 DEBUG Released lock at `/app/venv/.lock`
Failed to bytecode-compile Python file in: /app/venv/lib/python3.12/site-packages
1434.5   Caused by: Bytecode timed out (60s)
</code></pre>
<p>I've also tried adding <code>RUST_LOG=trace</code> but it doesn't seem to add anything useful to the logs. Can the debug logs be more detailed in the byte compilation so that it is easier to debug where actually the problem lies?</p>
<p>I <em>think</em> the problematic part is starting up the processes. GitHub workers are definitely a shared CPU cores, and slowing this with QEMU can make it easy that the Python takes long to start. So the code quite likely ends up here in some cases:</p>
<p>https://github.com/astral-sh/uv/blob/ccdf2d793bbc2401c891b799772f615a28607e79/crates/uv-installer/src/compile.rs#L308-L310</p>
<p>My rust knowledge is zero, so I don't really understand how this situation is handled in the rest of the code.</p>
<p>Anyway, I've written https://github.com/astral-sh/uv/pull/6958 to separate timeout exceptions so that it is clear whether the issue is in Python startup or in byte-compiling.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/jgehrcke">@jgehrcke</a> on 2024-10-11 09:20</div>
            <div class="timeline-body"><p>Just got</p>
<pre><code>#17 12.98 Installed 214 packages in 1.98s
#17 712.3 error: Failed to bytecode-compile Python file in: /opt/app-root/lib/python3.11/site-packages
#17 712.3   Caused by: Bytecode timed out (60s)
</code></pre>
<p>Also doing a QEMU stunt, building for arm64 on amd64.</p>
<blockquote>
<p>Interesting... I think that's a timeout we set per file, so it's intended to catch cases in which Python hangs but doesn't give us any indicator.</p>
</blockquote>
<p>Interesting.</p>
<p>I think things were making good progress, despite being slow. Any way we can tune that timeout constant?</p>
<p>This is uv 0.4.20.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/nijel">@nijel</a> on 2024-10-11 11:31</div>
            <div class="timeline-body"><p>I originally asked for configurable timeout as well, but now I doubt that increasing the timeout will do any good.</p>
<p>As mentioned before, sometimes the byte compilation just timeouts for me at GitHub after 6 hours, while normally the byte compilation takes 90 seconds. I'm sure that the VM used to run the action is not suddenly several magnitudes slower (all other steps take comparable time). So there has to be something wrong in the communication between the processes, what is exposed only occasionally in a slow environment. Sometimes the parent process detects it and fails with a timeout, sometimes it doesn't and hangs.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/Alexerson">@Alexerson</a> on 2024-10-17 17:21</div>
            <div class="timeline-body"><p>Getting this error as well on bitbucket pipelines in Docker.
We are not doing anything about QEMU. I’m currently trying to increase the size of the runner to see if this is the solution.
Locally, the build passes without issue.</p>
<p>We made some updates in our lockfile recently (and I think also moved from 3.12.6 to 3.12.7), so I wonder if there is a specific lib that we updated that triggers this behaviour, I’ll try to bisect and see which lib could be the issue.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/Alexerson">@Alexerson</a> on 2024-10-17 19:00</div>
            <div class="timeline-body"><p>Ok, so I confirm nothing changed in our code (a pipeline that passed yesterday is failing today).
There was maybe an update in the underlying docker image. I’ve noticed the version was not pinned so I’m trying to see if that helps with the reproduction.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/wv-opt-ai">@wv-opt-ai</a> on 2024-11-29 18:27</div>
            <div class="timeline-body"><p>Maybe a naive question, but could this be memory related? I've had this issue appear, and then it went away when I increased the memory limit of the runner to 2GiB, although that's of course no proof that more memory is the solution.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/nijel">@nijel</a> on 2024-11-29 18:46</div>
            <div class="timeline-body"><p>GitHub action runners where I observed this issue have 16 GB. But I haven't seen the issue for a while as well.</p>
<p>PS: Apparently I should not have written that, it is now back: https://github.com/WeblateOrg/docker/actions/runs/12100517537/job/33739218255?pr=2848</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/notatallshaw-gts">@notatallshaw-gts</a> on 2024-11-29 19:13</div>
            <div class="timeline-body"><blockquote>
<p>Maybe a naive question, but could this be memory related? I've had this issue appear, and then it went away when I increased the memory limit of the runner to 2GiB, although that's of course no proof that more memory is the solution.</p>
</blockquote>
<p>If compiling byte-code uses enough memory that the machine starts to swap thrash, then yes, this is possible.</p>
<p>One thing that I would imagine helping, is if you could set the number of bytecode workers to 1, similar to concurrent builds and concurrent downloads, but I don't see that anywhere in the documentation(?).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2024-11-29 19:30</div>
            <div class="timeline-body"><p>How many threads do you have? We currently spawn <a href="https://doc.rust-lang.org/std/thread/fn.available_parallelism.html">available_parallelism</a>-many workers.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/adgilbert">@adgilbert</a> on 2025-01-15 22:39</div>
            <div class="timeline-body"><blockquote>
<blockquote>
<p>Maybe a naive question, but could this be memory related? I've had this issue appear, and then it went away when I increased the memory limit of the runner to 2GiB, although that's of course no proof that more memory is the solution.</p>
</blockquote>
<p>If compiling byte-code uses enough memory that the machine starts to swap thrash, then yes, this is possible.</p>
<p>One thing that I would imagine helping, is if you could set the number of bytecode workers to 1, similar to concurrent builds and concurrent downloads, but I don't see that anywhere in the documentation(?).</p>
</blockquote>
<p>I also had this issue while running a pipeline with docker containers where the first step involved installing libraries with uv. Increasing the amount of memory available to the docker containers solved it for me.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/0phoff">@0phoff</a> on 2025-01-16 10:22</div>
            <div class="timeline-body"><p>I am <em>occasionally</em> encountering the same issue while emulating <code>aarch64</code>, which is annoying as I need to restart my CI/CD pipeline.</p>
<p>It would be nice to be able to configure the number of workers and timeout for bytecode compilation, so users can play around to try and get something more robust working on their hardware. :)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2025-01-16 10:23</div>
            <div class="timeline-body"><p>@adgilbert @0phoff How much memory did you have before and after, and how many core/threads does the machine have?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/10672.html">astral-sh/uv#10672</a> on 2025-01-16 10:43</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/10673.html">astral-sh/uv#10673</a> on 2025-01-16 10:56</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2025-01-16 11:16</div>
            <div class="timeline-body"><p>To add some context: On my machine, i can bytecode compile a project 4437 files in 9.15s on a single efficiency core (<code>taskset -c</code>), i.e. an average of 2ms per file. If we're hitting the 60s timeout, that's 30000x slower than that average, so i'm suspecting there's something more than just too low timeouts going on.</p>
<p>I've created a branch that logs memory statistics on timeout: https://github.com/astral-sh/uv/pull/10673. If you could try triggering the timeout with a uv build from that branch, it would be much appreciated! I've prepared a docker image at <code>ghcr.io/konstin/uv:konsti-gh-6105</code></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/notatallshaw">@notatallshaw</a> on 2025-01-16 13:06</div>
            <div class="timeline-body"><blockquote>
<p>, i can bytecode compile a project 4437 files in 9.15s on a single efficiency core (<code>taskset -c</code>), i.e. an average of 2ms per file. If we're hitting the 60s timeout, that's 30000x slower than that average, so i'm suspecting there's something more than just too low timeouts going on.</p>
</blockquote>
<p>From a statistics perspective I don't think average is a useful statistic here, I assume it only takes 1 file to exceed 60 seconds?</p>
<p>There will likely be some distribution of file timings that the average won't reveal, and the average will be skewed by empty Python files (e.g. <code>__init__.py</code>), very small Python files, and files which happen to be warm cached by the OS.</p>
<p>Do you know what the maximum time was? I would probably multiply that by 100x to see if 60 seconds is reasonable number people are hitting, as some people are probably running on hardware up to two orders of magnitude slower (CPU, disk latency, disk speed, and of course random security tools) than you have.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/theodore-s-beers">@theodore-s-beers</a> on 2025-01-16 17:51</div>
            <div class="timeline-body"><blockquote>
<p>I am <em>occasionally</em> encountering the same issue while emulating <code>aarch64</code>, which is annoying as I need to restart my CI/CD pipeline.</p>
</blockquote>
<p>I'm also dealing with this problem. I have a self-hosted runner, on a very powerful amd64 server, where I'm using Docker Buildx to build images for both amd64 and arm64. The build often hangs indefinitely at <code>uv sync</code> on the emulated arm64 side, and I can't figure out why. It's gotten worse recently.</p>
<p>edit: I should note that I have <em>not</em> seen a problem doing the inverse, i.e., building amd64 images with uv on my ARM Mac.</p>
<p>edit2: Another possibly relevant point is that I see <code>uv sync</code> either completing within a few seconds, or hanging forever.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/cpcloud">@cpcloud</a> on 2025-02-05 17:19</div>
            <div class="timeline-body"><p>I am hitting this now too, when building a nix closure under qemu (aarch64) on an x86_64 machine, that itself is a cloud VM, so there are at least two layers of virtualization in my case.</p>
<p>I can also corroborate that the timeout is not easily reproducible, sometimes &quot;just run it again&quot; seems to work.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../../ibis-project/ibis/pulls/10795.html">ibis-project/ibis#10795</a> on 2025-02-05 17:25</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/theodore-s-beers">@theodore-s-beers</a> on 2025-02-06 00:53</div>
            <div class="timeline-body"><blockquote>
<p>I am hitting this now too, when building a nix closure under qemu (aarch64) on an x86_64 machine, that itself is a cloud VM, so there are at least two layers of virtualization in my case.</p>
<p>I can also corroborate that the timeout is not easily reproducible, sometimes &quot;just run it again&quot; seems to work.</p>
</blockquote>
<p>Our builds went from unpredictably failing on this to almost always. We just switched to same-architecture runners.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/denis-savran">@denis-savran</a> on 2025-02-18 09:08</div>
            <div class="timeline-body"><p>We are experiencing a similar problem in our GitLab CI and locally when building ARM64 Docker images on AMD64 machines with QEMU emulation.
<code>uv sync</code> reaches the bytecode compilation phase and then hangs when several workers exit successfully.</p>
<p>Trailing log:</p>
<pre><code>#37 [linux/arm64 build 9/9] RUN --mount=type=cache,target=/root/.cache/uv,sharing=locked &lt;&lt;EOF (cd /project...)
#37 30.50 DEBUG No workspace root found, using project root
#37 30.50 DEBUG Calling `hatchling.build.build_wheel(&quot;/root/.cache/uv/builds-v0/.tmpa1vi9Q&quot;, {}, None)`
#37 43.10 DEBUG Finished building: my_project @ file:///project
#37 43.10       Built my_project @ file:///project
#37 43.10 DEBUG Released lock at `/root/.cache/uv/sdists-v7/path/db2c85c65f34daaf/.lock`
#37 43.15 Prepared 1 package in 25.56s
#37 43.18 Installed 1 package in 18ms
#37 43.18 DEBUG Starting 32 bytecode compilation workers
#37 47.22 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.22 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.23 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.23 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.26 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.28 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.28 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.28 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.30 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.33 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.33 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.36 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.40 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.43 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.46 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.56 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.57 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.58 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.64 DEBUG Bytecode compilation worker exiting: Ok(())
#37 47.67 DEBUG Bytecode compilation worker exiting: Ok(())
#37 48.11 DEBUG Bytecode compilation worker exiting: Ok(())
ERROR: Job failed: execution took longer than 1h0m0s seconds
</code></pre>
<p>I already reproduced the problem locally but there was no useful output in <code>strace</code>.
Processes were locked in <code>futex</code> calls.
Debug build (<code>ghcr.io/konstin/uv:konsti-gh-6105</code>) did not help.</p>
<p>Backtrace of a hanging child process:</p>
<pre><code>(gdb) backtrace -full -no-filters
#0  0x00000000006cfca1 in __syscall6 (a6=&lt;optimized out&gt;, a5=&lt;optimized out&gt;, a4=&lt;optimized out&gt;, a3=&lt;optimized out&gt;, a2=&lt;optimized out&gt;, a1=&lt;optimized out&gt;, n=&lt;optimized out&gt;)
    at ./arch/x86_64/syscall_arch.h:59
        ret = &lt;optimized out&gt;
        r10 = 0
        r8 = 0
        r9 = 139826955288576
#1  syscall (n=&lt;optimized out&gt;) at src/misc/syscall.c:20
        ap = {{gp_offset = 48, fp_offset = 0, overflow_arg_area = 0x7f2cb7be89c0, reg_save_area = 0x7f2cb7be8980}}
        a = 7609100
        b = 0
        c = 4294967295
        d = 0
        e = 0
        f = &lt;optimized out&gt;
#2  0x0000000000671caf in qemu_event_wait ()
No symbol table info available.
#3  0x000000000067c5e0 in call_rcu_thread ()
No symbol table info available.
#4  0x0000000000671ee2 in qemu_thread_start ()
No symbol table info available.
#5  0x00000000006daadc in start (p=0x7f2cb7be8a90) at src/thread/pthread_create.c:203
        args = 0x7f2cb7be8a90
        state = &lt;optimized out&gt;
#6  0x00000000006dc0d4 in __clone () at src/thread/x86_64/clone.s:22
No locals.
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2025-02-18 09:24</div>
            <div class="timeline-body"><p>Thank you for the backtrace!</p>
<p>Can you share what you ran to reproduce this locally?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/denis-savran">@denis-savran</a> on 2025-02-19 15:37</div>
            <div class="timeline-body"><p>Temporary solution with timeouts and retries for <code>uv sync</code> commands which helped to fix failing Docker builds:</p>
<pre><code class="language-dockerfile"># syntax=docker/dockerfile:1
FROM ubuntu:noble AS build

# https://docs.docker.com/reference/dockerfile/#automatic-platform-args-in-the-global-scope
ARG TARGETARCH
ARG python_version=3.12

SHELL [&quot;/bin/sh&quot;, &quot;-exc&quot;]

...

# https://github.com/astral-sh/uv/pkgs/container/uv
COPY --link --from=ghcr.io/astral-sh/uv:0.6 /uv /usr/local/bin/uv

# https://docs.astral.sh/uv/configuration/environment/
ENV UV_PYTHON=&quot;python$python_version&quot; \
  UV_PYTHON_DOWNLOADS=never \
  UV_PROJECT_ENVIRONMENT=/app \
  UV_LINK_MODE=copy \
  PYTHONOPTIMIZE=1

COPY pyproject.toml uv.lock /project/

RUN --mount=type=cache,id=/root/.cache/uv-$TARGETARCH,target=/root/.cache/uv,sharing=locked &lt;&lt;EOF
cd /project
uv sync \
  $([ &quot;$TARGETARCH&quot; = 'arm64' ] &amp;&amp; echo '--verbose') \
  --no-dev \
  --no-install-project \
  --locked

timeout 15m sh -ex &lt;&lt;EOT
until timeout 5m uv sync \
  $([ &quot;$TARGETARCH&quot; = 'arm64' ] &amp;&amp; echo '--verbose') \
  --no-dev \
  --no-install-project \
  --compile-bytecode
do
  echo &quot;Bytecode compilation timed out&quot;
  echo &quot;Retrying&quot;
done
EOT
EOF

COPY VERSION /project/
COPY src/ /project/src

RUN --mount=type=cache,id=/root/.cache/uv-$TARGETARCH,target=/root/.cache/uv,sharing=locked &lt;&lt;EOF
cd /project
sed -Ei &quot;s/^(version = \&quot;)0\.0\.0(\&quot;)$/\1$(cat VERSION)\2/&quot; pyproject.toml
uv sync \
  $([ &quot;$TARGETARCH&quot; = 'arm64' ] &amp;&amp; echo '--verbose') \
  --no-dev \
  --no-editable

timeout 9m sh -ex &lt;&lt;EOT
until timeout 3m uv sync \
  $([ &quot;$TARGETARCH&quot; = 'arm64' ] &amp;&amp; echo '--verbose') \
  --no-dev \
  --no-editable \
  --compile-bytecode
do
  echo &quot;Bytecode compilation timed out&quot;
  echo &quot;Retrying&quot;
done
EOT
EOF
</code></pre>
<p>Log with one retry:</p>
<pre><code>#15 0.823 + timeout 15m sh -ex
#15 0.859 + timeout 5m uv sync --verbose --no-dev --no-install-project --compile-bytecode
#15 0.880 &lt;jemalloc&gt;: MADV_DONTNEED does not work (memset will be used instead)
#15 0.880 &lt;jemalloc&gt;: (This is the expected behaviour if you are running under QEMU)
#15 1.115 DEBUG uv 0.6.1
#15 1.120 DEBUG Found project root: `/project`
#15 1.122 DEBUG No workspace root found, using project root
#15 1.125 DEBUG Acquired lock for `/project`
#15 1.127 DEBUG Using Python request `3.12` from explicit request
#15 1.128 DEBUG Checking for Python environment at `/app`
#15 1.136 DEBUG The virtual environment's Python version satisfies `3.12`
#15 1.137 DEBUG Released lock at `/tmp/uv-b95abc02d7f2ad9b.lock`
#15 1.192 DEBUG Using request timeout of 30s
#15 1.210 DEBUG Found static `pyproject.toml` for: my_project @ file:///project
#15 1.211 DEBUG No workspace root found, using project root
#15 1.223 DEBUG Existing `uv.lock` satisfies workspace requirements
#15 1.223 Resolved 69 packages in 38ms
#15 1.228 DEBUG Omitting `my_project` from resolution due to `--no-install-project`
#15 1.239 DEBUG Using request timeout of 30s
#15 1.248 DEBUG Requirement already installed: alembic==1.14.0
...
#15 1.250 DEBUG Requirement already installed: six==1.17.0
#15 1.253 DEBUG Starting 16 bytecode compilation workers
#15 95.27 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.28 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.30 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.32 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.37 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.38 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.46 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.62 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.73 DEBUG Bytecode compilation worker exiting: Ok(())
#15 95.85 DEBUG Bytecode compilation worker exiting: Ok(())
#15 96.17 DEBUG Bytecode compilation worker exiting: Ok(())
#15 96.35 DEBUG Bytecode compilation worker exiting: Ok(())
#15 97.11 DEBUG Bytecode compilation worker exiting: Ok(())
#15 97.44 DEBUG Bytecode compilation worker exiting: Ok(())
#15 98.93 DEBUG Bytecode compilation worker exiting: Ok(())
#15 300.9 + echo Bytecode compilation timed out
#15 300.9 Bytecode compilation timed out
#15 300.9 Retrying
#15 300.9 + echo Retrying
#15 300.9 + timeout 5m uv sync --verbose --no-dev --no-install-project --compile-bytecode
#15 300.9 &lt;jemalloc&gt;: MADV_DONTNEED does not work (memset will be used instead)
#15 300.9 &lt;jemalloc&gt;: (This is the expected behaviour if you are running under QEMU)
#15 301.1 DEBUG uv 0.6.1
#15 301.1 DEBUG Found project root: `/project`
#15 301.1 DEBUG No workspace root found, using project root
#15 301.1 DEBUG Acquired lock for `/project`
#15 301.1 DEBUG Using Python request `3.12` from explicit request
#15 301.1 DEBUG Checking for Python environment at `/app`
#15 301.2 DEBUG The virtual environment's Python version satisfies `3.12`
#15 301.2 DEBUG Released lock at `/tmp/uv-b95abc02d7f2ad9b.lock`
#15 301.2 DEBUG Using request timeout of 30s
#15 301.2 DEBUG Found static `pyproject.toml` for: my_project @ file:///project
#15 301.2 DEBUG No workspace root found, using project root
#15 301.2 DEBUG Existing `uv.lock` satisfies workspace requirements
#15 301.2 Resolved 69 packages in 38ms
#15 301.2 DEBUG Omitting `my_project` from resolution due to `--no-install-project`
#15 301.3 DEBUG Using request timeout of 30s
#15 301.3 DEBUG Requirement already installed: alembic==1.14.0
...
#15 301.3 DEBUG Requirement already installed: six==1.17.0
#15 301.3 DEBUG Starting 16 bytecode compilation workers
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 DEBUG Bytecode compilation worker exiting: Ok(())
#15 304.1 Bytecode compiled 864 files in 2.87s
#15 DONE 304.2s
</code></pre>
<p>I will to try to provide more details on local reproduction of the problem later.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Renamed from "Bytecode timed out (60s)" to "Bytecode compilation hangs non-deterministically hangs in QEMU aarch64 docker" by @konstin on 2025-02-24 10:03</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">needs-mre</span> removed by @konstin on 2025-02-24 10:03</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">bug</span> added by @konstin on 2025-02-24 10:03</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2025-02-24 10:10</div>
            <div class="timeline-body"><p>I've made a minimal reproducer for this: https://github.com/konstin/gh11699</p>
<p>It looks like the specific combination needs is aarch64 through qemu in a docker container.</p>
<p>I tried to debug this with gdb but it couldn't get it to work. Running gdb in the container errors due to qemu limitations and attaching gdb from the host directly can't resolve any symbols. Using the recommended gdbserver just hangs for me, using <code>debug.sh</code> from the repo in the container:</p>
<pre><code>$ gdb-multiarch
(gdb) set debug remote 1
(gdb) target remote localhost:7777
Remote debugging using localhost:7777
[remote] start_remote_1: enter
  [remote] Sending packet: $qSupported:multiprocess+;swbreak+;hwbreak+;qRelocInsn+;fork-events+;vfork-events+;exec-events+;vContSupported+;QThreadEvents+;QThreadOptions+;no-resumed+;memory-tagging+;xmlRegisters=i386#72
  [remote] Sending packet: $qSupported:multiprocess+;swbreak+;hwbreak+;qRelocInsn+;fork-events+;vfork-events+;exec-events+;vContSupported+;QThreadEvents+;QThreadOptions+;no-resumed+;memory-tagging+;xmlRegisters=i386#72
  [remote] Sending packet: $qSupported:multiprocess+;swbreak+;hwbreak+;qRelocInsn+;fork-events+;vfork-events+;exec-events+;vContSupported+;QThreadEvents+;QThreadOptions+;no-resumed+;memory-tagging+;xmlRegisters=i386#72
  [remote] Sending packet: $qSupported:multiprocess+;swbreak+;hwbreak+;qRelocInsn+;fork-events+;vfork-events+;exec-events+;vContSupported+;QThreadEvents+;QThreadOptions+;no-resumed+;memory-tagging+;xmlRegisters=i386#72
  [remote] getpkt: Timed out.
  [remote] getpkt: Timed out.
  [remote] getpkt: Timed out.
Ignoring packet error, continuing...
  [remote] packet_ok: Packet qSupported (supported-packets) is supported
warning: unrecognized item &quot;timeout&quot; in &quot;qSupported&quot; response
  [remote] Sending packet: $vCont?#49
  [remote] Sending packet: $vCont?#49
  [remote] Sending packet: $vCont?#49
  [remote] Sending packet: $vCont?#49
  [remote] getpkt: Timed out.
  [remote] getpkt: Timed out.
  [remote] getpkt: Timed out.
Ignoring packet error, continuing...
  [remote] packet_ok: Packet vCont (verbose-resume) is supported
  [remote] Sending packet: $vMustReplyEmpty#3a
  [remote] Sending packet: $vMustReplyEmpty#3a
  [remote] Sending packet: $vMustReplyEmpty#3a
  [remote] Sending packet: $vMustReplyEmpty#3a
  [remote] getpkt: Timed out.
  [remote] getpkt: Timed out.
  [remote] getpkt: Timed out.
Ignoring packet error, continuing...
[remote] start_remote_1: exit
Remote replied unexpectedly to 'vMustReplyEmpty': timeout
</code></pre>
<p>I'm only getting this timeout when the gdbserver is running, if it isn't running it's a plain <code>could not connect: Connection timed out.</code>. Both container and host are running ubuntu 24.04.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../issues/11699.html">astral-sh/uv#11699</a> on 2025-02-24 10:13</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/geofft">@geofft</a> on 2025-02-28 17:02</div>
            <div class="timeline-body"><p>I think I've tracked this down to a fairly straightforward bug in qemu-user and reported it here: https://gitlab.com/qemu-project/qemu/-/issues/2846</p>
<p>Basically there's an internal structure in qemu-user that tracks open FDs and translates them for the guest process, and they use a lock to protect that structure. But you're not supposed to mix and match locks and fork, and so if your emulated program has one thread that is in the middle of opening or closing a file descriptor while another thread forks, nothing will ever unlock the lock in the child, and so it will deadlock as soon as it tries to open or close a file descriptor.</p>
<p>I think they just didn't think about the fact that they run fork (to handle guest fork) when they added the lock. One &quot;solution&quot; would be to revert the patch adding the lock but presumably that will cause a different race condition.</p>
<p>A more practical workaround would be to reduce the concurrency of bytecode compilation with <code>UV_CONCURRENT_INSTALLS=1</code>, new in 0.6.3 (#11615).</p>
<p>For what it's worth, gdb has tons of problems with getting needlessly confused about Linux namespaces / containers. In this case, since qemu-user-static exists outside of the container, there's no need for gdb to even bother. You can force it to skip its misguided detection logic by giving it a full path, like <code>gdb -p 12345 /usr/bin/qemu-user-static</code> (from outside the container). No gdbserver is necessary. On Ubuntu, I had to set up <a href="https://documentation.ubuntu.com/server/reference/debugging/debug-symbol-packages/index.html">ddebs</a> (debuginfod didn't seem to work for qemu-user-static), <code>apt install qemu-user-static-dbgsym</code>, and also do a <code>sudo apt-get source qemu</code> inside /usr/src and rename the directory appropriately to get source code.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/jgehrcke">@jgehrcke</a> on 2025-02-28 17:16</div>
            <div class="timeline-body"><p>Very nice work @geofft -- I also read https://gitlab.com/qemu-project/qemu/-/issues/2846 with pleasure.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">external</span> added by @zanieb on 2025-02-28 17:18</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/vicchi">@vicchi</a> on 2025-03-03 10:15</div>
            <div class="timeline-body"><blockquote>
<p>A more practical workaround would be to reduce the concurrency of bytecode compilation with UV_CONCURRENT_INSTALLS=1, new in 0.6.3 (https://github.com/astral-sh/uv/pull/11615).</p>
</blockquote>
<p>I can confirm that running my build test case (from #11699) with <code>UV_COMPILE_BYTECODE=1</code> and <code>UV_CONCURRENT_INSTALLS=1</code> is a very viable and working workaround. Thanks @geofft !</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../../ITISFoundation/osparc-simcore/pulls/7604.html">ITISFoundation/osparc-simcore#7604</a> on 2025-04-29 07:09</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../../ray-project/ray/issues/50961.html">ray-project/ray#50961</a> on 2025-05-25 05:10</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/tobiasmcnulty">@tobiasmcnulty</a> on 2025-05-30 18:31</div>
            <div class="timeline-body"><p>FWIW, I hit this error in a qemu VM on amd64 as well.</p>
<pre><code>12.56 Prepared 134 packages in 9.68s
114.4 Installed 134 packages in 1m 41s
198.9 error: Failed to bytecode-compile Python file in: /venv/lib/python3.12/site-packages
198.9   Caused by: Bytecode timed out (60s) compiling file: `/venv/lib/python3.12/site-packages/foo/bar.py`
</code></pre>
<pre><code>  /usr/bin/docker version
  Client:
   Version:           26.1.3
   API version:       1.45
   Go version:        go1.22.2
   Git commit:        26.1.3-0ubuntu1~22.04.1
   Built:             Mon Oct 14 21:24:40 2024
   OS/Arch:           linux/amd64
   Context:           default
  Server:
   Engine:
    Version:          26.1.3
    API version:      1.45 (minimum version 1.24)
    Go version:       go1.22.2
    Git commit:       26.1.3-0ubuntu1~22.04.1
    Built:            Mon Oct 14 21:24:40 2024
    OS/Arch:          linux/amd64
    Experimental:     false
   containerd:
    Version:          1.7.24
    GitCommit:        
   runc:
    Version:          1.1.12-0ubuntu2~22.04.1
    GitCommit:        
   docker-init:
    Version:          0.19.0
    GitCommit:     
  /usr/bin/docker info
  Client:
   Version:    26.1.3
   Context:    default
   Debug Mode: false
   Plugins:
    buildx: Docker Buildx (Docker Inc.)
      Version:  v0.24.0
      Path:     /home/runner/.docker/cli-plugins/docker-buildx
    compose: Docker Compose (Docker Inc.)
      Version:  2.27.1+ds1-0ubuntu1~22.04.1
      Path:     /usr/libexec/docker/cli-plugins/docker-compose
 &lt;snip&gt;
   Kernel Version: 5.15.0-131-generic
   Operating System: Ubuntu 22.04.5 LTS
   OSType: linux
   Architecture: x86_64
&lt;snip&gt;

</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/geofft">@geofft</a> on 2025-05-30 18:43</div>
            <div class="timeline-body"><p>Just to confirm, do you mean a qemu <em>VM</em>, i.e., with its own x86-64 kernel / full operating system? Or is this qemu-user for a cross-arch container (maybe also inside a qemu or other VM)?</p>
<p>I would expect this bug to affect qemu-user on all platforms—I guess it's just that aarch64 containers on x86_64 CI runners is a very common use case which is why the bug was reported that way. But the code with the bug isn't used in qemu-system, so if this is happening without qemu-user involved, then we might want to dig into that as a separate issue.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/tobiasmcnulty">@tobiasmcnulty</a> on 2025-05-30 18:57</div>
            <div class="timeline-body"><p>@geofft Thanks for the quick response &amp; sorry if I'm confusing matters. I am seeing this error building a Docker image on an amd64 QMEU virtual machine with its own x86-64 kernel / full operating system. The image is being built by a self-hosted GitHub Actions runner using https://github.com/docker/setup-buildx-action &amp; https://github.com/docker/build-push-action. I would not think it would use <code>qemu-user</code> since I'm not targeting a different platform, but I could be mistaken. FWIW, I did <em>not</em> observe this error when the image was built using the same GitHub Actions <code>steps</code> in a non-self-hosted runner. I set <code>UV_CONCURRENT_INSTALLS=1</code> as you suggested and haven't reproduced the error again yet.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/tobiasmcnulty">@tobiasmcnulty</a> on 2025-05-30 20:16</div>
            <div class="timeline-body"><p>@geofft For further clarification, I was using the <code>docker-container</code> driver for setup-buildx-action during the previous test. I am not sure if <code>docker-container</code> uses <code>qemu-user</code> or not.</p>
<p>I need to switch to the <code>docker</code> driver for other reasons, so I'll let you know if I still encounter the issue with it or not (I suspect not).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/14369.html">astral-sh/uv#14369</a> on 2025-06-30 09:01</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-10 01:30:32 UTC
    </footer>
</body>
</html>
