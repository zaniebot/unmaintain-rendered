```yaml
number: 6030
title: "`uv pip install` fails to install `llama-cpp-python`"
type: issue
state: closed
author: alonsosilvaallende
labels:
  - external
assignees: []
created_at: 2024-08-12T09:29:28Z
updated_at: 2024-08-13T14:28:09Z
url: https://github.com/astral-sh/uv/issues/6030
synced_at: 2026-01-10T01:57:13Z
```

# `uv pip install` fails to install `llama-cpp-python`

---

_Issue opened by @alonsosilvaallende on 2024-08-12 09:29_

Thank you very much for this package. I'm encountering the following issue. In an emptly virtual environment, when I run
```console
uv pip install llama-cpp-python --verbose
```
I obtain
```console
DEBUG uv 0.2.35
DEBUG Searching for Python interpreter in system path
DEBUG Found `cpython-3.10.12-linux-x86_64-gnu` at `/home/asilva/test-llama-cpp/.venv/bin/python3` (active virtual environment)
DEBUG Using Python 3.10.12 environment at test-llama-cpp/.venv/bin/python3
DEBUG Acquired lock for `test-llama-cpp/.venv`
DEBUG At least one requirement is not satisfied: llama-cpp-python
DEBUG Using request timeout of 30s
DEBUG Solving with installed Python version: 3.10.12
DEBUG Adding direct dependency: llama-cpp-python*
DEBUG Found fresh response for: https://pypi.org/simple/llama-cpp-python/
DEBUG Searching for a compatible version of llama-cpp-python (*)
DEBUG Selecting: llama-cpp-python==0.2.87 [compatible] (llama_cpp_python-0.2.87.tar.gz)
DEBUG Acquired lock for `/home/asilva/.cache/uv/built-wheels-v3/pypi/llama-cpp-python/0.2.87`
DEBUG No cache entry for: https://files.pythonhosted.org/packages/a2/63/7b9fe4c6b9d52e1ed2c2689711cdbb60314cf13474c626accd4213cf937c/llama_cpp_python-0.2.87.tar.gz
DEBUG Downloading source distribution: llama-cpp-python==0.2.87
error: Failed to download and build `llama-cpp-python==0.2.87`
  Caused by: Failed to extract archive
  Caused by: failed to unpack `/home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h`
  Caused by: File exists (os error 17) when symlinking ../ggml/include/ggml-alloc.h to /home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h
```

Current uv version: uv 0.2.35

Current platform:
PRETTY_NAME="Ubuntu 22.04.4 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.4 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy


---

_Comment by @baggiponte on 2024-08-12 09:47_

Uhm, I cannot decipher the last line: 

```
Caused by: File exists (os error 17) when symlinking ../ggml/include/ggml-alloc.h to /home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h
```

There might be another version of ggml-alloc somewhere in the machine?

---

_Comment by @alonsosilvaallende on 2024-08-12 10:04_

> Uhm, I cannot decipher the last line:
> 
> ```
> Caused by: File exists (os error 17) when symlinking ../ggml/include/ggml-alloc.h to /home/asilva/.cache/uv/built-wheels-v3/.tmpvYPWA5/llama_cpp_python-0.2.87/vendor/llama.cpp/spm-headers/ggml-alloc.h
> ```
> 
> There might be another version of ggml-alloc somewhere in the machine?

Thank you very much for your answer @baggiponte 
Any pointers on how to check if that is the case and how to remove it?

---

_Comment by @alonsosilvaallende on 2024-08-12 11:44_

I tested other versions of llama-cpp-python. Up to version `llama-cpp-python=0.2.85` it works without any problem. The last two versions `llama-cpp-python=0.2.86` and `llama-cpp-python=0.2.87` do not work with `uv` anymore.

---

_Label `compatibility` added by @charliermarsh on 2024-08-12 14:36_

---

_Comment by @charliermarsh on 2024-08-12 14:47_

I can take a look. My guess is we're refusing to overwrite a file with a symlink, or something like that.

---

_Assigned to @charliermarsh by @charliermarsh on 2024-08-12 14:48_

---

_Comment by @charliermarsh on 2024-08-12 17:53_

I think there might be something wrong with this source distribution. If you untar it, every entry is duplicated: `tar -tf llama_cpp_python-0.2.87.tar.gz`:

```
...
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-bpe.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-bpe.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-spm.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-1-spm.cpp
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-random.py
llama_cpp_python-0.2.87/vendor/llama.cpp/tests/test-tokenizer-random.py
...
```

I don't see the same issue with the prior release. Do you mind reporting this on the library itself?

---

_Label `compatibility` removed by @charliermarsh on 2024-08-12 17:55_

---

_Label `upstream` added by @charliermarsh on 2024-08-12 17:55_

---

_Comment by @charliermarsh on 2024-08-12 17:55_

Nevermind, I commented on https://github.com/abetlen/llama-cpp-python/issues/1670.

---

_Comment by @henryiii on 2024-08-13 02:41_

scikit-build-core 0.10.2 should fix this (thanks to @abetlen)!

---

_Comment by @alonsosilvaallende on 2024-08-13 03:29_

Great. Thank you very much. Should I close it then or leave it open until fixed in case other people are having the same issue?

---

_Comment by @zanieb on 2024-08-13 03:39_

Best to close it so we know we don't need to do anything here. Thanks!

---

_Closed by @zanieb on 2024-08-13 03:39_

---

_Comment by @alonsosilvaallende on 2024-08-13 14:28_

For others looking at this issue, this has been solved in `llama-cpp-python==0.2.88`

---
