<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Does auto option in ``torch-backend`` preview only select the highest supported CUDA version? - astral-sh/uv #12357</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Does auto option in ``torch-backend`` preview only select the highest supported CUDA version?</h1>

    <div class="meta">
        <span class="state state-closed">Closed</span>
        <a href="https://github.com/astral-sh/uv/issues/12357">#12357</a>
        opened by <a href="https://github.com/FishAlchemist">@FishAlchemist</a>
        on 2025-03-21 08:19
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Issue opened by <a href="https://github.com/FishAlchemist">@FishAlchemist</a> on 2025-03-21 08:19</div>
            <div class="timeline-body"><h3>Question</h3>
<p>Ref:</p>
<ul>
<li>https://github.com/astral-sh/uv/pull/12070</li>
</ul>
<p>What I actually want to ask is, even if the Python version is not supported, will uv still choose to install the highest compatible version of CUDA?</p>
<h3>Command:</h3>
<pre><code> uv pip install &quot;torch&lt;=2.4,&gt;=2.0&quot; --torch-backend=auto --preview --verbose --dry-run
</code></pre>
<p>When using Python 3.8, if I use <strong>auto</strong> for installation, uv will try to find wheels from CUDA 12.6, resulting in not finding any wheels, and the error messages are somewhat confusing</p>
<pre><code>DEBUG uv 0.6.9 (3d9460278 2025-03-20)
DEBUG Searching for default Python interpreter in virtual environments
DEBUG Found `cpython-3.8.20-windows-x86_64-none` at `C:\Users\[user-name]\Documents\source\temp_rustpython\.venv\Scripts\python.exe` (virtual environment)
DEBUG Using Python 3.8.20 environment at: .venv
DEBUG Acquired lock for `.venv`
DEBUG At least one requirement is not satisfied: torch&gt;=2.0, &lt;=2.4
DEBUG Detected CUDA driver version from `nvidia-smi`: 572.83
DEBUG Using request timeout of 30s
DEBUG Solving with installed Python version: 3.8.20
DEBUG Solving with target Python version: &gt;=3.8.20
DEBUG Adding direct dependency: torch&gt;=2.0, &lt;=2.4+
DEBUG Acquired lock for `C:\Users\[user-name]\AppData\Local\uv\cache\simple-v15\index\d349d1d03fe1cebf\torch.lock`
DEBUG No cache entry for: https://download.pytorch.org/whl/cu126/torch/
DEBUG Released lock at `C:\Users\[user-name]\AppData\Local\uv\cache\simple-v15\index\d349d1d03fe1cebf\torch.lock`
DEBUG Searching for a compatible version of torch (&gt;=2.0, &lt;=2.4+)
DEBUG Searching for a compatible version of torch (&gt;=2.0, &lt;2.0.1 | &gt;2.0.1, &lt;=2.4+)
DEBUG Searching for a compatible version of torch (&gt;2.0.0, &lt;2.0.1 | &gt;2.0.1, &lt;=2.4+)
DEBUG No compatible version found for: torch
  × No solution found when resolving dependencies:
  ╰─▶ Because only the following versions of torch are available:
          torch&lt;=2.0.0
          torch==2.0.1
          torch&gt;2.4
      and torch&gt;=2.0.0,&lt;=2.0.1 has no wheels with a matching platform tag (e.g., `win_amd64`), we can conclude that torch&gt;=2.0.0,&lt;=2.0.1 cannot be used.
      And because you require torch&gt;=2.0,&lt;=2.4, we can conclude that your requirements are unsatisfiable.

      hint: Wheels are available for `torch` (v2.0.1) on the following platform: `manylinux2014_aarch64`
DEBUG Released lock at `C:\Users\[user-name]\Documents\source\temp_rustpython\.venv\.lock`
</code></pre>
<p>You can follow this table to filter out CUDA versions that are not supported by the current Python version. If the resolver has difficulty doing this, perhaps you could also choose to inform the user of the lack of support in the error message.
https://github.com/pytorch/pytorch/blob/main/RELEASE.md#release-compatibility-matrix
Apart from the latest PyTorch version, I guess the supported Python versions are fixed</p>
<h3>Platform</h3>
<p>Windows 11 x86-64</p>
<h3>Version</h3>
<p>uv 0.6.9 (3d9460278 2025-03-20) | Python 3.8.20</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">question</span> added by @FishAlchemist on 2025-03-21 08:19</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Renamed from "Does auto option in torch-backend preview only select the highest supported CUDA version?" to "Does auto option in ``torch-backend`` preview only select the highest supported CUDA version?" by @FishAlchemist on 2025-03-21 08:19</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to @charliermarsh by @zanieb on 2025-03-21 13:38</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2025-03-21 14:03</div>
            <div class="timeline-body"><p>Yeah it should be trying each compatible version in sequence. This should be easy to fix. Thanks.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/12385.html">astral-sh/uv#12385</a> on 2025-03-22 00:37</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @charliermarsh on 2025-03-22 15:53</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @charliermarsh on 2025-03-22 15:53</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-09 23:35:03 UTC
    </footer>
</body>
</html>
