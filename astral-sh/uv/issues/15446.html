<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>0.8.13 install vllm in cuda env, but install torch with cpu - astral-sh/uv #15446</title>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../index.html">Back to index</a>
    </div>

    <h1>0.8.13 install vllm in cuda env, but install torch with cpu</h1>

    <div class="meta">
        <span class="state state-closed">Closed</span>
        <a href="https://github.com/astral-sh/uv/issues/15446">#15446</a>
        opened by <a href="https://github.com/yang-ybb">@yang-ybb</a>
        on 2025-08-22 06:41
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Issue opened by <a href="https://github.com/yang-ybb">@yang-ybb</a> on 2025-08-22 06:41</div>
            <div class="timeline-body"><h3>Summary</h3>
<pre><code>+ pip3 install uv
Looking in indexes: https://bytedpypi.byted.org/simple, https://bytedpypi.byted.org/simple
Collecting uv
  Downloading https://bytedpypi.byted.org/packages/uv/uv-0.8.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.4/19.4 MB 90.7 MB/s eta 0:00:00
tiktok-thoth-infer-dev4-76a4a284-ai-64c9dcfb6-6gqvj 2025-08-20 +03:20:11 service isn't ready!
Installing collected packages: uv
Successfully installed uv-0.8.12
</code></pre>
<pre><code>uv pip install -U vllm --torch-backend=auto --extra-index-url https://wheels.vllm.ai/b2f6c247a9b84556a8ea0e75bb4a2db765ff3315
+ torch==2.7.1+cu128
 + torchaudio==2.7.1+cu128
 + torchvision==0.22.1+cu128
</code></pre>
<p>there are 4 GPUs in my env. firstly, i use uv=<strong>0.8.12</strong>, install vllm, will install torch==<strong>2.7.1+cu128</strong>.</p>
<pre><code>+ pip3 install uv
Looking in indexes: https://bytedpypi.byted.org/simple, https://bytedpypi.byted.org/simple
Collecting uv
  Downloading https://bytedpypi.byted.org/packages/uv/uv-0.8.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.5/19.5 MB 144.8 MB/s eta 0:00:00
Installing collected packages: uv
search-tiktok-tako-response-model-t-550433c0-de-88d7ddfbc-ks44r 2025-08-22 +06:09:29 service isn't ready!
Successfully installed uv-0.8.13
</code></pre>
<pre><code>uv pip install -U vllm --torch-backend=auto --extra-index-url https://wheels.vllm.ai/b2f6c247a9b84556a8ea0e75bb4a2db765ff3315
+ torch==2.7.1+cpu
 + torchaudio==2.7.1+cpu
 + torchvision==0.22.1+cpu
</code></pre>
<p>secondly, i use uv=<strong>0.8.13</strong>, install vllm, will install torch==<strong>2.7.1+cpu</strong>, seem wrong.</p>
<h3>Platform</h3>
<p>Linux 5.15.120.bsk.2-amd64 x86_64 GNU/Linux</p>
<h3>Version</h3>
<p>uv 0.8.13</p>
<h3>Python version</h3>
<p><em>No response</em></p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">bug</span> added by @yang-ybb on 2025-08-22 06:41</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Assigned to @charliermarsh by @charliermarsh on 2025-08-22 10:05</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Referenced in <a href="../pulls/15449.html">astral-sh/uv#15449</a> on 2025-08-22 10:38</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @charliermarsh on 2025-08-22 11:06</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-09 23:28:29 UTC
    </footer>
</body>
</html>
