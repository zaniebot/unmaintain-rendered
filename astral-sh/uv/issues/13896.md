```yaml
number: 13896
title: uv rebuilds dependencies if they take too long to install
type: issue
state: closed
author: saagarjha
labels:
  - question
assignees: []
created_at: 2025-06-07T04:04:57Z
updated_at: 2025-07-03T12:10:22Z
url: https://github.com/astral-sh/uv/issues/13896
synced_at: 2026-01-10T01:57:31Z
```

# uv rebuilds dependencies if they take too long to install

---

_Issue opened by @saagarjha on 2025-06-07 04:04_

### Summary

Some dependencies take a long time to install. For example, installing PyTorch from source (yes, I know it doesn't work out of the box with build isolation: just bear with me). Most packages from pypi have a max-age for 600 seconds, so if the build takes longer than this uv will consider them to be stale and trigger another build for anything that depends on them. This seems undesirable. I understand the idea of respecting the header but it seems really odd to me that you wouldn't consider the dependency to be valid across a single command-line invocation.

I've attached a log with an attempt at building PyTorch. Again, I understand that PyTorch installs are not supported by uv at the moment. My concern is solely why it goes around to build it again once it's finished resolving packages.

If you want to reproduce this, here's my pyproject.toml:

```toml
[project]
name = "test"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "torch",
]

[tool.uv.sources]
torch = { path = "deps/pytorch", editable = true }
```

Just dump a fresh PyTorch clone into the folder. But I think this is really more a problem with any build that takes forever, so take your pick of a large project. That said, here's a log: [log.txt](https://github.com/user-attachments/files/20636932/log.txt)

### Platform

Ubuntu 22.04 arm64

### Version

uv 0.7.12

### Python version

Python 3.10.12

---

_Label `bug` added by @saagarjha on 2025-06-07 04:04_

---

_Comment by @zanieb on 2025-06-07 04:48_

I'm not sure your diagnosis is correct, can you share more details about why you think that's what's happening?

PyPI cache headers shouldn't be involved at all for a local dependency like this.

From the logs, it looks like we first invoke `setuptools.build_meta:__legacy__.get_requires_for_build_editable()` because there's no static metadata for your local pytorch and we need to invoke its build system to determine its requirements. The second invocation is `etuptools.build_meta:__legacy__.build_editable`, which actually installs the package.

---

_Label `bug` removed by @zanieb on 2025-06-07 04:48_

---

_Label `question` added by @zanieb on 2025-06-07 04:48_

---

_Comment by @saagarjha on 2025-06-07 07:22_

I might be misunderstanding but it seems like it is actually trying to install it twice. For example, `setuptools.build_meta:__legacy__.get_requires_for_build_editable()` appears twice in the log. In particular, you can see that it does actually resolve all the packages ("Resolved 12 packages in 11m 22s") but then it goes back around to redo the work.

---

_Comment by @zanieb on 2025-06-07 14:25_

`get_requires_for_build_editable` isn't an install though, it's getting the requirements for the build environment. We need two build environments, one for `prepare_metadata_for_build_editable` (which is called after the first invocation to get metadata) and one for `build_editable` (which is called after the second to build an installable wheel).

See https://peps.python.org/pep-0660/#prepare-metadata-for-build-editable

It seems like a problem with torch that it'd build the whole package in order to determine the metadata, that build backend method is intended to be a fast-path?

---

_Comment by @saagarjha on 2025-06-17 18:35_

Hi, sorry, I just had some time to look at this more. I think I understand what you're saying but I'm not sure if I understand this in the context of the build log. I can see that it runs the following steps:

```
DEBUG Calling `setuptools.build_meta:__legacy__.get_requires_for_build_editable()`
DEBUG Calling `setuptools.build_meta:__legacy__.prepare_metadata_for_build_editable()`
DEBUG Calling `setuptools.build_meta:__legacy__.get_requires_for_build_editable()`
DEBUG Calling `setuptools.build_meta:__legacy__.build_editable("/home/ubuntu/.cache/uv/builds-v0/.tmpdZmWYo", {}, None)`
```

So, it does actually try to build it just once. Apparently PyTorch just calls cmake itself in the `prepare_metadata_for_build_editable` stage. Is this reasonable? I'm not sure if I should ask them why they're doing it because this is "weird" or if this is just totally normal for packages to do.

---

_Referenced in [astral-sh/uv#14269](../../astral-sh/uv/issues/14269.md) on 2025-06-26 17:27_

---

_Comment by @zanieb on 2025-06-26 17:28_

> Apparently PyTorch just calls cmake itself in the prepare_metadata_for_build_editable stage. Is this reasonable? I'm not sure if I should ask them why they're doing it because this is "weird" or if this is just totally normal for packages to do.

I'm not sure. I think it probably is reasonable, but they should avoid doing a bunch of repeated work when that happens?

---

_Comment by @saagarjha on 2025-07-03 12:10_

I think PyTorch just landed changes to not do this anymore, so I'm going to close this. I don't think I could demonstrate it was a uv bug anyway, so thanks for putting up for me while I tried to diagnose it.

---

_Closed by @saagarjha on 2025-07-03 12:10_

---
