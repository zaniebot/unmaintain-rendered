```yaml
number: 11945
title: "uv failed to resolve pytorch dependencies in project with `cu126`"
type: issue
state: closed
author: hv0905
labels:
  - external
assignees: []
created_at: 2025-03-04T10:18:27Z
updated_at: 2025-03-05T16:18:54Z
url: https://github.com/astral-sh/uv/issues/11945
synced_at: 2026-01-10T01:57:27Z
```

# uv failed to resolve pytorch dependencies in project with `cu126`

---

_Issue opened by @hv0905 on 2025-03-04 10:18_

### Summary

I'm trying to integrate `PyTorch` with uv following [this tutorial](https://docs.astral.sh/uv/guides/integration/pytorch/#configuring-accelerators-with-optional-dependencies), and I wrote the following `pyproject.toml` file:

```toml
[project]
# ...
requires-python = ">=3.10,<3.13"
dependencies = [
  # some pytorch-unrelated dependencies
]

[dependency-groups]
dev = [
  # some pytorch-unrelated dependencies
]

# All the dependencies that related to PyTorch goes here
[project.optional-dependencies]
cpu = [
    "torch>=2.6.0",
    "torchvision",
    "easypaddleocr>=0.3",
    "transformers>=4.49.0",
]
cu126 = [
    "torch>=2.6.0",
    "torchvision",
    "easypaddleocr>=0.3",
    "transformers>=4.49.0",
]
cu124 = [
    "torch>=2.6.0",
    "torchvision",
    "easypaddleocr>=0.3",
    "transformers>=4.49.0",
]
cu118 = [
    "torch>=2.6.0",
    "torchvision",
    "easypaddleocr>=0.3",
    "transformers>=4.49.0",
]

[tool.uv]
conflicts = [
    [
        { extra = "cpu" },
        { extra = "cu126" },
        { extra = "cu124" },
        { extra = "cu118" },
    ],
]

[tool.uv.sources]
torch = [
    { index = "pytorch-cpu", extra = "cpu" },
    { index = "pytorch-cu126", extra = "cu126" },
    { index = "pytorch-cu124", extra = "cu124" },
    { index = "pytorch-cu118", extra = "cu118" }
]
torchvision = [
    { index = "pytorch-cpu", extra = "cpu" },
    { index = "pytorch-cu126", extra = "cu126" },
    { index = "pytorch-cu124", extra = "cu124" },
    { index = "pytorch-cu118", extra = "cu118" }
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu118"
url = "https://download.pytorch.org/whl/cu118"
explicit = true

```
*(View the full pyproject.toml [here](https://github.com/hv0905/NekoImageGallery/blob/7f6c4a2bce18cd79415aef5d562217fa9aea760f/pyproject.toml#L1), if necessary)*


However, when I'm trying to run `uv sync --extra cu126 --dev` on a Linux x86_64 platform, uv failed to resolve some nvidia-related dependencies (like nvidia-cudnn-cu12 and nvidia-cublas-cu12) for torch==2.6.0+cu126, which cause torch failed to start.

![Image](https://github.com/user-attachments/assets/36c727de-3670-4d45-9b49-3659a0511e1f)

Iâ€˜ve reviewed `uv.lock` file generated by `uv`, it seems that uv resolve a wrong list of dependencies of torch, as follows:

![Image](https://github.com/user-attachments/assets/d0f77b38-7d77-434d-9967-bb5493cb0c8a)

However, torch==2.6.0+cu126 requires more dependencies than this, checking it by `uv run pip show torch`

![Image](https://github.com/user-attachments/assets/3b17b3f3-717d-448c-bcc1-62864e00d6e2)

It seems that this is a bug of uv dependencies resolver.

### Platform

Ubuntu 24.04 x86_64

### Version

v0.6.4

### Python version

python 3.12.7

---

_Label `bug` added by @hv0905 on 2025-03-04 10:18_

---

_Comment by @charliermarsh on 2025-03-04 15:21_

The problem here is that PyTorch is returning inconsistent metadata for those wheels.

If you download https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp310-cp310-linux_aarch64.whl.metadata, you'll see:

```
Requires-Dist: filelock
Requires-Dist: typing-extensions>=4.10.0
Requires-Dist: setuptools; python_version >= "3.12"
Requires-Dist: sympy==1.13.1; python_version >= "3.9"
Requires-Dist: networkx
Requires-Dist: jinja2
Requires-Dist: fsspec
Provides-Extra: optree
Requires-Dist: optree>=0.13.0; extra == "optree"
Provides-Extra: opt-einsum
Requires-Dist: opt-einsum>=3.3; extra == "opt-einsum"
```

But if you download https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp310-cp310-manylinux_2_28_x86_64.whl.metadata, you'll see:

```
Requires-Dist: filelock
Requires-Dist: typing-extensions>=4.10.0
Requires-Dist: setuptools; python_version >= "3.12"
Requires-Dist: sympy==1.13.1; python_version >= "3.9"
Requires-Dist: networkx
Requires-Dist: jinja2
Requires-Dist: fsspec
Requires-Dist: nvidia-cuda-nvrtc-cu12==12.6.77; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cuda-runtime-cu12==12.6.77; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cuda-cupti-cu12==12.6.80; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cudnn-cu12==9.5.1.17; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cublas-cu12==12.6.4.1; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cufft-cu12==11.3.0.4; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-curand-cu12==10.3.7.77; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cusolver-cu12==11.7.1.2; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cusparse-cu12==12.5.4.2; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-cusparselt-cu12==0.6.3; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-nccl-cu12==2.21.5; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-nvtx-cu12==12.6.77; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: nvidia-nvjitlink-cu12==12.6.85; platform_system == "Linux" and platform_machine == "x86_64"
Requires-Dist: triton==3.2.0; platform_system == "Linux" and platform_machine == "x86_64"
Provides-Extra: optree
Requires-Dist: optree>=0.13.0; extra == "optree"
Provides-Extra: opt-einsum
Requires-Dist: opt-einsum>=3.3; extra == "opt-einsum"
```

This has to be solved in PyTorch: https://github.com/pytorch/pytorch/issues/146679 / https://github.com/pytorch/pytorch/pull/145021.


---

_Label `bug` removed by @charliermarsh on 2025-03-04 15:22_

---

_Label `external` added by @charliermarsh on 2025-03-04 15:22_

---

_Comment by @charliermarsh on 2025-03-04 15:23_

I can give you a manual workaround in the meantime.

---

_Comment by @charliermarsh on 2025-03-04 15:31_

You can add this to your `pyproject.toml` to override the registry metadata:

```toml
[[tool.uv.dependency-metadata]]
name = "torch"
version = "2.6.0+cu126"
requires-python = ">=3.9.0"
requires-dist = [
    'filelock',
    'typing-extensions>=4.10.0',
    'setuptools; python_version >= "3.12"',
    'sympy==1.13.1; python_version >= "3.9"',
    'networkx',
    'jinja2',
    'fsspec',
    'nvidia-cuda-nvrtc-cu12==12.6.77; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cuda-runtime-cu12==12.6.77; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cuda-cupti-cu12==12.6.80; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cudnn-cu12==9.5.1.17; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cublas-cu12==12.6.4.1; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cufft-cu12==11.3.0.4; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-curand-cu12==10.3.7.77; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cusolver-cu12==11.7.1.2; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cusparse-cu12==12.5.4.2; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-cusparselt-cu12==0.6.3; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-nccl-cu12==2.21.5; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-nvtx-cu12==12.6.77; platform_system == "Linux" and platform_machine == "x86_64"',
    'nvidia-nvjitlink-cu12==12.6.85; platform_system == "Linux" and platform_machine == "x86_64"',
    'triton==3.2.0; platform_system == "Linux" and platform_machine == "x86_64"',
    'optree>=0.13.0; extra == "optree"',
    'opt-einsum>=3.3; extra == "opt-einsum"',
]
provides-extras = [
    'optree',
    'opt-einsum'
]
```

---

_Comment by @hv0905 on 2025-03-04 15:38_

Thanks! I will stay on cuda 12.4 until Pytorch team resolve this problem in the next release.

---

_Renamed from "uv failed to resolve pytorch dependencies in project using extra markers" to "uv failed to resolve pytorch dependencies in project with `cu126`" by @charliermarsh on 2025-03-04 15:38_

---

_Comment by @charliermarsh on 2025-03-05 16:18_

Gonna close for now since this is "upstream" and we have a workaround here.

---

_Closed by @charliermarsh on 2025-03-05 16:18_

---

_Assigned to @charliermarsh by @charliermarsh on 2025-03-05 16:18_

---
