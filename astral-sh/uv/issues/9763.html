<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Can't run tensorrt_llm with uv - astral-sh/uv #9763</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Can't run tensorrt_llm with uv</h1>

    <div class="meta">
        <span class="state state-open">Open</span>
        <a href="https://github.com/astral-sh/uv/issues/9763">#9763</a>
        opened by <a href="https://github.com/twmht">@twmht</a>
        on 2024-12-10 04:02
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Issue opened by <a href="https://github.com/twmht">@twmht</a> on 2024-12-10 04:02</div>
            <div class="timeline-body"><p>Hi,</p>
<p>I use uv (from python3.10.12)  to install <a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html">tensort_llm</a></p>
<pre><code class="language-bash">uv pip install tensorrt_llm
</code></pre>
<p>and then import tensorrt_llm</p>
<pre><code class="language-pythom">import tensorrt_llm
</code></pre>
<p>but it would show</p>
<pre><code>Traceback (most recent call last):
  File &quot;/home/shared/WhisperS2T/examples/test_import.py&quot;, line 1, in &lt;module&gt;
    import tensorrt_llm
  File &quot;/home/acer/.venv/tensorrt-llm/lib/python3.10/site-packages/tensorrt_llm/__init__.py&quot;, line 32, in &lt;module&gt;
    import tensorrt_llm.functional as functional
  File &quot;/home/acer/.venv/tensorrt-llm/lib/python3.10/site-packages/tensorrt_llm/functional.py&quot;, line 25, in &lt;module&gt;
    import tensorrt as trt
  File &quot;/home/acer/.venv/tensorrt-llm/lib/python3.10/site-packages/tensorrt/__init__.py&quot;, line 18, in &lt;module&gt;
    from tensorrt_bindings import *
ModuleNotFoundError: No module named 'tensorrt_bindings'
</code></pre>
<p>But if you install it through pip, there will be no problems at all.</p>
<p>Any idea?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/rohnsha0">@rohnsha0</a> on 2024-12-10 07:04</div>
            <div class="timeline-body"><p>using <code>uv add</code> doesn't help?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/twmht">@twmht</a> on 2024-12-10 07:10</div>
            <div class="timeline-body"><p>I didn't try <code>uv add</code>, but what is the big difference between it and <code>uv pip install</code>?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/twmht">@twmht</a> on 2024-12-10 07:14</div>
            <div class="timeline-body"><p>Based on my current observations, it seems that using uv pip install tensorrt_llm misses some dependencies during installation.</p>
<p>For example, when I install it using the regular pip install, it automatically installs tensorrt-bindings and tensorrt-libs as well.</p>
<pre><code>tensorrt==9.2.0.post12.dev5
tensorrt-bindings==9.2.0.post12.dev5
tensorrt-libs==9.2.0.post12.dev5
tensorrt-llm==0.8.0.dev2024012301
</code></pre>
<p>However, uv only installs tensorrt and does not install tensorrt-bindings or tensorrt-libs.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-12-10 13:33</div>
            <div class="timeline-body"><p>Can you include the <code>--verbose</code> logs from <code>uv pip install</code>? (Are you sure that you installed from the nvidia index, and that you activated the virtual environment?)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">question</span> added by @charliermarsh on 2024-12-10 13:33</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2024-12-10 17:04</div>
            <div class="timeline-body"><p>Can reproduce in <code>nvidia/cuda:12.6.3-cudnn-devel-ubuntu24.04</code>. The pypi packages uses https://github.com/wheel-next/wheel-stub as build backend, maybe @emmatyping-nv knows.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/emmatyping-nv">@emmatyping-nv</a> on 2024-12-10 19:44</div>
            <div class="timeline-body"><p>Does uv inspect the PKG-INFO to decide dependencies or does it build the wheel and look at what the backend generates? <code>tensorrt_cu12</code> does a similar thing to wheel-stub to acquire the real wheel via an sdist build, but I don't think it lists it's dependencies in the PKG-INFO.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-12-10 19:48</div>
            <div class="timeline-body"><p>If available for PyPI dependencies, yes, we'll use PKG-INFO. If not, we ask the backend. It's all heuristics so we could probably refine it.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/melMass">@melMass</a> on 2024-12-27 12:21</div>
            <div class="timeline-body"><p>I solved this issue by using <code>--pre</code>:</p>
<pre><code class="language-diff">uv add --group trt tensorrt --pre # I'm using a group, omit it for regular dep
# Ignoring existing lockfile due to change in pre-release mode: `if-necessary-or-explicit` vs. `allow`
# Resolved 153 packages in 883ms
#   Built tensorrt==10.7.0
# Prepared 7 packages in 36.67s
# Uninstalled 5 packages in 198ms
# Installed 8 packages in 207ms
- beautifulsoup4==4.12.3
+ beautifulsoup4==4.13.0b2
- cython==3.0.11
+ cython==3.1.0a1
- omegaconf==2.3.0
+ omegaconf==2.4.0.dev3
- safetensors==0.4.5
+ safetensors==0.4.6.dev0
- scipy==1.14.1
+ scipy==1.15.0rc2
+ tensorrt==10.7.0
+ tensorrt-bindings==9.3.0.post12.dev1
+ tensorrt-cu12==10.7.0
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/emmatyping-nv">@emmatyping-nv</a> on 2024-12-30 16:18</div>
            <div class="timeline-body"><p>Perhaps after resolving dependencies via <code>PKG-INFO</code>, after the wheel build you could verify the generated wheel dependencies match the <code>PKG-INFO</code>, and backtrack if they disagree. This lets the current behavior continue as a pre-fetch optimization while still ending up with the correct result.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/konstin">@konstin</a> on 2025-01-02 15:52</div>
            <div class="timeline-body"><p>There's a number of packages with <code>PKG-INFO</code> that doesn't match the final <code>METADATA</code>, so i'm afraid we can't dismiss those packages.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/emmatyping-nv">@emmatyping-nv</a> on 2025-01-02 16:21</div>
            <div class="timeline-body"><blockquote>
<p>There's a number of packages with PKG-INFO that doesn't match the final METADATA, so i'm afraid we can't dismiss those packages.</p>
</blockquote>
<p>I think if you re-solve dependencies with the new requirements if the PKG-INFO and METADATA do not match, you won't have issues unless information is somehow not captured in the METADATA file that is captured in the PKG-INFO (which should not happen unless a build backend is misbehaving).</p>
<p>To be more precise with what I said above, I'm imagining uv having the following behavior:</p>
<ol>
<li>uv selects an sdist to be installed (say, as part of normal package resolution)</li>
<li>you download the dependencies from PKG-INFO, and store the list of those</li>
<li>you build the sdist into a wheel (probably concurrently with the downloads in (2)</li>
<li>you check if the METADATA matches the PKG-INFO <em>requirements/extras only</em></li>
<li>Then you either
a. find that they match and continue with the resolution normally
b. find that they differ and feed this information back to the resolver so that it can take this additional information into account</li>
</ol>
<p>This way if the requirements listed in METADATA matches PKG-INFO, you get the current speed benefits with a tiny bit of extra checks. If they differ, package installation/resolution will be slower, but still eventually come out with the correct answer.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/emmatyping-nv">@emmatyping-nv</a> on 2025-01-02 17:00</div>
            <div class="timeline-body"><p>@melMass</p>
<blockquote>
<p>I solved this issue by using --pre</p>
</blockquote>
<p>I would recommend instead to <a href="https://docs.astral.sh/uv/configuration/indexes/#defining-an-index">use an index</a> to point to the official NVIDIA PyPI server and the sub-packages <code>tensorrt-cu12</code> points to:</p>
<pre><code class="language-toml">[project]
dependencies = [
    &quot;tensorrt-cu12-libs&quot;, # ref: https://github.com/astral-sh/uv/issues/9763
    &quot;tensorrt-cu12-bindings&quot;, # ref: https://github.com/astral-sh/uv/issues/9763
]

[tool.uv.sources]
tensorrt-cu12-libs = { index = &quot;nvidia&quot; }
tensorrt-cu12-bindings = { index = &quot;nvidia&quot; }

[[tool.uv.index]]
name = &quot;nvidia&quot;
url = &quot;https://pypi.nvidia.com/&quot;
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/henryzhuhr">@henryzhuhr</a> on 2025-08-08 17:34</div>
            <div class="timeline-body"><p>my <code>pyproject.toml</code> is:</p>
<pre><code class="language-toml">[project]
name = &quot;my project&quot;
version = &quot;0.1.0&quot;
description = &quot;Add your description here&quot;
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.11, &lt;3.13&quot;
dependencies = [
    &quot;huggingface-hub[cli]&gt;=0.34.3&quot;,
    &quot;loguru&gt;=0.7.3&quot;,
    &quot;transformers[torch]&gt;=4.54.1&quot;,
]
</code></pre>
<p>When I use the command <code>uv add tensorrt-llm</code> to add the dependency, I encounter the following error:</p>
<pre><code class="language-bash">error: Package `flashinfer` attempted to resolve via URL: git+https://github.com/flashinfer-ai/flashinfer.git@06309c4e. URL dependencies must be expressed as direct requirements or constraints. Consider adding `flashinfer @ git+https://github.com/flashinfer-ai/flashinfer.git@06309c4e` to your dependencies or constraints file.
</code></pre>
<p>However, when I add with <code>uv pip install tensorrt-llm</code>, everything works fine.</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-09 23:35:01 UTC
    </footer>
</body>
</html>
