<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Add auto-detection for AMD GPUs - astral-sh/uv #14176</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Add auto-detection for AMD GPUs</h1>

    <div class="meta">
        <span class="state-icon state-merged"></span>
        <a href="https://github.com/astral-sh/uv/pull/14176">#14176</a>
        opened by <a href="https://github.com/charliermarsh">@charliermarsh</a>
        on 2025-06-21 01:59
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Pull request opened by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2025-06-21 01:59</div>
            <div class="timeline-body"><h2>Summary</h2>
<p>Allows <code>--torch-backend=auto</code> to detect AMD GPUs. The approach is fairly well-documented inline, but I opted for <code>rocm_agent_enumerator</code> over (e.g.) <code>rocminfo</code> since it seems to be the recommended approach for scripting: https://rocm.docs.amd.com/projects/rocminfo/en/latest/how-to/use-rocm-agent-enumerator.html.</p>
<p>Closes https://github.com/astral-sh/uv/issues/14086.</p>
<h2>Test Plan</h2>
<pre><code>root@rocm-jupyter-gpu-mi300x1-192gb-devcloud-atl1:~# ./uv-linux-libc-11fb582c5c046bae09766ceddd276dcc5bb41218/uv pip install torch --torch-backend=auto
Resolved 11 packages in 251ms
Prepared 2 packages in 6ms
Installed 11 packages in 257ms
 + filelock==3.18.0
 + fsspec==2025.5.1
 + jinja2==3.1.6
 + markupsafe==3.0.2
 + mpmath==1.3.0
 + networkx==3.5
 + pytorch-triton-rocm==3.3.1
 + setuptools==80.9.0
 + sympy==1.14.0
 + torch==2.7.1+rocm6.3
 + typing-extensions==4.14.0
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">enhancement</span> added by @charliermarsh on 2025-06-21 01:59</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Review requested from @geofft by @charliermarsh on 2025-06-21 02:34</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/zanieb">@zanieb</a> reviewed on 2025-06-21 13:20</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/zanieb">@zanieb</a> on <code>docs/guides/integration/pytorch.md</code>:447 on 2025-06-21 13:20</div>
            <div class="timeline-body"><p>Perhaps, now that you have another &quot;and&quot;</p>
<pre><code class="language-suggestion">When enabled, uv will query for the installed CUDA driver and AMD GPU versions then use the
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/zanieb">@zanieb</a> approved on 2025-06-21 13:20</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="event">Merged by @charliermarsh on 2025-06-21 15:21</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @charliermarsh on 2025-06-21 15:21</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Branch deleted on 2025-06-21 15:21</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-10 07:27:35 UTC
    </footer>
</body>
</html>
