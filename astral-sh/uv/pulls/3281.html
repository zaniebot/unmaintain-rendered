<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Run resolve/install benchmarks in ci - astral-sh/uv #3281</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Run resolve/install benchmarks in ci</h1>

    <div class="meta">
        <span class="state-icon state-merged"></span>
        <a href="https://github.com/astral-sh/uv/pull/3281">#3281</a>
        opened by <a href="https://github.com/ibraheemdev">@ibraheemdev</a>
        on 2024-04-26 16:41
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header">Pull request opened by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-26 16:41</div>
            <div class="timeline-body"><h2>Summary</h2>
<p>Runs resolver benchmarks in CI with codspeed.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/codspeed-hq[bot]">@codspeed-hq[bot]</a> on 2024-04-26 19:42</div>
            <div class="timeline-body"><h2><a href="https://codspeed.io/astral-sh/uv/branches/ibraheemdev:benches">CodSpeed Performance Report</a></h2>
<h3>Congrats! CodSpeed is installed ğŸ‰</h3>
<p><code>ğŸ†•</code> <strong>12 new benchmarks were detected.</strong></p>
<p>You will start to see performance impacts in the reports once the benchmarks are run from your default branch.</p>
<details>
  <summary><h3>Detected benchmarks</h3></summary>

<ul>
<li><code>build_platform_tags[burntsushi-archlinux]</code> (6.3 ms)</li>
<li><code>wheelname_parsing[flyte-long-compatible]</code> (21 Âµs)</li>
<li><code>wheelname_parsing[flyte-long-incompatible]</code> (26.3 Âµs)</li>
<li><code>wheelname_parsing[flyte-short-compatible]</code> (11.9 Âµs)</li>
<li><code>wheelname_parsing[flyte-short-incompatible]</code> (12.2 Âµs)</li>
<li><code>wheelname_parsing_failure[flyte-long-extension]</code> (2.6 Âµs)</li>
<li><code>wheelname_parsing_failure[flyte-short-extension]</code> (2.6 Âµs)</li>
<li><code>wheelname_tag_compatibility[flyte-long-compatible]</code> (2.6 Âµs)</li>
<li><code>wheelname_tag_compatibility[flyte-long-incompatible]</code> (1.8 Âµs)</li>
<li><code>wheelname_tag_compatibility[flyte-short-compatible]</code> (2.5 Âµs)</li>
<li><code>wheelname_tag_compatibility[flyte-short-incompatible]</code> (1.1 Âµs)</li>
<li><code>resolve_warm_jupyter</code> (366.7 ms)</li>
</ul>
</details>

</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> reviewed on 2024-04-26 19:48</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on <code>crates/bench/benches/uv.rs</code>:85 on 2024-04-26 19:48</div>
            <div class="timeline-body"><p>We can probably use <code>uv venv</code> here instead of <code>virtualenv</code>, just to remove the external dependency.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> reviewed on 2024-04-26 19:48</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on <code>crates/bench/benches/uv.rs</code>:85 on 2024-04-26 19:48</div>
            <div class="timeline-body"><p>I think we use <code>virtualenv</code> in the benchmark script just because that's designed to benchmark uv against other tools, and so it removes one source of (possible) variance.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Review comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on <code>crates/bench/benches/uv.rs</code>:24 on 2024-04-26 20:41</div>
            <div class="timeline-body"><p>Should the benchmarks be run on more/different inputs?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/ibraheemdev">@ibraheemdev</a> reviewed on 2024-04-26 20:41</div>
            <div class="timeline-body"></div>
        </div>
        <div class="timeline-entry">
            <div class="event">Marked ready for review by @ibraheemdev on 2024-04-26 20:41</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-26 20:45</div>
            <div class="timeline-body"><p>Hmm it doesn't look like the benchmarks are running correctly under Codspeed, the performance report is showing the resolve/install benchmarks running in microseconds.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/adriencaccia">@adriencaccia</a> on 2024-04-26 21:03</div>
            <div class="timeline-body"><p>Hey @ibraheemdev, I am a co-founder at @CodSpeedHQ!</p>
<blockquote>
<p>Hmm it doesn't look like the benchmarks are running correctly under Codspeed, the performance report is showing the resolve/install benchmarks running in microseconds.</p>
</blockquote>
<p>Yes, running arbitrary executables in a benchmark with CodSpeed will not give out relevant results, as most of the compute is done in a new process that is not instrumented.
It would be best to directly call the underlying functions of the library, without relying on the built executable.</p>
<p>For example, calling https://github.com/astral-sh/uv/blob/2af80c28a8e6a2da755ab78f3ea7b028e8b1510c/crates/uv/src/commands/pip_compile.rs#L52 instead of
https://github.com/ibraheemdev/uv/blob/4ebdc40f60562c05559ac6331abe1a56275e2c8b/crates/bench/benches/uv.rs#L41-L42.</p>
<p>Hope that helps you a bit ğŸ˜ƒ</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-26 21:06</div>
            <div class="timeline-body"><p>@adriencaccia Thanks! I suspected we would have to do this eventually, but didn't realize CodSpeed didn't support processing external commands at all.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Converted to draft by @ibraheemdev on 2024-04-26 21:06</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">benchmarks</span> added by @ibraheemdev on 2024-04-29 18:24</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">internal</span> added by @ibraheemdev on 2024-04-29 18:25</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Marked ready for review by @ibraheemdev on 2024-04-29 20:32</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/charliermarsh">@charliermarsh</a> approved on 2024-04-30 04:20</div>
            <div class="timeline-body"><p>Nice, thank you! Open to giving this a shot. Do we have any sense for what the variance/noise will look like?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/adriencaccia">@adriencaccia</a> on 2024-04-30 14:44</div>
            <div class="timeline-body"><blockquote>
<p>Nice, thank you! Open to giving this a shot. Do we have any sense for what the variance/noise will look like?</p>
</blockquote>
<p>I tested it out on my fork at https://github.com/adriencaccia/uv/pull/1, and I have the following variance results for 101 runs on the same commit:</p>
<pre><code class="language-text">Found 101 runs for adriencaccia/uv (fca26cde1b54f7467267ca4dff7a9b9cb6f10d29)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              (index)                                                                               â”‚  average  â”‚ standardDeviation â”‚ varianceCoefficient â”‚   range   â”‚ rangeCoefficient â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-short-incompatible] â”‚ '1.1 Âµs'  â”‚     '27.3 ns'     â”‚       '2.5%'        â”‚ '55.6 ns' â”‚      '5.1%'      â”‚
â”‚  crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-short-compatible]  â”‚ '2.5 Âµs'  â”‚     '27.3 ns'     â”‚       '1.1%'        â”‚ '55.6 ns' â”‚      '2.2%'      â”‚
â”‚  crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-long-compatible]   â”‚ '2.6 Âµs'  â”‚     '27.3 ns'     â”‚       '1.0%'        â”‚ '55.6 ns' â”‚      '2.1%'      â”‚
â”‚ crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-long-incompatible]  â”‚ '1.8 Âµs'  â”‚     '13.6 ns'     â”‚       '0.7%'        â”‚ '27.8 ns' â”‚      '1.5%'      â”‚
â”‚    crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing_failure::wheelname_parsing_failure[flyte-short-extension]     â”‚ '2.6 Âµs'  â”‚     '13.6 ns'     â”‚       '0.5%'        â”‚ '27.8 ns' â”‚      '1.1%'      â”‚
â”‚     crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing_failure::wheelname_parsing_failure[flyte-long-extension]     â”‚ '2.6 Âµs'  â”‚     '13.6 ns'     â”‚       '0.5%'        â”‚ '27.8 ns' â”‚      '1.1%'      â”‚
â”‚            crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-short-compatible]            â”‚  '12 Âµs'  â”‚     '13.6 ns'     â”‚       '0.1%'        â”‚ '27.8 ns' â”‚      '0.2%'      â”‚
â”‚           crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-short-incompatible]           â”‚ '12.2 Âµs' â”‚     '13.6 ns'     â”‚       '0.1%'        â”‚ '27.8 ns' â”‚      '0.2%'      â”‚
â”‚           crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_build_platform_tags::build_platform_tags[burntsushi-archlinux]           â”‚ '6.3 ms'  â”‚     '13.6 ns'     â”‚       '0.0%'        â”‚ '27.8 ns' â”‚      '0.0%'      â”‚
â”‚           crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-long-incompatible]            â”‚ '26.3 Âµs' â”‚      '0 ns'       â”‚       '0.0%'        â”‚   '0 s'   â”‚      '0.0%'      â”‚
â”‚            crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-long-compatible]             â”‚  '21 Âµs'  â”‚      '0 ns'       â”‚       '0.0%'        â”‚   '0 s'   â”‚      '0.0%'      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>It is fairly stable, so you should be able to set a low regression threshold to around 5% ğŸ™‚</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-04-30 14:51</div>
            <div class="timeline-body"><p>Awesome, thanks so much Adrien!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2024-04-30 15:06</div>
            <div class="timeline-body"><p>Hm I don't see the resolver benchmarks there â€” I'd expect the distribution filename benches to be very stable but the resolver ones are probably less so.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2024-04-30 15:10</div>
            <div class="timeline-body"><p>Looks like there's something wrong and the resolver benches are missing on the latest commit.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-30 15:37</div>
            <div class="timeline-body"><p>I forgot to use the <code>codspeed-criterion-compat</code> shim in the <code>uv</code> benchmarks, but it looks like the crate doesn't support async runs.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/adriencaccia">@adriencaccia</a> on 2024-04-30 16:14</div>
            <div class="timeline-body"><p>@ibraheemdev let me know when you want me to run variance checks again on the new benchmarks</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-30 16:16</div>
            <div class="timeline-body"><p>@adriencaccia can you run them now? I'm also curious why benchmarks seem to be running ~15x slower on CodSpeed than locally, is it using an aggregate time instead of per-run?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/adriencaccia">@adriencaccia</a> on 2024-04-30 16:29</div>
            <div class="timeline-body"><blockquote>
<p>@adriencaccia can you run them now?</p>
</blockquote>
<p>Alright, I started them. Will post the results once they are done ğŸ˜‰</p>
<blockquote>
<p>I'm also curious why benchmarks seem to be running ~15x slower on CodSpeed than locally, is it using an aggregate time instead of per-run?</p>
</blockquote>
<p>This is because we run the code with <code>valgrind</code>, it adds a 4x to 10x overhead, sometimes more. But that is how we get those consistent measures and flamegraphs ğŸ˜‰</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/adriencaccia">@adriencaccia</a> on 2024-04-30 16:36</div>
            <div class="timeline-body"><p>Results with the new benchmarks:</p>
<pre><code class="language-text">Found 101 runs for adriencaccia/uv (7bbc18a361ba078e21186db90b98d6b88b3a8a7c)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              (index)                                                                               â”‚  average   â”‚ standardDeviation â”‚ varianceCoefficient â”‚   range   â”‚ rangeCoefficient â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                               crates/bench/benches/uv.rs::uv::resolve_warm_black::resolve_warm_black                                               â”‚ '15.3 ms'  â”‚    '527.5 Âµs'     â”‚       '3.4%'        â”‚ '2.3 ms'  â”‚     '15.0%'      â”‚
â”‚ crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-short-incompatible] â”‚  '1.1 Âµs'  â”‚     '27.5 ns'     â”‚       '2.5%'        â”‚ '55.6 ns' â”‚      '5.1%'      â”‚
â”‚                                             crates/bench/benches/uv.rs::uv::resolve_warm_jupyter::resolve_warm_jupyter                                             â”‚ '366.5 ms' â”‚     '4.2 ms'      â”‚       '1.1%'        â”‚ '22.8 ms' â”‚      '6.2%'      â”‚
â”‚  crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-short-compatible]  â”‚  '2.5 Âµs'  â”‚     '27.5 ns'     â”‚       '1.1%'        â”‚ '55.6 ns' â”‚      '2.2%'      â”‚
â”‚  crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-long-compatible]   â”‚  '2.6 Âµs'  â”‚     '27.5 ns'     â”‚       '1.0%'        â”‚ '55.6 ns' â”‚      '2.1%'      â”‚
â”‚ crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_tag_compatibility::wheelname_tag_compatibility[flyte-long-incompatible]  â”‚  '1.9 Âµs'  â”‚     '13.7 ns'     â”‚       '0.7%'        â”‚ '27.8 ns' â”‚      '1.5%'      â”‚
â”‚    crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing_failure::wheelname_parsing_failure[flyte-short-extension]     â”‚  '2.6 Âµs'  â”‚     '13.7 ns'     â”‚       '0.5%'        â”‚ '27.8 ns' â”‚      '1.1%'      â”‚
â”‚     crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing_failure::wheelname_parsing_failure[flyte-long-extension]     â”‚  '2.6 Âµs'  â”‚     '13.7 ns'     â”‚       '0.5%'        â”‚ '27.8 ns' â”‚      '1.1%'      â”‚
â”‚            crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-short-compatible]            â”‚  '12 Âµs'   â”‚     '13.7 ns'     â”‚       '0.1%'        â”‚ '27.8 ns' â”‚      '0.2%'      â”‚
â”‚           crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-short-incompatible]           â”‚ '12.2 Âµs'  â”‚     '13.7 ns'     â”‚       '0.1%'        â”‚ '27.8 ns' â”‚      '0.2%'      â”‚
â”‚           crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_build_platform_tags::build_platform_tags[burntsushi-archlinux]           â”‚  '6.3 ms'  â”‚     '13.7 ns'     â”‚       '0.0%'        â”‚ '27.8 ns' â”‚      '0.0%'      â”‚
â”‚           crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-long-incompatible]            â”‚ '26.3 Âµs'  â”‚      '0 ns'       â”‚       '0.0%'        â”‚   '0 s'   â”‚      '0.0%'      â”‚
â”‚            crates/bench/benches/distribution_filename.rs::distribution_filename::benchmark_wheelname_parsing::wheelname_parsing[flyte-long-compatible]             â”‚  '21 Âµs'   â”‚      '0 ns'       â”‚       '0.0%'        â”‚   '0 s'   â”‚      '0.0%'      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Indeed, it seems that <code>crates/bench/benches/uv.rs::uv::resolve_warm_black::resolve_warm_black</code> is a bit more inconsistent</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2024-04-30 16:38</div>
            <div class="timeline-body"><p>Maybe we remove the Black test? It seems like the variance is way higher than the Jupyter test.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/zanieb">@zanieb</a> on 2024-04-30 17:21</div>
            <div class="timeline-body"><p>I wonder why that is. It shouldn't be that different? (as far as variance)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-30 17:24</div>
            <div class="timeline-body"><p>@zanieb It's probably that the actual resolve step is faster, so the benchmark is more influenced by other factors (file I/O, etc.)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/ibraheemdev">@ibraheemdev</a> on 2024-04-30 17:39</div>
            <div class="timeline-body"><p>I'm going to go ahead and merge this with just the jupyter benchmark. We'll see how consistent/useful the reports are.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Merged by @ibraheemdev on 2024-04-30 17:39</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by @ibraheemdev on 2024-04-30 17:39</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-10 14:38:12 UTC
    </footer>
</body>
</html>
