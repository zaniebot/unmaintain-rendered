<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimize for size in release builds - astral-sh/uv #5909</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Optimize for size in release builds</h1>

    <div class="meta">
        <span class="state-icon state-closed"></span>
        <a href="https://github.com/astral-sh/uv/pull/5909">#5909</a>
        opened by <a href="https://github.com/davfsa">@davfsa</a>
        on 2024-08-08 14:10
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/davfsa">@davfsa</a></div>
            <div class="timeline-body">Summary
<p>This is a bit of a followup to #5904, which I did without properly testing this idea, as I expected it to provide way worst results than it seems to have done.</p>
<p>Apart from LTO, I also wanted to test setting <code>opt-level</code> to optimize for size (<code>&quot;s&quot;</code>). It wasn&#x27;t the first test I did because I expected LTO to be more of an overall gain, but optimizing for size, not so much. It has still yielded good results in the limited speed testing I have done (which I was afraid it would not do), and wanted to share these here.</p>
<p>The main idea behind these PRs is to slowdown the need for PyPI size increases <a href="https://github.com/pypi/support/issues/4260">pypi/support#4260</a> and overall just being more efficient where possible :)</p>
<p>Marking it as a draft for now to enable discussion (as it seems like this is a hot topic from what I have seen in the ruff repo and #5904).</p>
Test Plan


Expand

<p>Git commit for each of the executables:</p>
<ul>
<li><code>uv-main</code>: https://github.com/astral-sh/uv/commit/acbd367eadc6de2b5accbab1c288076a21190967</li>
<li><code>uv-lto</code>: https://github.com/astral-sh/uv/commit/cac3c4dfa55df7dbb1a5755a4c8756d6e80d7580</li>
<li><code>uv-size</code>: https://github.com/astral-sh/uv/commit/50efcde8cac5302a040939b3a2f2e69305d23ddc</li>
<li><code>uv-size-no-lto</code>: https://github.com/astral-sh/uv/commit/cde0aa1a5034a8e0beb0e9b621208672cd7424d2 with https://github.com/astral-sh/uv/commit/cac3c4dfa55df7dbb1a5755a4c8756d6e80d7580 reverted</li>
</ul>
<p>System info:</p>
<pre><code>CPU: AMD Ryzen 7 3700X (16) @ 3.600GHz
Memory: 32GB @ 3200 MT/s
Uname: Linux galaxy 6.6.44-1-MANJARO #1 SMP PREEMPT_DYNAMIC Sat Aug  3 10:09:33 UTC 2024 x86_64 GNU/Linux
</code></pre>
<hr>
Binary Size
<p>Command run: <code>cargo build --release</code> and then getting the binaries from <code>targets/release/uv</code></p>
<ul>
<li>uv-lto: 25M</li>
<li>uv-main: 30M</li>
<li>uv-size-no-lto: 22M</li>
<li>uv-size: 17M</li>
</ul>
Conclusion
<p>Drastic improvement in size by enabling both LTO and optimizing for size!</p>
Wheel Size
<p>Command run: <code>uvx maturin build --release</code> and then getting the wheels from <code>targets/wheels/uv-0.2.34-py3-none-linux_x86_64.whl</code></p>
<ul>
<li>uv-lto: 11M</li>
<li>uv-main: 12M</li>
<li>uv-size-no-lto: 8.7M</li>
<li>uv-size: 7.4M</li>
</ul>
Conclusion
<p>Drastic improvement in size by enabling both LTO and optimizing for wheel size too!</p>
<hr>
Executable Speed
<p>uv-lto:</p>
<pre><code>$ ~/coding/uv/uv-lto run resolver --uv-pip --benchmark resolve-warm --benchmark resolve-cold ../requirements/trio.in
warning: `uv run` is experimental and may change without warning
Benchmark 1: uv pip (resolve-warm)
  Time (mean ± σ):      26.7 ms ±   1.1 ms    [User: 8.5 ms, System: 32.4 ms]
  Range (min … max):    24.6 ms …  31.1 ms    97 runs
 
Benchmark 1: uv pip (resolve-cold)
  Time (mean ± σ):     405.1 ms ±  40.3 ms    [User: 128.7 ms, System: 72.0 ms]
  Range (min … max):   334.3 ms … 473.2 ms    10 runs
</code></pre>
<p>uv-main:</p>
<pre><code>$ ~/coding/uv/uv-main run resolver --uv-pip --benchmark resolve-warm --benchmark resolve-cold ../requirements/trio.in
warning: `uv run` is experimental and may change without warning
Benchmark 1: uv pip (resolve-warm)
  Time (mean ± σ):      26.6 ms ±   1.1 ms    [User: 8.5 ms, System: 32.5 ms]
  Range (min … max):    23.6 ms …  30.4 ms    98 runs
 
Benchmark 1: uv pip (resolve-cold)
  Time (mean ± σ):     366.9 ms ±  36.0 ms    [User: 115.9 ms, System: 77.1 ms]
  Range (min … max):   325.4 ms … 435.9 ms    10 runs
</code></pre>
<p>uv-size-no-lto:</p>
<pre><code>$ ~/coding/uv/uv-size-no-lto run resolver --uv-pip --benchmark resolve-warm --benchmark resolve-cold ../requirements/trio.in
warning: `uv run` is experimental and may change without warning
Benchmark 1: uv pip (resolve-warm)
  Time (mean ± σ):      27.0 ms ±   1.1 ms    [User: 9.0 ms, System: 33.0 ms]
  Range (min … max):    23.3 ms …  29.5 ms    91 runs
 
Benchmark 1: uv pip (resolve-cold)
  Time (mean ± σ):     373.8 ms ±  37.7 ms    [User: 103.2 ms, System: 77.5 ms]
  Range (min … max):   328.8 ms … 424.3 ms    10 runs
</code></pre>
<p>uv-size:</p>
<pre><code>$ ~/coding/uv/uv-size run resolver --uv-pip --benchmark resolve-warm --benchmark resolve-cold ../requirements/trio.in
warning: `uv run` is experimental and may change without warning
Benchmark 1: uv pip (resolve-warm)
  Time (mean ± σ):      26.5 ms ±   0.9 ms    [User: 9.4 ms, System: 31.7 ms]
  Range (min … max):    24.5 ms …  28.8 ms    104 runs
 
Benchmark 1: uv pip (resolve-cold)
  Time (mean ± σ):     377.8 ms ±  24.5 ms    [User: 113.7 ms, System: 74.5 ms]
  Range (min … max):   346.7 ms … 406.1 ms    10 runs
</code></pre>
Result
<p>I am not entirely sure why <code>uv-lto</code> is slighly slower than <code>uv-main</code> even tho benchmarks say otherwise (re-ran the benchmark multiple times), but will leave it to codespeed to determine that by properly running the benchmarks. What I was aiming to prove with these benchmarks is that optimizing for speed doesn&#x27;t actually slow down uv that much, mostly in what I would call an &quot;acceptable&quot; manner, considering how fast uv is already.</p>
<hr>
Build times
<p>Massive thanks to @T-256 for bringing up <a href="https://github.com/astral-sh/ruff/issues/9224">astral-sh/ruff#9224</a>. After reading through it and its sub-links, this <a href="https://github.com/astral-sh/ruff/issues/9224#issuecomment-1866415345">comment by zanieb</a> really made me realize that maybe ensuring build times are not too drastic is something worth ensuring, as to not make it harder for developers getting into the needy giddy of optimizing (and as I have also found out, lol)</p>
<p>Numbers are taken directly from the &quot;finished&quot; message using <code>cargo build --release</code>.</p>
<p><strong>They are not real benchmarks, they are single runs, and must be taken with a grain of salt, but give good indications of what is going on</strong></p>
Cold run (after <code>cargo clean</code>)
<ul>
<li>uv-lto: 3m 41s</li>
<li>uv-main: 1m 32s</li>
<li>uv-size-no-lto: 1m 03s</li>
<li>uv-size: 2m 14s</li>
</ul>
<p>Conclusions: Slight improvement in build times compared to LTO builds, but still half a minute slower than what it was before enabling LTO</p>
Warm run
<p><em>Didn&#x27;t really have any good ideas on what a warm run would look like, so I havent run these. If anybody knows a good way to do this, please do let me know and I will run them</em></p>


</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Converted to draft by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 14:10</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/bluss">@bluss</a> on 2024-08-08 14:11</div>
            <div class="timeline-body"><p>Is lto = &quot;thin&quot; an option by the way, where does it land w.r.t time and size?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 14:15</div>
            <div class="timeline-body"><blockquote>
<p>Is lto = &quot;thin&quot; an option by the way, where does it land w.r.t time and size?</p>
</blockquote>
<p>Didn&#x27;t test it, only now realized that <code>profile.dist</code> (for <code>cargo dist</code> builds) seems to run with it. Will post the results when I can!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/codspeed-hq[bot]">@codspeed-hq[bot]</a> on 2024-08-08 14:20</div>
            <div class="timeline-body"><a href="https://codspeed.io/astral-sh/uv/branches/davfsa:task/optimize-for-size">CodSpeed Performance Report</a>
Merging #5909 will <strong>improve performances by 15.12%</strong>
<p>Comparing <code>davfsa:task/optimize-for-size</code> (54d259b) with <code>main</code> (2822dde)</p>
Summary
<p><code>⚡ 2</code> improvements
<code>✅ 12</code> untouched benchmarks</p>
Benchmarks breakdown
<p>|     | Benchmark | <code>main</code> | <code>davfsa:task/optimize-for-size</code> | Change |
| --- | --------- | ----------------------- | ------------------- | ------ |
| ⚡ | <code>wheelname_tag_compatibility[flyte-long-compatible]</code> | 2 µs | 1.8 µs | +11.47% |
| ⚡ | <code>wheelname_tag_compatibility[flyte-short-compatible]</code> | 2 µs | 1.7 µs | +15.12% |</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 14:25</div>
            <div class="timeline-body"><p>@bluss Didn&#x27;t fully test the speed of using <code>lto = &quot;thin&quot;</code>, but just after a normal build and seeing the size of the executable size, I dont think it would be much better performance wise nor even worth testing:</p>
<p>Binary size: 31MB
Wheel size (py3-none-linux_x86_64):  13MB</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-08 14:33</div>
            <div class="timeline-body"><p>I would be somewhat skeptical of using <code>z</code> because of its possible impacts on runtime perf. IIRC, it disables auto-vectorization.</p>
<p>IMO, if we&#x27;re looking to decrease binary size, we should be chasing other avenues first. Like changes to the code itself that decrease bloat. We have barely done any of that, and I expect there are probably a lot of low hanging fruits.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 14:37</div>
            <div class="timeline-body"><blockquote>
<p>I would be somewhat skeptical of using z because of its possible impacts on runtime perf. IIRC, it disables auto-vectorization.</p>
</blockquote>
<p>Quick look at https://doc.rust-lang.org/cargo/reference/profiles.html#opt-level does mention that it will also disable loop vectorization. I will try <code>&quot;s&quot;</code> instead and see the size/performance hits (my mind instantly went to &quot;z&quot;, because it is what I have used in other projects)</p>
<blockquote>
<p>IMO, if we&#x27;re looking to decrease binary size, we should be chasing other avenues first. Like changes to the code itself that decrease bloat. We have barely done any of that, and I expect there are probably a lot of low hanging fruits.</p>
</blockquote>
<p>I am not too familiar with UVs code, but if there is anywhere you think I should be looking in particular, let me know and will explore in that direction!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-08 14:39</div>
            <div class="timeline-body"><blockquote>
<p>I am not too familiar with UVs code, but if there is anywhere you think I should be looking in particular, let me know and will explore in that direction!</p>
</blockquote>
<p>I would look for uses of generics and either remove them, limit the scope of their monomorphization or switch to <code>dyn</code> if possible. And I would start near the root of the crate. The highest value functions to attack are the biggest ones.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-08 14:40</div>
            <div class="timeline-body"><p>The other dimension to look at are dependencies. We are not especially conservative with bringing in new dependencies. I wouldn&#x27;t be surprised if there were some we could pluck out, either with a little extra code on our part or just different feature configurations.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-08 14:41</div>
            <div class="timeline-body"><p><code>cargo bloat</code> can probably help identify the biggest functions. And it should also point out when there are multiple copies of the same function.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 14:44</div>
            <div class="timeline-body"><blockquote>
<p>I will try &quot;s&quot; instead and see the size/performance hits</p>
</blockquote>
<p>It seems to be mostly on par to using <code>z</code> (+1MB binary size only, which I think its acceptable). Will update this PR and the description.</p>
<hr>
<p>Thanks @BurntSushi for all the helpful information, will look into it!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 15:02</div>
            <div class="timeline-body"><p>Ok, really confused right now, but benchmarks now report a performance increase? Huh?</p>
<p>Thats unexpected :thinking:</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 17:27</div>
            <div class="timeline-body"><p>Did some reading on the flags, and it seems like optimizing for speed (levels 2 and 3) only really do more aggressive inlining and vectorization, as well as loop unrolling. Otherwise, optimizing for space has the same other optimizations as enabling optimizations (except for the ones outlined before).</p>
<p>So I guess its a good thing to enable by default and it makes sense that the benchmarks do not report any slowdowns (the speedups are interesting tho).</p>
<p>Think this is fine to set a ready for merge!</p>
<p>reference: https://docs.rust-embedded.org/book/unsorted/speed-vs-size.html#optimize-for-speed</p>
<hr>
<p>On another note, the point raised by BurntSushi regarding build times i found to be quite important, so might have a look tomorrow and open another pr/issue if i find anything interesting to share :)</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Marked ready for review by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 17:27</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-08 17:31</div>
            <div class="timeline-body"><p>Our CI benchmarks don&#x27;t have the best coverage at the moment. We&#x27;ll want to run some of the hyperfine benchmarks locally to test the effects of this. My prior here is that we should have our <code>opt-level = 3</code>. We <em>want</em> aggressive inlining and vectorization.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 17:41</div>
            <div class="timeline-body"><blockquote>
<p>Our CI benchmarks don&#x27;t have the best coverage at the moment. We&#x27;ll want to run some of the hyperfine benchmarks locally to test the effects of this.</p>
</blockquote>
<p>Would be happy to do so. The benchmarks I attached to the description of the issue seem to indicate no drastic slowdowns, but if you indicate which benchmarks I should perform, I&#x27;ll perform them and post my findings here.</p>
<blockquote>
<p>My prior here is that we should have our opt-level = 3. We want aggressive inlining and vectorization.</p>
</blockquote>
<p>Vectorization will be just like <code>opt-level = 3</code>, it was <code>opt-level = z</code> that was removing it (which i assume caused the slowdown the bench marks first reported). I could play around with <code>inline-threshold</code> and see how close I can get it to the <code>opt-level = 2</code> and <code>opt-level = 3</code> values of 225 and 275 respectively.</p>
<p>Will report back!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/davfsa">@davfsa</a> on 2024-08-08 18:27</div>
            <div class="timeline-body"><p>Would like to add this information to the discussion: it seems that in rustc 1.18.0+, using <code>opt-level = s</code> is a combination of LLVM flags, setting speed optimization to 2 (ending in the same optimizations as <code>opt-level = 2</code>) and size optimization to 1 (2 being aggressive).</p>
<p>From what I can gather, optimizing for space with &quot;s&quot; is outputting an executable that is almost 2x smaller than the previous ones, while still staying mostly performant as previously.</p>
<p>I would be interested in running proper benchmarks to actually see what the performance cost would be going from O3 + LTO to O2 + size + LTO (and playing around with flags to see what gives the best results)</p>
<p>reference: https://github.com/rust-lang/rust/blob/d3a393932eeafa4638ae22f5ecbc38bf38760d0e/compiler/rustc_codegen_ssa/src/base.rs#L1016-L1018</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/samypr100">@samypr100</a> on 2024-08-08 23:56</div>
            <div class="timeline-body"><p>https://github.com/johnthagen/min-sized-rust is also a often a recommended reference, but I agree with @BurntSushi that there might be other areas to look at first</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2025-04-28 00:46</div>
            <div class="timeline-body"><p>I&#x27;m going to close this for now since we&#x27;re not actively exploring it.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/charliermarsh">@charliermarsh</a> on 2025-04-28 00:46</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 19:47:15 UTC
    </footer>
</body>
</html>
