<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>add built-in ability to limit search to first N bytes of file/stream (like with `head -c`) - BurntSushi/ripgrep #3035</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>add built-in ability to limit search to first N bytes of file/stream (like with <code>head -c</code>)</h1>

    <div class="meta">
        <span class="state-icon state-open"></span>
        <a href="https://github.com/BurntSushi/ripgrep/issues/3035">#3035</a>
        opened by <a href="https://github.com/moschroe">@moschroe</a>
        on 2025-04-18 14:37
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/moschroe">@moschroe</a></div>
            <div class="timeline-body"><h4>Describe your feature request</h4>
<p>I recently had the use case of searching an nginx cache (using slicing) containing many 100 GiB of data. Each file contains the response HTTP header for the slice. The slices can be over a MiB in size (could vary depending on nginx config), but the content is irrelevant, all I needed was within the first 1-2KiB of every file.</p>
<p>It was a pain to find certain cache slices because ripgrep has to stream the entire file (it contains a binary header, so binary mode must be used) in case there is no match, which holds for the vast majority of files.</p>
<p>I thought of having a built-in <code>head -c</code> that would prevent needless examination of file contents beyond a known header.</p>
<p>An anecdotal benchmark on my system shows a factor 2000 lower search time with a cold filesystem cache and factor 400 with a warm cache. This is a completely different dataset with fewer, larger files, though, the original system is unfortunately no longer accessible to me.</p>
<p>I implemented a draft for this feature here, would love a review and, hopefully, merge: https://github.com/moschroe/ripgrep/tree/feat_head-bytes (should I open a PR?)
It is most likely not as clean as it could be, so I'd be happy to improve it until acceptable.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">enhancement</span> added by @BurntSushi on 2025-04-18 14:45</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2025-04-18 14:46</div>
            <div class="timeline-body"><p>I think I'd be open to this. It would be pretty annoying to stitch this together using <code>head</code> outside of ripgrep. I suppose you could use <code>--pre</code> for this though. Have you considered that?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/moschroe">@moschroe</a> on 2025-04-18 17:56</div>
            <div class="timeline-body"><p>To be honest, I scoured the man page multiple times but, for some reason, must have overlooked or disregarded <code>--pre</code>. ðŸ¤¦</p>
<p>While there is certainly some overhead to spawning ~1 million processes (1TB/1MB=1e6 files), it would most likely always beat having to read every file entirely by a large margin.</p>
<p>My main reason to use <code>rg</code> here was that I knew it could not only filter but also traverse the filesystem efficiently. But with the pre process being spawned on already discovered files, it would likely be efficient enough.</p>
<p>I might be able to benchmark the difference, should I get access to such a system again.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/SaintNick2023">@SaintNick2023</a> on 2025-08-05 14:47</div>
            <div class="timeline-body"><p>I'm sure there will be plenty of use cases for limiting fetch/read and search only the first N bytes of the files, especially when combined with --max-count 1 it would give a <strong>huge</strong> performance boost for many large files where the searchstring is in a header block.</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-12 16:43:54 UTC
    </footer>
</body>
</html>
