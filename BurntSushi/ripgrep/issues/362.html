<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Compiled regex exceeds size limit of 10485760 bytes. - BurntSushi/ripgrep #362</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>Compiled regex exceeds size limit of 10485760 bytes.</h1>

    <div class="meta">
        <span class="state-icon state-closed"></span>
        <a href="https://github.com/BurntSushi/ripgrep/issues/362">#362</a>
        opened by <a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a>
        on 2017-02-13 19:43
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a></div>
            <div class="timeline-body"><p>Hi, I am trying to use a file with more then 8,000 entries (10-20 letter words, one per line. 132K) and get their corresponding lines in a big file (645,151lines, 76M). I use:
<code>rg -w -f query_file target_file</code></p>
<p>I get the error: <code>Compiled regex exceeds size limit of 10485760 bytes.</code>
How can I configure it to allow rg to run without the limit?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-13 19:47</div>
            <div class="timeline-body"><p>You can&#x27;t, as of now, without re-compiling and hard-coding a new limit.</p>
<p>I would be interested to hear how well 8,000 entries performs. As of now, it is fed into a single regex as a single alternation. If they are all plain text strings and not patterns, then it might be better to use Aho-Corasick instead (which ripgrep should do, it just doesn&#x27;t yet).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">enhancement</span> added by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-13 19:48</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-13 19:49</div>
            <div class="timeline-body"><p>If you were so inclined, the limit is here: https://github.com/BurntSushi/ripgrep/blob/master/grep/src/search.rs#L67</p>
<p>FYI, you can&#x27;t &quot;remove&quot; the limit (but you can set it arbitrarily high).</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a> on 2017-02-13 20:17</div>
            <div class="timeline-body"><p>Thanks, I have run it with a 640-line file (11K) without problems and very fast. The lines of the file are like these:</p>
<pre><code>AACY020304192.1.1216
AACY020311045.179.1696
AACY020524983.300.1803
AACY020558197.3281.4799
AACY023705044.289.1515
AACY023835985.1.1221
</code></pre>
<p>I am fairly new to coding, so excuse me but I need a &quot;for dummies&quot; howto set the limit very high. Basically, what should I do and where?
I have a server with 64 cores, 128 Mb RAM.
sorry</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-13 20:21</div>
            <div class="timeline-body"><p>The limit probably <em>should</em> be exposed as a flag so that it&#x27;s a knob you can turn easily. That feature is not currently available, so the only way for you to do it is change the source code of ripgrep and recompile it. Briefly:</p>
<pre><code>$ git clone git://github.com/BurntSushi/ripgrep
$ cd ripgrep
... try to compile it to make sure your env is setup right
$ cargo build --release
... change the limit in the source code
$ $EDITOR grep/src/search.rs
... compile again
$ cargo build --release
... the ripgrep binary is in target/release
$ ./target/release/rg blah blah blah
</code></pre>
<p>In order for the above to work, you will need to install Rust. See: https://rustup.rs/</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a> on 2017-02-16 19:58</div>
            <div class="timeline-body"><p>OK, solved, thanks.
I ran a file with 11,724 lines in under 1:20 h, not bad compared to several hours with grep.</p>
<p>I changed the &quot;size_limit&quot; from 10 to 1000:</p>
<pre><code> impl Default for Options {
     fn default() -&gt; Options {
         Options {
             case_insensitive: false,
             case_smart: false,
             line_terminator: b&#x27;\n&#x27;,
             size_limit: 1000 * (1 &lt;&lt; 20),
             dfa_size_limit: 10 * (1 &lt;&lt; 20),
         }
     }
 }
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a> on 2017-02-16 19:58</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a> on 2017-02-16 19:58</div>
            <div class="timeline-body"><p>Cheers</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-16 20:03</div>
            <div class="timeline-body"><p>Can you try increasing the dfa limit as well? Might speed things up too</p>
<p>On Feb 16, 2017 2:58 PM, &quot;Microbial Genomics Lab&quot; <a href="mailto:notifications@github.com">notifications@github.com</a>
wrote:</p>
<blockquote>
<p>Cheers</p>
<p>—
You are receiving this because you commented.
Reply to this email directly, view it on GitHub
<a href="https://github.com/BurntSushi/ripgrep/issues/362#issuecomment-280441247">BurntSushi/ripgrep#362</a>,
or mute the thread
<a href="https://github.com/notifications/unsubscribe-auth/AAb34qqW670PqgAxZQNhO7lrXV_VA0b6ks5rdKpggaJpZM4L_ose">https://github.com/notifications/unsubscribe-auth/AAb34qqW670PqgAxZQNhO7lrXV_VA0b6ks5rdKpggaJpZM4L_ose</a>
.</p>
</blockquote>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-17 12:14</div>
            <div class="timeline-body"><p>I&#x27;m going to re-open this because I think this limit should be configurable without re-compiling ripgrep.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Reopened by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-17 12:14</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/GenomicaMicrob">@GenomicaMicrob</a> on 2017-02-17 14:08</div>
            <div class="timeline-body"><p>Nice! Down to seconds now!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-02-17 14:30</div>
            <div class="timeline-body"><p>Wow. My guess is that you were previously exhausting the cache space of the DFA, so it probably did a lot of thrashing or dropped down to one of the (much) slower NFA engines.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Label <span class="label">help wanted</span> added by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-03-12 23:52</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Closed by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2017-04-12 22:14</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/victoriastuart">@victoriastuart</a> on 2018-01-06 20:22</div>
            <div class="timeline-body"><p>Just a comment (I have not tried resetting the limit, as detailed above): I ran into this exact issue today, comparing a ~15K list (individual words on separate lines) to another file (~272K; ditto).  Large, I know, but grep trounced that task, whereas ripgrep failed:</p>
<pre><code>time rg -Fxv -f my_stopwords.txt my_list | sort | uniq &gt; \
~/projects/nlp/tfidf/output/kw_not_sw

  Compiled regex exceeds size limit of 10485760 bytes.                            
  Command exited with non-zero status 1                                           
  0:01.58                                                                         
 
time grep -Fxv -f my_stopwords.txt my_list | sort | uniq &gt; \
~/projects/nlp/tfidf/output/kw_not_sw

  0:00.14
</code></pre>
<p>Arch Linux x84_64; 32MB RAM + swap + tmpfs; ripgrep v.0.7.1; grep (GNU grep) v.3.1</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2018-01-06 20:35</div>
            <div class="timeline-body"><p>@victoriastuart Increase the size limit using <code>--regex-size-limit</code>.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/victoriastuart">@victoriastuart</a> on 2018-01-07 19:08</div>
            <div class="timeline-body"><p>Hi Andrew; thank you for the project/code, comment -- appreciated.  Love ripgrep (v. fast, generally)!  :-D</p>
<p>Some observations (just a FYI; I&#x27;m happy with using grep, here):</p>
<pre><code>$ time rg --regex-size-limit 100M -Fxv -f  \
/mnt/Vancouver/Programming/data/nlp/stopwords/my_stopwords.txt  \
/mnt/Vancouver/untitled | sort | uniq &gt; ~/projects/nlp/tfidf/output/kw_not_sw

Compiled regex exceeds size limit of 104857600 bytes.
Command exited with non-zero status 1
0:01.55

$ time rg --regex-size-limit 200M -Fxv -f  \
/mnt/Vancouver/Programming/data/nlp/stopwords/my_stopwords.txt  \
/mnt/Vancouver/untitled | sort | uniq &gt; ~/projects/nlp/tfidf/output/kw_not_sw

^C          ## manually terminated
Command terminated by signal 2
21:07.17    ## 21 min

$ time grep -Fxv -f  \
/mnt/Vancouver/Programming/data/nlp/stopwords/my_stopwords.txt  \
/mnt/Vancouver/untitled | sort | uniq &gt; ~/projects/nlp/tfidf/output/kw_not_sw

0:00.13    ## ~0.1 sec

Regarding the ripgrep experiments:

* Intel Core i7-4790 CPU @ 3.60 GHz x 4 cores (hyper-threaded to 8 threads):
  * only 1 of 4 CPU/threads used @100% at any one time (rest ~@10-20%;
    includes other background processes, I presume).
* Memory (RAM; swap) usage unchanged throughout.
* Noted:
  * https://github.com/tiehuis/ripgrep/commit/593895566512f45b4dbdec78de2c46a7a91e8e18
  * The default limit is 10M. This should only be changed on very large regex
    inputs where the (slower) fallback regex engine may otherwise be used
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2018-01-07 19:15</div>
            <div class="timeline-body"><p>You need to increase --dfa-size-limit too.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/victoriastuart">@victoriastuart</a> on 2018-01-07 20:02</div>
            <div class="timeline-body"><p>Noting <a href="https://github.com/BurntSushi/ripgrep/issues/497">BurntSushi/ripgrep#497</a> ,</p>
<pre><code>time rg --regex-size-limit 200M --dfa-size-limit 10G -Fxv -f  \
/mnt/Vancouver/Programming/data/nlp/stopwords/my_stopwords.txt  \
/mnt/Vancouver/untitled &gt; ~/projects/nlp/tfidf/output/kw_not_sw

^C Command terminated by signal 2
33:58.19    ## manually-terminated at t ~34 min
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2018-01-07 20:09</div>
            <div class="timeline-body"><p>@victoriastuart thanks! Is possible can you share the data you are searching and your regex queries as well? Or tell me how to get it? It reproduce it publicly available data?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/victoriastuart">@victoriastuart</a> on 2018-01-07 20:28</div>
            <div class="timeline-body"><p>Hi ... it&#x27;s my own data (private), but simply lists of words; e.g.:</p>
<ul>
<li>my_stopwords.txt (currently 272K entries):</li>
</ul>
<pre><code>#wed
&#x27;d
&#x27;ll
&#x27;m
&#x27;re
&#x27;s
&#x27;t
&#x27;tis
&#x27;twas
&#x27;ve
**
+summary
--
-141
-2
-200c
-a
-casts
-determination
-immunocompatible
-induced
-researchers
-resistant
-sensitive
-β
...
.b
/diaphanous
/pax7
0-10
0-μm
0.02
0.2
0.5
000
000-fold
00000002-0030
00000004-0010
[ ... SNIP!! ... ]
zzzxpster
zörnig
zünd
zürich
~130
~130,000
²-actin
µm
ß
ángel
école
òscar
öaw
ûlo
α
α-helical
αβ
β
β-sandwich
β-sheets
β-subunit
β1
β2
β3
γ-carboxyl
μm
−141
</code></pre>
<ul>
<li>untitled (tmp file, generated from a custom tf-idf search script that I wrote; one of several methods I&#x27;m using -- along with RAKE; TextRank; others; ...):</li>
</ul>
<pre><code>`[&#x27;cell&#x27;, &#x27;gene&#x27;, &#x27;rna&#x27;, &#x27;cancer&#x27;, &#x27;protein&#x27;, &#x27;disease&#x27;, &#x27;dna&#x27;, &#x27;mouse&#x27;, &#x27;human&#x27;, &#x27;tumor&#x27;, &#x27;expression&#x27;, &#x27;genetic&#x27;, &#x27;function&#x27;, &#x27;mrna&#x27;, &#x27;tissue&#x27;, &#x27;brain&#x27;, &#x27;memory&#x27;, &#x27;genome&#x27;, &#x27;mirna&#x27;, &#x27;mechanism&#x27;, &#x27;molecular&#x27;, &#x27;stem&#x27;, &#x27;rnai&#x27;, &#x27;mutation&#x27;, &#x27;pathway&#x27;, &#x27;breast&#x27;, &#x27;blood&#x27;, &#x27;micrornas&#x27;, &#x27;cellular&#x27;, &#x27;lncrna&#x27;, ...]
</code></pre>
<p>formatted for processing (~15K lines, this particular output):</p>
<pre><code>cell
gene
rna
cancer
protein
disease
dna
mouse
human
tumor
expression
genetic
function
mrna
tissue
brain
memory
genome
mirna
mechanism
molecular
stem
rnai
mutation
pathway
breast
blood
micrornas
cellular
lncrna
[ ... SNIP!! ... ]
free-energy
bldg
edn
br
lookup
sciencemag
453-466
ac9erisnzlnjed
aczdv
csb28z6ji
g7bq
q8uv1gph4msxsoqw8ar
xad
zooew
tt
phylogenet
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/garry-ut99">@garry-ut99</a> on 2024-08-07 09:49</div>
            <div class="timeline-body"><p>When trying to do what described in:</p>
<ul>
<li>https://github.com/Genivia/ugrep/issues/153#issuecomment-2272449057</li>
</ul>
<p>It throws: <code>rg: compiled regex exceeds size limit of 104857600</code></p>
<p>When trying to incerase limits as per <a href="https://github.com/BurntSushi/ripgrep/issues/362">BurntSushi/ripgrep#362</a>#issuecomment-355848324, using the both options, where <code>--regex-size-limit</code> is 200M, then 300M and so on, it still throws the same:
<code>rg: compiled regex exceeds size limit of 209715200</code>
<code>rg: compiled regex exceeds size limit of 314572800</code>
<code>rg: compiled regex exceeds size limit of 524288000</code>
<code>rg: compiled regex exceeds size limit of 943718400</code></p>
<p>Then finally when I used: <code>--regex-size-limit 10G</code> it went out of RAM:
<code>memory allocation of 4294967296 bytes failed</code></p>
<p>I have 16GB RAM, it just crashed the same way like ug, eating almost all RAM.</p>
<p>Concluding: all greps: grep, rg, ug eat incredibly insane ammount of RAM to incerase speed.
But rg and ug are even more RAM hungry compared to old classic grep, that they get out of RAM quickly and fail to finish their job.
I do understand that rg and ug&#x27;s algorithms are faster than classic grep&#x27;s, but what is the point of faster algorithms if they just fail? In the end, ug and rg are useless compared to old classic grep on my PC, in terms of comparing big files for duplicates.</p>
<p>It would be good if the flawed rg and ug&#x27;s RAM hungry algorithms would be fixed, I don&#x27;t mean to sacrifice speed and to remove the current algorithm, the point is to simply have some alternative options to be able to finish the task without insane RAM usage, even if it will take some more time, some alternative option like &quot;slower but less ram hungry and being able to finish the task&quot; or maybe automatic splitting files into smaller chunks, whatever you invent to fix it.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-07 11:22</div>
            <div class="timeline-body"><p>@garry-ut99 Please open a new issue and provide an MRE. I can&#x27;t help you if you can&#x27;t provide a way for me to reproduce the behavior you&#x27;re seeing. You don&#x27;t even share the actual <code>rg</code> you&#x27;re using!</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/garry-ut99">@garry-ut99</a> on 2024-08-07 12:39</div>
            <div class="timeline-body"><blockquote>
<p>Please open a new issue</p>
</blockquote>
<p>Strange request, as you didn&#x27;t tell the same to the previous person who posted similiar issue in the current thread after one year: <a href="https://github.com/BurntSushi/ripgrep/issues/362">BurntSushi/ripgrep#362</a>#issuecomment-355773426, hence I assumed it&#x27;s ok for you to post similiar issues in the same thread, but it seems you strangely suddenly changed your mind,  I prefer to continue in the current thread until you explain/convince me: why do you want me to create a separate thread given a fact you didn&#x27;t want the previous person with a similair issue to create a separate thread.</p>
<blockquote>
<p>and provide an MRE. I can&#x27;t help you if you can&#x27;t provide a way for me to reproduce the behavior you&#x27;re seeing.</p>
</blockquote>
<p>Another strange statement, as I provided much useful informations, including description of the issue, ammount of my RAM, example content of my files, their sizes, and an exact command line used to compare the both files, I expected you to at least try to reproduce issue on your side, by using files with similair size and similiar content, using any binary, and then eventually to ask me for &quot;MRE&quot;, if you still can&#x27;t reproduce, but you strangely jumped directly into requiring me to provide MRE for you.</p>
<blockquote>
<p>You don&#x27;t even share the actual rg you&#x27;re using!</p>
</blockquote>
<p>Strange, as when no version is provided, the assumption is: the latest, which means <code>14.1.0</code> currently, but I agree that I forgot to specify the binary, as I have forgotten that there is so many different binaries, so the one I used is <code>-x86_64-pc-windows-gnu.zip</code></p>
<p>Many strange statements from your side.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2024-08-07 12:47</div>
            <div class="timeline-body"><p>I&#x27;ll repeat one last time: please open a new issue with a <a href="https://stackoverflow.com/help/minimal-reproducible-example">minimal reproducible example</a>. If you want my help, that&#x27;s what I require.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Locked by <a href="https://github.com/ghost">@ghost</a> on 2024-08-07 12:48</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 18:48:03 UTC
    </footer>
</body>
</html>
