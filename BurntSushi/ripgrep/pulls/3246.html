<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>perf(searcher/mmap): advise sequential access for file-backed mmaps on Unix - BurntSushi/ripgrep #3246</title>
    <link rel="stylesheet" href="../../../style.css">
</head>
<body>
    <div class="back-link">
        <a href="../../../index.html">Back to index</a>
    </div>

    <h1>perf(searcher/mmap): advise sequential access for file-backed mmaps on Unix</h1>

    <div class="meta">
        <span class="state-icon state-open"></span>
        <a href="https://github.com/BurntSushi/ripgrep/pull/3246">#3246</a>
        opened by <a href="https://github.com/howmanysmall">@howmanysmall</a>
        on 2025-12-15 05:54
    </div>

    <div class="timeline">
        <div class="timeline-entry">
            <div class="timeline-header"><a href="https://github.com/howmanysmall">@howmanysmall</a></div>
            <div class="timeline-body"><p>This applies <code>memmap2::Mmap::advise(Advice::Sequential)</code> after mapping a file on Unix. This is particularly important on macOS where mmap performance has historically been inconsistent (see #36). We also log <code>madvise</code> failures at debug level (including the path when available).</p>
Benchmark (macOS, 4GB file)
<p>Command (as-run):</p>
<pre><code>hyperfine --warmup 5 \
  &#x27;rg -a &quot;foo&quot; test_large_file || true&#x27; \
  &#x27;./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true&#x27; \
  &#x27;./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true&#x27;
</code></pre>
<p>Results:</p>
<ul>
<li>released <code>rg</code> (PATH), default behavior: 2.569 s ± 0.529 s</li>
<li>local <code>./target/release/rg --no-mmap</code>: 2.548 s ± 0.315 s</li>
<li>local <code>./target/release/rg --mmap</code>: 530.1 ms ± 362.8 ms</li>
</ul>
<p>(So local <code>--mmap</code> is ~4.8× faster than local <code>--no-mmap</code> on this workload.)</p>
Safety / escape hatch
<p>File-backed mmaps can SIGBUS if the underlying file is truncated while being read. Users can opt out with <code>--no-mmap</code> (already documented in the CAVEATS).</p>
Testing
<ul>
<li>cargo fmt --all --check</li>
<li>cargo test --workspace --features pcre2</li>
<li>ci/test-complete</li>
</ul>
</div>
        </div>
        <div class="timeline-entry">
            <div class="event">Marked ready for review by <a href="https://github.com/howmanysmall">@howmanysmall</a> on 2025-12-15 06:07</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/howmanysmall">@howmanysmall</a> on 2025-12-15 06:09</div>
            <div class="timeline-body"><p>Should add some benchmarks as well. These were ran on my M4 Pro (14 core).</p>
1 GB File
<pre><code>&gt;mkfile 1g test_large_file
&gt;hyperfine --warmup 5 &#x27;rg -a &quot;foo&quot; test_large_file || true&#x27; &#x27;./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true&#x27; &#x27;./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true&#x27; &#x27;grep -a &quot;foo&quot; test_large_file || true&#x27;
Benchmark 1: rg -a &quot;foo&quot; test_large_file || true
  Time (mean ± σ):     195.7 ms ±  11.2 ms    [User: 53.9 ms, System: 136.8 ms]
  Range (min … max):   186.6 ms … 221.5 ms    13 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the &#x27;--warmup&#x27; or &#x27;--prepare&#x27; options.

Benchmark 2: ./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true
  Time (mean ± σ):     195.6 ms ±  13.6 ms    [User: 55.0 ms, System: 136.6 ms]
  Range (min … max):   187.1 ms … 235.7 ms    15 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the &#x27;--warmup&#x27; or &#x27;--prepare&#x27; options.

Benchmark 3: ./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true
  Time (mean ± σ):      90.6 ms ±   2.8 ms    [User: 56.9 ms, System: 32.9 ms]
  Range (min … max):    85.9 ms …  97.1 ms    31 runs

Benchmark 4: grep -a &quot;foo&quot; test_large_file || true
  Time (mean ± σ):     216.4 ms ±  11.9 ms    [User: 70.6 ms, System: 138.2 ms]
  Range (min … max):   201.1 ms … 235.5 ms    14 runs

Summary
  ./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true ran
    2.16 ± 0.16 times faster than ./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true
    2.16 ± 0.14 times faster than rg -a &quot;foo&quot; test_large_file || true
    2.39 ± 0.15 times faster than grep -a &quot;foo&quot; test_large_file || true
</code></pre>
4 GB File
<pre><code>&gt;mkfile 4g test_large_file
&gt;hyperfine --warmup 5 &#x27;rg -a &quot;foo&quot; test_large_file || true&#x27; &#x27;./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true&#x27; &#x27;./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true&#x27; &#x27;grep -a &quot;foo&quot; test_large_file || true&#x27;
Benchmark 1: rg -a &quot;foo&quot; test_large_file || true
  Time (mean ± σ):      3.291 s ±  0.678 s    [User: 0.425 s, System: 1.728 s]
  Range (min … max):    2.559 s …  4.702 s    10 runs

Benchmark 2: ./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true
  Time (mean ± σ):      2.749 s ±  0.321 s    [User: 0.422 s, System: 1.476 s]
  Range (min … max):    2.280 s …  3.412 s    10 runs

Benchmark 3: ./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true
  Time (mean ± σ):     412.7 ms ±  67.4 ms    [User: 222.7 ms, System: 169.0 ms]
  Range (min … max):   381.7 ms … 602.9 ms    10 runs

  Warning: Statistical outliers were detected. Consider re-running this benchmark on a quiet system without any interferences from other programs. It might help to use the &#x27;--warmup&#x27; or &#x27;--prepare&#x27; options.

Benchmark 4: grep -a &quot;foo&quot; test_large_file || true
  Time (mean ± σ):      1.240 s ±  0.091 s    [User: 0.187 s, System: 0.812 s]
  Range (min … max):    1.105 s …  1.408 s    10 runs

Summary
  ./target/release/rg -a &quot;foo&quot; test_large_file --mmap || true ran
    3.00 ± 0.54 times faster than grep -a &quot;foo&quot; test_large_file || true
    6.66 ± 1.34 times faster than ./target/release/rg -a &quot;foo&quot; test_large_file --no-mmap || true
    7.97 ± 2.10 times faster than rg -a &quot;foo&quot; test_large_file || true
</code></pre>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2025-12-15 16:30</div>
            <div class="timeline-body"><p>Thanks! I&#x27;ll take a look at this soon. I&#x27;ll need to do my own benchmarks though. The benchmark you have here is quite pathological. It&#x27;s just 4GB of NUL bytes. Is this something that you search realistically?</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/howmanysmall">@howmanysmall</a> on 2025-12-15 17:09</div>
            <div class="timeline-body"><p>No, it was really just the easiest thing to benchmark. I should have probably done something more comprehensive but I couldn&#x27;t be bothered.</p>
</div>
        </div>
        <div class="timeline-entry">
            <div class="timeline-header">Comment by <a href="https://github.com/BurntSushi">@BurntSushi</a> on 2025-12-18 19:04</div>
            <div class="timeline-body"><p>OK, so I did some of my own benchmarking on a &quot;normal&quot; plain text file. And unfortunately, I don&#x27;t see that much has changed. There <em>is</em> a case where using memory maps on macOS (for this input) is slightly faster than not, but there is also a very significant regression once you start searching a larger file.</p>
<p>OK, first is acquiring the corpora. There are two files. The first is a smaller
sample of the second. The first is 278MB compressed. The second is 3.5GB compressed.</p>
<pre><code>curl -LO https://burntsushi.net/stuff/OpenSubtitles2018.raw.sample.en.gz
curl -LO https://burntsushi.net/stuff/OpenSubtitles2018.raw.en.gz
gzip -d OpenSubtitles2018.raw.sample.en.gz
gzip -d OpenSubtitles2018.raw.en.gz
</code></pre>
<p>This first benchmark is on Linux that uses a pattern that never matches. We compare three cases: no memory maps, with memory maps and advice and with memory maps and no advice:</p>
<pre><code>$ hyperfine --output pipe -i -w1 -m3 -M10 &#x27;rg-master --no-mmap ZQZQZQ OpenSubtitles2018.raw.sample.en&#x27; &#x27;rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.sample.en&#x27; &#x27;rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.sample.en&#x27;

Benchmark 1: rg-master --no-mmap ZQZQZQ OpenSubtitles2018.raw.sample.en
  Time (mean ± σ):      87.5 ms ±   1.4 ms    [User: 31.4 ms, System: 55.8 ms]
  Range (min … max):    85.1 ms …  89.2 ms    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 2: rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.sample.en
  Time (mean ± σ):      59.5 ms ±   2.7 ms    [User: 47.1 ms, System: 12.1 ms]
  Range (min … max):    55.5 ms …  65.5 ms    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.sample.en
  Time (mean ± σ):      59.2 ms ±   2.6 ms    [User: 45.0 ms, System: 13.9 ms]
  Range (min … max):    54.9 ms …  62.4 ms    10 runs

  Warning: Ignoring non-zero exit code.

Summary
  rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.sample.en ran
    1.01 ± 0.06 times faster than rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.sample.en
    1.48 ± 0.07 times faster than rg-master --no-mmap ZQZQZQ OpenSubtitles2018.raw.sample.en
</code></pre>
<p>That was on the smaller &quot;sample&quot; file. Now let&#x27;s do it again on the larger file:</p>
<pre><code>$ hyperfine --output pipe -i -w1 -m3 -M3 &#x27;rg-master --no-mmap ZQZQZQ full.txt&#x27; &#x27;rg-mmap-advice ZQZQZQ full.txt&#x27; &#x27;rg-mmap-noadvice ZQZQZQ full.txt&#x27;
Benchmark 1: rg-master --no-mmap ZQZQZQ full.txt
  Time (mean ± σ):      1.215 s ±  0.110 s    [User: 0.380 s, System: 0.833 s]
  Range (min … max):    1.142 s …  1.342 s    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 2: rg-mmap-advice ZQZQZQ full.txt
  Time (mean ± σ):     803.6 ms ±  12.0 ms    [User: 589.3 ms, System: 212.4 ms]
  Range (min … max):   792.9 ms … 816.6 ms    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: rg-mmap-noadvice ZQZQZQ full.txt
  Time (mean ± σ):     798.9 ms ±  40.5 ms    [User: 592.7 ms, System: 204.2 ms]
  Range (min … max):   772.1 ms … 845.5 ms    3 runs

  Warning: Ignoring non-zero exit code.

Summary
  rg-mmap-noadvice ZQZQZQ full.txt ran
    1.01 ± 0.05 times faster than rg-mmap-advice ZQZQZQ full.txt
    1.52 ± 0.16 times faster than rg-master --no-mmap ZQZQZQ full.txt

</code></pre>
<p>This is consistent with my historical observation of mmap performance on Linux:</p>
<ol>
<li>The sequential advice doesn&#x27;t matter.</li>
<li>Using memory maps gives a modest improvement over not using memory maps.</li>
</ol>
<p>Now let&#x27;s do exactly the same benchmark, but on macOS. First is the smaller file:</p>
<pre><code>$ hyperfine --output pipe -i -w1 -m3 -M10 &#x27;rg-master ZQZQZQ OpenSubtitles2018.raw.sample.en&#x27; &#x27;rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.sample.en&#x27; &#x27;rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.sample.en&#x27;
Benchmark 1: rg-master ZQZQZQ OpenSubtitles2018.raw.sample.en
  Time (mean ± σ):     107.0 ms ±   0.1 ms    [User: 42.0 ms, System: 64.6 ms]
  Range (min … max):   106.8 ms … 107.1 ms    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 2: rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.sample.en
  Time (mean ± σ):      86.4 ms ±   0.3 ms    [User: 54.0 ms, System: 32.0 ms]
  Range (min … max):    86.1 ms …  86.9 ms    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.sample.en
  Time (mean ± σ):      86.3 ms ±   0.1 ms    [User: 54.0 ms, System: 31.9 ms]
  Range (min … max):    86.0 ms …  86.5 ms    10 runs

  Warning: Ignoring non-zero exit code.

Summary
  rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.sample.en ran
    1.00 ± 0.00 times faster than rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.sample.en
    1.24 ± 0.00 times faster than rg-master ZQZQZQ OpenSubtitles2018.raw.sample.en
</code></pre>
<p>OK, this is promising! There&#x27;s no difference between memory maps with and without sequential advice, but there is a modest (even more modest) improvement over not using memory maps.</p>
<p>Now let&#x27;s try with the bigger file:</p>
<pre><code>$ hyperfine --output pipe -i -w1 -m3 -M3 &#x27;rg-master ZQZQZQ OpenSubtitles2018.raw.en&#x27; &#x27;rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.en&#x27; &#x27;rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.en&#x27;
Benchmark 1: rg-master ZQZQZQ OpenSubtitles2018.raw.en
  Time (mean ± σ):      7.497 s ±  0.006 s    [User: 0.649 s, System: 1.380 s]
  Range (min … max):    7.492 s …  7.503 s    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 2: rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.en
  Time (mean ± σ):     26.701 s ±  0.061 s    [User: 1.495 s, System: 2.147 s]
  Range (min … max):   26.639 s … 26.762 s    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.en
  Time (mean ± σ):     31.401 s ±  0.070 s    [User: 1.611 s, System: 4.829 s]
  Range (min … max):   31.345 s … 31.479 s    3 runs

  Warning: Ignoring non-zero exit code.

Summary
  rg-master ZQZQZQ OpenSubtitles2018.raw.en ran
    3.56 ± 0.01 times faster than rg-mmap-advice ZQZQZQ OpenSubtitles2018.raw.en
    4.19 ± 0.01 times faster than rg-mmap-noadvice ZQZQZQ OpenSubtitles2018.raw.en
</code></pre>
<p>Wat. This to me says that memory maps on macOS still suck. The sequential advice <em>does</em> seem to matter here, but regardless of setting the advice, using memory maps is still significantly slower than not using them.</p>
<p>Now, let&#x27;s go back to your benchmark. Let&#x27;s start by confirming that I can roughly reproduce your result:</p>
<pre><code>$ hyperfine -i --output pipe -w1 &#x27;rg-master -a &quot;foo&quot; test_large_file&#x27; &#x27;rg-mmap-advice -a &quot;foo&quot; test_large_file&#x27; &#x27;rg-mmap-noadvice -a &quot;foo&quot; test_large_file&#x27; &#x27;grep -a &quot;foo&quot; test_large_file&#x27;
Benchmark 1: rg-master -a &quot;foo&quot; test_large_file
  Time (mean ± σ):      2.461 s ±  0.098 s    [User: 0.449 s, System: 1.223 s]
  Range (min … max):    2.391 s …  2.644 s    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 2: rg-mmap-advice -a &quot;foo&quot; test_large_file
  Time (mean ± σ):     418.9 ms ±   1.8 ms    [User: 263.7 ms, System: 154.7 ms]
  Range (min … max):   416.5 ms … 423.1 ms    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: rg-mmap-noadvice -a &quot;foo&quot; test_large_file
  Time (mean ± σ):     799.6 ms ±   3.8 ms    [User: 239.8 ms, System: 559.4 ms]
  Range (min … max):   797.0 ms … 810.1 ms    10 runs

  Warning: Ignoring non-zero exit code.

Benchmark 4: grep -a &quot;foo&quot; test_large_file
  Time (mean ± σ):     685.1 ms ±   8.1 ms    [User: 217.0 ms, System: 465.8 ms]
  Range (min … max):   677.2 ms … 704.9 ms    10 runs

  Warning: Ignoring non-zero exit code.

Summary
  rg-mmap-advice -a &quot;foo&quot; test_large_file ran
    1.64 ± 0.02 times faster than grep -a &quot;foo&quot; test_large_file
    1.91 ± 0.01 times faster than rg-mmap-noadvice -a &quot;foo&quot; test_large_file
    5.87 ± 0.24 times faster than rg-master -a &quot;foo&quot; test_large_file
</code></pre>
<p>That looks roughly consistent with what you observe: mmap is significantly better than non-mmap, and sequential advice gives another boost.</p>
<p>So... does file size matter here? If I create a 12GB file of all NUL bytes, will the mmap approach be slower? I just did an ad hoc test here since I didn&#x27;t feel like waiting for <code>hyperfine</code> given the times:</p>
<pre><code>$ time rg-master -a foo test_large_file_x3

real    18.033
user    2.469
sys     7.605
maxmem  7920528 MB
faults  14
$ time rg-master -a foo test_large_file_x3

real    18.395
user    2.487
sys     7.859
maxmem  8068928 MB
faults  177

$ time rg-mmap-advice -a foo test_large_file_x3

real    25.124
user    1.581
sys     2.033
maxmem  11026528 MB
faults  786645
$ time rg-mmap-advice -a foo test_large_file_x3

real    25.250
user    1.595
sys     2.198
maxmem  11002368 MB
faults  770135
$ time rg-mmap-advice -a foo test_large_file_x3

real    24.603
user    1.580
sys     2.273
maxmem  10994512 MB
faults  729232
</code></pre>
<p>... so... yeah... file size matters?</p>
<p>What about testing the original 4GB file on Linux? (I&#x27;m not going to bother with the 12GB file because I have no suspicion that Linux will crap out with larger files like macOS does.)</p>
<pre><code>$ hyperfine --output pipe -i -w1 -m3 -M3 &#x27;rg-master --no-mmap -a foo /tmp/test_large_file&#x27; &#x27;rg-mmap-advice -a foo /tmp/test_large_file&#x27; &#x27;rg-mmap-noadvice -a foo /tmp/test_large_file&#x27;
Benchmark 1: rg-master --no-mmap -a foo /tmp/test_large_file
  Time (mean ± σ):      2.570 s ±  0.032 s    [User: 0.659 s, System: 1.906 s]
  Range (min … max):    2.550 s …  2.606 s    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 2: rg-mmap-advice -a foo /tmp/test_large_file
  Time (mean ± σ):     375.7 ms ±   5.1 ms    [User: 210.0 ms, System: 164.8 ms]
  Range (min … max):   371.4 ms … 381.4 ms    3 runs

  Warning: Ignoring non-zero exit code.

Benchmark 3: rg-mmap-noadvice -a foo /tmp/test_large_file
  Time (mean ± σ):     373.8 ms ±   2.6 ms    [User: 206.2 ms, System: 166.7 ms]
  Range (min … max):   370.8 ms … 375.8 ms    3 runs

  Warning: Ignoring non-zero exit code.

Summary
  rg-mmap-noadvice -a foo /tmp/test_large_file ran
    1.01 ± 0.02 times faster than rg-mmap-advice -a foo /tmp/test_large_file
    6.88 ± 0.10 times faster than rg-master --no-mmap -a foo /tmp/test_large_file
</code></pre>
<p>Yeah so both the mmap searches are faster, but now <em>substantially</em> faster than the approach without memory mapping. So I think there is more going on here than just memory mapping. In particular, if we get the peak memory usage of the no-mmap search:</p>
<pre><code>$ time rg-master --no-mmap -a foo /tmp/test_large_file

real    2.704
user    0.831
sys     1.867
maxmem  11077 MB
faults  0
</code></pre>
<p>That is quite a lot. It turns out that searching a file with all NUL bytes is pretty pathological. And when you use the <code>-a/--text</code> flag, you&#x27;re specifically telling ripgrep to treat binary data as if it were text. But if you omit the <code>-a/--text</code> flag:</p>
<pre><code>$ time rg-master --no-mmap foo /tmp/test_large_file

real    1.400
user    1.020
sys     0.376
maxmem  30 MB
faults  0
</code></pre>
<p>Which is still slower than the mmap searches, but faster than with <code>-a/--text</code> <em>and</em> memory usage is far more reasonable.</p>
<p>What&#x27;s going on here is that when you use <code>-a/--text</code> in this example, ripgrep searches by chunking up the input into lines. And the underlying regex engine(s) have a requirement that their haystack fit into contiguous memory. So this means every line has to be read onto the heap. But in this case, the file is just 4GB of NUL bytes. It&#x27;s only one line. So the entire file gets read onto the heap as a single line. That&#x27;s slow and causes higher memory usage.</p>
<p>But what about when <code>-a/--text</code> is <em>not</em> used? In that case, ripgrep uses a heuristic (adopted from GNU grep) that &quot;zaps&quot; all of the NUL bytes in the haystack into line terminators. This heuristic is meant to avoid the &quot;read GB of data onto the heap&quot; by introducing &quot;fake&quot; lines where there previously were none.</p>
<p>Both of these cases, in other words, are doing extra work due to the pathological nature of the input. And this is where the mmap option really helps. Here, it isn&#x27;t <em>just</em> that mmap is itself faster than file I/O (at least, it is on Linux for a single large file by a modest amount), but it&#x27;s also fundamentally changing the work that ripgrep has to do. When you memory map a file, the entire file is represented by a contiguous sequence of bytes (courtesy of the operating system). So all this &quot;zap NUL&quot; or &quot;read entire file as a single line onto the heap&quot; business completely goes away.</p>
<p>So this contributes to <em>this particular case</em> being faster with memory maps on macOS. But as the file size grows, the suckiness of macOS memory maps seems to win out. <strong>And also</strong>, as soon as you use more &quot;regular&quot; input that isn&#x27;t full of NUL bytes, then you&#x27;re just left with whether memory maps on macOS are better than normal file I/O <em>all else being equal</em>. And while it seems it may be the case for smaller files, it becomes definitively <em>not</em> the case for larger files.</p>
<p>TL;DR - File backed memory maps on macOS still suck and I am still unable to see a benchmark on Linux where the &quot;sequential&quot; advice matters.</p>
<p>So at least for now, I think I&#x27;m not seeing enough evidence here to merge this change. While it improves the pathological benchmark you&#x27;ve presented, it <em>significantly</em> regresses non-pathological benchmarks.</p>
</div>
        </div>
    </div>

    <footer>
        Synced at 2026-01-20 18:48:21 UTC
    </footer>
</body>
</html>
