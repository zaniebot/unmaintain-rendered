---
number: 4
title: Add tests
type: issue
state: closed
author: kbknapp
labels:
  - C-enhancement
assignees: []
created_at: 2015-03-03T19:01:58Z
updated_at: 2018-08-02T03:29:35Z
url: https://github.com/clap-rs/clap/issues/4
synced_at: 2026-01-07T12:31:16-06:00
---

# Add tests

---

_Issue opened by @kbknapp on 2015-03-03 19:01_

_No description provided._

---

_Label `enhancement` added by @kbknapp on 2015-03-03 19:02_

---

_Comment by @kbknapp on 2015-03-16 15:29_

Need to add tests for subcommands


---

_Comment by @gsquire on 2015-03-17 04:47_

I'd be willing to help start this. How would you want the tests to be written since it parses from the command line?


---

_Comment by @kbknapp on 2015-03-17 14:04_

I'd appreciate the help! There are two ways I can see going about it, one
would be to write more comprehensive simple tests (such as what's done in
src/lib.rs) just asserting things that should or shouldn't work.

A more comprehensive way, but also far more difficult, would be to write a
separate module or binary all together which uses the API to assert some of
the more internal workings (such as correct parsing of pre-determined
command line arguments).

I'm of the mind to say start small and grow, so if you'd like to put
together some more tests in src/lib.rs that'd be awesome! The way I have
things working right now is that if the developer (i.e. consumer of `clap`)
does something wrong it will `panic!` at runtime (things such as adding `.index()` and `.takes_value()` to the same `Arg`). This ensures it will be caught
before ever making it to the end user. But if the end user (i.e. user of
the consumer's product) does something wrong, it should not `panic!` but
fail gracefully with an error message and usage string). So what I'm more
concerned with testing is the developer side of things, that should (or
should not) `panic!`

On Tue, Mar 17, 2015 at 12:47 AM, Garrett Squire notifications@github.com
wrote:

> I'd be willing to help start this. How would you want the tests to be
> written since it parses from the command line?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82103845.


---

_Comment by @untitaker on 2015-03-17 15:32_

Since you can't assert that a panic is happening, I suppose there should be a separate API which doesn't use panics, which
- can then be wrapped with one that does panic
- can be used directly to assert correct detection of developer errors.

Related: Clap could generally provide utilities for the dev to test its own app's behavior. Then those could be used for testing Clap itself too.

On 17 March 2015 15:04:26 CET, "Kevin K." notifications@github.com wrote:

> I'd appreciate the help! There are two ways I can see going about it,
> one
> would be to write more comprehensive simple tests (such as what's done
> in
> src/lib.rs) just asserting things that should or shouldn't work.
> 
> A more comprehensive way, but also far more difficult, would be to
> write a
> separate module or binary all together which uses the API to assert
> some of
> the more internal workings (such as correct parsing of pre-determined
> command line arguments).
> 
> I'm of the mind to say start small and grow, so if you'd like to put
> together some more tests in src/lib.rs that'd be awesome! The way I
> have
> things working right now is that if the developer (i.e. consumer of
> `clap`)
> does something wrong it will `panic!` at runtime, so that it will be
> caught
> before ever making it to the end user. But if the end user (i.e. user
> of
> the consumer's product) does something wrong, it should not `panic!`
> but
> fail gracefully with an error message and usage string). So what I'm
> more
> concerned with testing is the developer side of things, that should (or
> should not) `panic!`
> 
> On Tue, Mar 17, 2015 at 12:47 AM, Garrett Squire
> notifications@github.com
> wrote:
> 
> > I'd be willing to help start this. How would you want the tests to be
> > written since it parses from the command line?
> > 
> > —
> > Reply to this email directly or view it on GitHub
> > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82103845.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82370305


---

_Comment by @kbknapp on 2015-03-17 15:46_

You can use the #[should_panic] directive if a given function should
produce a panic (which causes the test to pass on a panic). You just have
to be careful, because things can panic for a multitude of reasons, and
it's hard to determine why they panic'ed. I believe there is a directive to
such as #[should_panic("some string")] which checks the panic message for a
particular string, and only passes the test if the panic message contains
that string (but I can't remember off the top of my head the exact name).

On Tue, Mar 17, 2015 at 11:32 AM, Markus Unterwaditzer <
notifications@github.com> wrote:

> Since you can't assert that a panic is happening, I suppose there should
> be a separate API which doesn't use panics, which
> - can then be wrapped with one that does panic
> - can be used directly to assert correct detection of developer errors.
> 
> Related: Clap could generally provide utilities for the dev to test its
> own app's behavior. Then those could be used for testing Clap itself too.
> 
> On 17 March 2015 15:04:26 CET, "Kevin K." notifications@github.com
> wrote:
> 
> > I'd appreciate the help! There are two ways I can see going about it,
> > one
> > would be to write more comprehensive simple tests (such as what's done
> > in
> > src/lib.rs) just asserting things that should or shouldn't work.
> > 
> > A more comprehensive way, but also far more difficult, would be to
> > write a
> > separate module or binary all together which uses the API to assert
> > some of
> > the more internal workings (such as correct parsing of pre-determined
> > command line arguments).
> > 
> > I'm of the mind to say start small and grow, so if you'd like to put
> > together some more tests in src/lib.rs that'd be awesome! The way I
> > have
> > things working right now is that if the developer (i.e. consumer of
> > `clap`)
> > does something wrong it will `panic!` at runtime, so that it will be
> > caught
> > before ever making it to the end user. But if the end user (i.e. user
> > of
> > the consumer's product) does something wrong, it should not `panic!`
> > but
> > fail gracefully with an error message and usage string). So what I'm
> > more
> > concerned with testing is the developer side of things, that should (or
> > should not) `panic!`
> > 
> > On Tue, Mar 17, 2015 at 12:47 AM, Garrett Squire
> > notifications@github.com
> > wrote:
> > 
> > > I'd be willing to help start this. How would you want the tests to be
> > > written since it parses from the command line?
> > > 
> > > —
> > > Reply to this email directly or view it on GitHub
> > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82103845.
> > 
> > ---
> > 
> > Reply to this email directly or view it on GitHub:
> > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82370305
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82415819.


---

_Comment by @untitaker on 2015-03-17 15:51_

Interesting, didn't know that! Still believe that a results-based API would
provide some benefits (more precise assertions), tedious to implement though.

Is there something similar for asserting a particular stdout output?

On Tue, Mar 17, 2015 at 08:46:02AM -0700, Kevin K. wrote:

> You can use the #[should_panic] directive if a given function should
> produce a panic (which causes the test to pass on a panic). You just have
> to be careful, because things can panic for a multitude of reasons, and
> it's hard to determine why they panic'ed. I believe there is a directive to
> such as #[should_panic("some string")] which checks the panic message for a
> particular string, and only passes the test if the panic message contains
> that string (but I can't remember off the top of my head the exact name).
> 
> On Tue, Mar 17, 2015 at 11:32 AM, Markus Unterwaditzer <
> notifications@github.com> wrote:
> 
> > Since you can't assert that a panic is happening, I suppose there should
> > be a separate API which doesn't use panics, which
> > - can then be wrapped with one that does panic
> > - can be used directly to assert correct detection of developer errors.
> > 
> > Related: Clap could generally provide utilities for the dev to test its
> > own app's behavior. Then those could be used for testing Clap itself too.
> > 
> > On 17 March 2015 15:04:26 CET, "Kevin K." notifications@github.com
> > wrote:
> > 
> > > I'd appreciate the help! There are two ways I can see going about it,
> > > one
> > > would be to write more comprehensive simple tests (such as what's done
> > > in
> > > src/lib.rs) just asserting things that should or shouldn't work.
> > > 
> > > A more comprehensive way, but also far more difficult, would be to
> > > write a
> > > separate module or binary all together which uses the API to assert
> > > some of
> > > the more internal workings (such as correct parsing of pre-determined
> > > command line arguments).
> > > 
> > > I'm of the mind to say start small and grow, so if you'd like to put
> > > together some more tests in src/lib.rs that'd be awesome! The way I
> > > have
> > > things working right now is that if the developer (i.e. consumer of
> > > `clap`)
> > > does something wrong it will `panic!` at runtime, so that it will be
> > > caught
> > > before ever making it to the end user. But if the end user (i.e. user
> > > of
> > > the consumer's product) does something wrong, it should not `panic!`
> > > but
> > > fail gracefully with an error message and usage string). So what I'm
> > > more
> > > concerned with testing is the developer side of things, that should (or
> > > should not) `panic!`
> > > 
> > > On Tue, Mar 17, 2015 at 12:47 AM, Garrett Squire
> > > notifications@github.com
> > > wrote:
> > > 
> > > > I'd be willing to help start this. How would you want the tests to be
> > > > written since it parses from the command line?
> > > > 
> > > > —
> > > > Reply to this email directly or view it on GitHub
> > > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82103845.
> > > 
> > > ---
> > > 
> > > Reply to this email directly or view it on GitHub:
> > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82370305
> > 
> > —
> > Reply to this email directly or view it on GitHub
> > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82415819.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82424729


---

_Comment by @kbknapp on 2015-03-17 15:57_

I totally agree. And that's where I'd eventually like to get, it's just
harder to implement, like you said.

> Is there something similar for asserting a particular stdout output?

I'm not sure, I haven't seen anything specific like that, but it'd be nice.
I can think of hacky ways to do that, but all involve another binary or
module. I currently have a binary, named "fake" which I use to test various
things, but it's not at all automated, just something I use to double check
myself. You'd almost have to have fake's test (or whatever binary) call
itself, monitor the output, and assert based off the findings...I'll have
to think on that some more.

If anyone has a good way to go about this, I'm all ears!

On Tue, Mar 17, 2015 at 11:51 AM, Markus Unterwaditzer <
notifications@github.com> wrote:

> Interesting, didn't know that! Still believe that a results-based API would
> provide some benefits (more precise assertions), tedious to implement
> though.
> 
> Is there something similar for asserting a particular stdout output?
> 
> On Tue, Mar 17, 2015 at 08:46:02AM -0700, Kevin K. wrote:
> 
> > You can use the #[should_panic] directive if a given function should
> > produce a panic (which causes the test to pass on a panic). You just have
> > to be careful, because things can panic for a multitude of reasons, and
> > it's hard to determine why they panic'ed. I believe there is a directive
> > to
> > such as #[should_panic("some string")] which checks the panic message
> > for a
> > particular string, and only passes the test if the panic message contains
> > that string (but I can't remember off the top of my head the exact name).
> > 
> > On Tue, Mar 17, 2015 at 11:32 AM, Markus Unterwaditzer <
> > notifications@github.com> wrote:
> > 
> > > Since you can't assert that a panic is happening, I suppose there
> > > should
> > > be a separate API which doesn't use panics, which
> > > - can then be wrapped with one that does panic
> > > - can be used directly to assert correct detection of developer errors.
> > > 
> > > Related: Clap could generally provide utilities for the dev to test its
> > > own app's behavior. Then those could be used for testing Clap itself
> > > too.
> > > 
> > > On 17 March 2015 15:04:26 CET, "Kevin K." notifications@github.com
> > > wrote:
> > > 
> > > > I'd appreciate the help! There are two ways I can see going about it,
> > > > one
> > > > would be to write more comprehensive simple tests (such as what's done
> > > > in
> > > > src/lib.rs) just asserting things that should or shouldn't work.
> > > > 
> > > > A more comprehensive way, but also far more difficult, would be to
> > > > write a
> > > > separate module or binary all together which uses the API to assert
> > > > some of
> > > > the more internal workings (such as correct parsing of pre-determined
> > > > command line arguments).
> > > > 
> > > > I'm of the mind to say start small and grow, so if you'd like to put
> > > > together some more tests in src/lib.rs that'd be awesome! The way I
> > > > have
> > > > things working right now is that if the developer (i.e. consumer of
> > > > `clap`)
> > > > does something wrong it will `panic!` at runtime, so that it will be
> > > > caught
> > > > before ever making it to the end user. But if the end user (i.e. user
> > > > of
> > > > the consumer's product) does something wrong, it should not `panic!`
> > > > but
> > > > fail gracefully with an error message and usage string). So what I'm
> > > > more
> > > > concerned with testing is the developer side of things, that should
> > > > (or
> > > > should not) `panic!`
> > > > 
> > > > On Tue, Mar 17, 2015 at 12:47 AM, Garrett Squire
> > > > notifications@github.com
> > > > wrote:
> > > > 
> > > > > I'd be willing to help start this. How would you want the tests to
> > > > > be
> > > > > written since it parses from the command line?
> > > > > 
> > > > > —
> > > > > Reply to this email directly or view it on GitHub
> > > > > <https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82103845
> > > > > .
> > > > 
> > > > ---
> > > > 
> > > > Reply to this email directly or view it on GitHub:
> > > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82370305
> > > 
> > > —
> > > Reply to this email directly or view it on GitHub
> > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82415819.
> > 
> > ---
> > 
> > Reply to this email directly or view it on GitHub:
> > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82424729
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82429895.


---

_Comment by @untitaker on 2015-03-17 16:18_

The CLI framework [click](http://click.pocoo.org/3/testing/) for Python has its
own tools for writing application tests. They monkeypatch a lot of things
(sys.stdout, sys.argv), I think some of those ideas are basically
unimplementable in Rust.

Using subprocesses with something like `expect` would be a language-independent
way to go about this, but such tests come with a huge performance penalty.

OTOH I think we wouldn't actually need as much test coverage as one would
require in a dynamic language. Mostly logic-intensive things like the help
output formatter require extensive tests, but that can be esentially a function
that takes an app and returns a string.

On Tue, Mar 17, 2015 at 08:57:08AM -0700, Kevin K. wrote:

> I totally agree. And there's where I'd eventually like to get, it's just
> harder to implement, like you said.
> 
> I'm not sure, I haven't seen anything specific like that, but it'd be nice.
> I can think of hacky ways to do that, but all involve another binary or
> module. I currently have a binary, named "fake" which I use to test various
> things, but it's not at all automated, just something I use to double check
> myself. You'd almost have to have fake's test (or whatever binary) call
> itself, monitor the output, and assert based off the findings...I'll have
> to think on that some more.
> 
> If anyone has a good way to go about this, I'm all ears!
> 
> On Tue, Mar 17, 2015 at 11:51 AM, Markus Unterwaditzer <
> notifications@github.com> wrote:
> 
> > Interesting, didn't know that! Still believe that a results-based API would
> > provide some benefits (more precise assertions), tedious to implement
> > though.
> > 
> > Is there something similar for asserting a particular stdout output?
> > 
> > On Tue, Mar 17, 2015 at 08:46:02AM -0700, Kevin K. wrote:
> > 
> > > You can use the #[should_panic] directive if a given function should
> > > produce a panic (which causes the test to pass on a panic). You just have
> > > to be careful, because things can panic for a multitude of reasons, and
> > > it's hard to determine why they panic'ed. I believe there is a directive
> > > to
> > > such as #[should_panic("some string")] which checks the panic message
> > > for a
> > > particular string, and only passes the test if the panic message contains
> > > that string (but I can't remember off the top of my head the exact name).
> > > 
> > > On Tue, Mar 17, 2015 at 11:32 AM, Markus Unterwaditzer <
> > > notifications@github.com> wrote:
> > > 
> > > > Since you can't assert that a panic is happening, I suppose there
> > > > should
> > > > be a separate API which doesn't use panics, which
> > > > - can then be wrapped with one that does panic
> > > > - can be used directly to assert correct detection of developer errors.
> > > > 
> > > > Related: Clap could generally provide utilities for the dev to test its
> > > > own app's behavior. Then those could be used for testing Clap itself
> > > > too.
> > > > 
> > > > On 17 March 2015 15:04:26 CET, "Kevin K." notifications@github.com
> > > > wrote:
> > > > 
> > > > > I'd appreciate the help! There are two ways I can see going about it,
> > > > > one
> > > > > would be to write more comprehensive simple tests (such as what's done
> > > > > in
> > > > > src/lib.rs) just asserting things that should or shouldn't work.
> > > > > 
> > > > > A more comprehensive way, but also far more difficult, would be to
> > > > > write a
> > > > > separate module or binary all together which uses the API to assert
> > > > > some of
> > > > > the more internal workings (such as correct parsing of pre-determined
> > > > > command line arguments).
> > > > > 
> > > > > I'm of the mind to say start small and grow, so if you'd like to put
> > > > > together some more tests in src/lib.rs that'd be awesome! The way I
> > > > > have
> > > > > things working right now is that if the developer (i.e. consumer of
> > > > > `clap`)
> > > > > does something wrong it will `panic!` at runtime, so that it will be
> > > > > caught
> > > > > before ever making it to the end user. But if the end user (i.e. user
> > > > > of
> > > > > the consumer's product) does something wrong, it should not `panic!`
> > > > > but
> > > > > fail gracefully with an error message and usage string). So what I'm
> > > > > more
> > > > > concerned with testing is the developer side of things, that should
> > > > > (or
> > > > > should not) `panic!`
> > > > > 
> > > > > On Tue, Mar 17, 2015 at 12:47 AM, Garrett Squire
> > > > > notifications@github.com
> > > > > wrote:
> > > > > 
> > > > > > I'd be willing to help start this. How would you want the tests to
> > > > > > be
> > > > > > written since it parses from the command line?
> > > > > > 
> > > > > > —
> > > > > > Reply to this email directly or view it on GitHub
> > > > > > <https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82103845
> > > > > > .
> > > > > 
> > > > > ---
> > > > > 
> > > > > Reply to this email directly or view it on GitHub:
> > > > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82370305
> > > > 
> > > > —
> > > > Reply to this email directly or view it on GitHub
> > > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82415819.
> > > 
> > > ---
> > > 
> > > Reply to this email directly or view it on GitHub:
> > > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82424729
> > 
> > —
> > Reply to this email directly or view it on GitHub
> > https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82429895.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/kbknapp/clap-rs/issues/4#issuecomment-82433398


---

_Comment by @gsquire on 2015-03-17 16:25_

For now, I think I could add some more tests to `src/lib.rs` as suggested. How would you all feel about a separate test script that can build and use a binary compiled with Clap and then run it with various args and check the results from there?

I think that would be simple enough to build with Python or Ruby or whatever else sounded appropriate. That's just my idea.


---

_Comment by @kbknapp on 2015-03-17 16:48_

@gsquire Yeah I'm good with that. The only thing I want to avoid is a huge convoluted system that takes a week to wrap your brain around before knowing how to simply test a library. But I'm all for a script that runs some automated testing.

I'd lean to towards Python if possible, as that's the background I come from, and I know very little (read none) Ruby.

@untitaker I'm not overly concerned with the performance of the tests, unless it gets ridiculous. The end user will never have to worry about the tests, they're more for our benefit to know we didn't break something along the way. And I totally agree that we wouldn't need quite as comprehensive a test suite, because a fair amount of the checking is already ensured by the compiler.


---

_Comment by @kbknapp on 2015-03-24 15:24_

The solution as it stands (or that I'm currently adding) is:
1. Test internal workings (such as _building_ an application with `clap`)
   
   a. ~~Use src/lib.rs tests, maybe at some point move to a tests dir if lib.rs gets too cluttered (not there yet)~~
   
   b. This is done-ish, but needs some more tests 
2. Test external workings (such as _using_ an application built with `clap`)
   
   a. ~~Add a `claptests` application inside this repo~~
   
   b. ~~Add a python script to run `claptests` multiple times with various options and verify the output~~


---

_Comment by @kbknapp on 2015-03-26 02:00_

~~Comparing command output is turning out to be quite difficult due to unicode...I haven't figured it out yet, but then I also have spent much time.~~ 

My goal is to have a python script which runs various commands checking the output against a known good. This script should be run when running `make test` inside claptests. Checking small outputs should be easy, but large chunks such as the help message is difficult.


---

_Comment by @kbknapp on 2015-03-26 15:25_

I finally figured it out. It's becase I don't sort the list of options or flags when printing help, so the order sometimes changes between runs. I don't want to sort options for performance reason (unless at a later date people just really want sorted options whe viewing the help info), so I'll simply count the number of lines printed and assume good.


---

_Comment by @gsquire on 2015-03-29 23:45_

@kbknapp Are you working on one currently? If you want to add it to the repository I can help add to it. Otherwise I will keep plugging away on my own.


---

_Comment by @kbknapp on 2015-03-30 00:02_

@gsquire Not currently. I've just got a simple python script which runs a few tests to ensure I haven't broken anything new upon a commit. (inside the claptests/ run `make test`) although, I still need to add quite a few features to be tested, it's still the bare minimum. If you've got something you'd like to incorporate I'll by all means take a look at it!


---

_Referenced in [clap-rs/clap#62](../../clap-rs/clap/issues/62.md) on 2015-04-05 19:09_

---

_Comment by @kbknapp on 2015-04-14 00:40_

I'm going to go ahead and close this issue, as I'm decently happy with the testing I currently have. Granted I could always use more, so this isn't to stop contributions to the tests...just so I don't have an issue that in all honesty could be open forever.


---

_Closed by @kbknapp on 2015-04-14 00:40_

---
