---
number: 17319
title: Early validation vs resolution-time failure in dependency solvers
type: issue
state: closed
author: quencs
labels: []
assignees: []
created_at: 2026-01-04T23:51:06Z
updated_at: 2026-01-05T13:56:10Z
url: https://github.com/astral-sh/uv/issues/17319
synced_at: 2026-01-07T12:31:16-06:00
---

# Early validation vs resolution-time failure in dependency solvers

---

_Issue opened by @quencs on 2026-01-04 23:51_

Framed in terms of uv / pip–style lock solvers, I think the tension here is really about how much responsibility we expect the solver to carry versus how much signal we give it up front.

Lower-bound solving is one of the few resolution strategies that genuinely changes outcomes, and in curated cases it can be very effective. But in practice, solvers like pip or uv can only operate on the metadata they’re given, and lower bounds in the wild are often conservative estimates rather than precise compatibility guarantees. Without editable or iteratively refined metadata, the solver is forced to treat those bounds as ground truth.

That’s where relying on future resolution failures becomes risky. When an incompatibility is only detected at solve time — potentially against a newer Python or environment target — the solver has no room to recover. Users get stuck on old lockfiles or pinned versions, and the cost shows up as ecosystem friction rather than actionable feedback for the author.

From a solver-design perspective, earlier and explicit validation isn’t about preventing resolution failures; it’s about ensuring that the solver fails for the right reasons, and at a time when authors can still adjust constraints intentionally. Resolution remains a useful signal, but treating it as the primary discovery mechanism tends to push risk downstream to users instead of helping maintainers make informed compatibility decisions up front.

---

_Comment by @quencs on 2026-01-04 23:57_

# Early validation vs resolution-time failure in uv’s dependency solver

## Background

This issue is intended as a design discussion about *when* dependency incompatibilities should surface in uv’s workflow, and *who* ultimately bears the cost when they do.

The focus is not on a specific bug, but on the trade-offs between:
- discovering incompatibilities early (e.g. during development or CI), and
- discovering them later at resolution or lock time, potentially against newer Python targets.

## Motivation

In real-world Python ecosystems, dependency metadata is often conservative or incomplete by necessity. Lower bounds, in particular, tend to represent best-effort estimates rather than precise compatibility guarantees, except in tightly controlled environments.

Solvers like uv (and pip) can only operate on the metadata they are given. When incompatibilities are deferred until resolution time—especially when regenerating lockfiles or targeting newer Python versions—the solver has no flexibility beyond failing. At that stage, the cost is no longer localized to the library author: users may become stuck on older locks or pinned versions, and maintainers are forced into retroactive compatibility or support decisions.

Earlier and more explicit validation can surface narrowing compatibility constraints while they are still cheap to act on, and while authors still have enough context to make intentional trade-offs.

## Lower-bound solving

Lower-bound solving is one of the few resolution strategies that genuinely changes outcomes, and in curated or well-maintained ecosystems it can be very effective. It can and does surface real issues.

However, its usefulness depends almost entirely on the accuracy of declared lower bounds. Without editable or continuously refined metadata, solvers are forced to treat those bounds as ground truth—even when they are only approximations. In broader ecosystems, this significantly limits lower-bound solving as a standalone safeguard.

As a result, lower-bound solving is a valuable signal, but not necessarily sufficient on its own for managing long-term compatibility.

## Framing the trade-off

From a solver-design perspective, the question is not whether resolution-time failures are useful—they clearly are—but whether relying on them as the *primary* discovery mechanism produces good outcomes.

When incompatibilities are discovered late:
- feedback loops are long,
- the impact is externalized to users,
- and lockfile or version-line fragmentation becomes more likely.

Earlier validation does not eliminate resolution failures, but it can help ensure they occur for the *right* reasons, and at a time when authors can still respond intentionally.

## Open questions

Some questions that may be worth discussion:

- Should uv provide or encourage mechanisms that surface narrowing compatibility earlier, even if resolution would technically succeed today?
- How should uv balance solver strictness against the reality of imperfect metadata?
- Are there cases where deferring failure to resolution time is clearly preferable, and how might those be distinguished?
- How should lockfile regeneration against newer Python targets factor into this design?

## Closing

The goal here is not to prescribe a single correct strategy, but to clarify the trade-offs and failure modes that arise in real ecosystems. Any insight into uv’s intended philosophy around these questions would be valuable.

---

_Comment by @konstin on 2026-01-05 13:56_

Please do not use LLMs to write issues, if you have a specific problem please describe it in your own words.

---

_Closed by @konstin on 2026-01-05 13:56_

---
